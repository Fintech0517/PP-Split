{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：这个notebook演示了如何使用quantification方法（目前实现了4种方法进行隐私量化）\n",
    "1. dFIL (batchsize = 1)\n",
    "2. distance correlation (batchsize>=2)\n",
    "3. mutual information (batchsize>=8)\n",
    "4. ULoss (batchsize = 1)\n",
    "\n",
    "注意用不同方法的时候要重新设置 批大小 （即args['batch_size']的值）\n",
    "\n",
    "因为在整个测试集上进行隐私量化，时间太长了（可能要跑好几天）所以这里设计了一个get_one_data()函数，取测试集的前k个数据作为一个数据集，batch_size=k,因此只需要迭代一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch.nn.functional import avg_pool2d\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "\n",
    "\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "from ppsplit.quantification.distance_correlation.distCor import distCorMetric\n",
    "from ppsplit.quantification.fisher_information.dFIL_inverse import dFILInverseMetric\n",
    "from ppsplit.quantification.shannon_information.mutual_information import MuInfoMetric\n",
    "from ppsplit.quantification.shannon_information.ULoss import ULossMetric\n",
    "from ppsplit.quantification.rep_reading.rep_reader import PCA_Reader\n",
    "\n",
    "\n",
    "# 模型、数据集获取\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader_and_model, get_dataloader,get_models, get_infotopo_para\n",
    "\n",
    "# utils\n",
    "from ppsplit.utils.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Ruijun Deng\n",
    "Date: 2024-08-24 00:41:30\n",
    "LastEditTime: 2024-08-28 05:27:58\n",
    "LastEditors: Ruijun Deng\n",
    "FilePath: /PP-Split/examples/InvMetrics/quantification.ipynb\n",
    "Description: \n",
    "'''\n",
    "# 基本参数：\n",
    "# 硬件\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 参数\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset', type = str, default = 'CIFAR10')\n",
    "# parser.add_argument('--device', type = str, default = 'cuda:1')\n",
    "# parser.add_argument('--batch_size',type=int, default=1) # muinfo最小为8，# distcor最小为2\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# args = {\n",
    "#         'device':torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "#         # 'device':torch.device(\"cpu\"),\n",
    "#         'dataset':'CIFAR10',\n",
    "#         # 'dataset':'bank',\n",
    "#         # 'dataset':'credit',\n",
    "#         # 'dataset':'purchase',\n",
    "#         # 'result_dir': 'InvMetric-202403',\n",
    "#         'result_dir': '20240428-Rep-quantify/',\n",
    "#         'batch_size':2,\n",
    "#         'noise_scale':0, # 防护措施\n",
    "#         'num_pairs': 10000, # RepE\n",
    "#         }\n",
    "# print(args['device'])\n",
    "\n",
    "args = {\n",
    "        'device':torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        # 'device':torch.device(\"cpu\"),\n",
    "        'dataset':'CIFAR10',\n",
    "        # 'dataset':'bank',\n",
    "        # 'dataset':'credit',\n",
    "        # 'dataset':'purchase',\n",
    "        # 'dataset':'Iris',\n",
    "        # 'model': 'ResNet18',\n",
    "        'model': 'VGG5',\n",
    "        # 'result_dir': '20240702-FIL/',\n",
    "        'result_dir': 'InvMetric-202403/',\n",
    "        'oneData_bs': 500,\n",
    "        'test_bs': 500,\n",
    "        'train_bs': 1,\n",
    "        'noise_scale': 0, # 防护措施\n",
    "        'split_layer': 5,\n",
    "        'test_num': 'MI', # MI, invdFIL, distCor, ULoss,  # split layer [2,3,5,7,9,11] for ResNet18\n",
    "        'no_dense':True,\n",
    "        }\n",
    "\n",
    "print(args['device'])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集及其模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "train decoder model...\n",
      "results_dir: ../../results/InvMetric-202403//VGG5/MI/\n",
      "inverse_dir: ../../results/InvMetric-202403//VGG5/MI/layer1/\n",
      "decoder_route: ../../results/InvMetric-202403//VGG5/MI//Decoder-layer1.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (denses): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)\n",
    "infotopo_msg = get_infotopo_para(args)\n",
    "msg = {**model_msg,**data_msg,**infotopo_msg}\n",
    "\n",
    "# 数据集\n",
    "one_data_loader,trainloader,testloader = data_msg['one_data_loader'],data_msg['trainloader'], data_msg['testloader']\n",
    "\n",
    "# infotopo\n",
    "conv = msg['conv']\n",
    "\n",
    "# 模型和路径\n",
    "client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "decoder_route = model_msg['decoder_route']\n",
    "image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "results_dir = model_msg['results_dir']\n",
    "inverse_dir = results_dir + 'layer'+str(args['split_layer'])+'/'\n",
    "data_type = 1 if args['dataset'] == 'CIFAR10' else 0\n",
    "split_layer = args['split_layer']\n",
    "\n",
    "print('results_dir:',results_dir)\n",
    "print('inverse_dir:',inverse_dir)\n",
    "print('decoder_route:',decoder_route)\n",
    "\n",
    "create_dir(results_dir)\n",
    "\n",
    "# client_net使用\n",
    "client_net = client_net.to(args['device'])\n",
    "client_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各种指标计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.dFIL-inverse\n",
    "注意：batchsize 需要等于1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# dFIL inverse指标计算\n",
    "\n",
    "eta_same_layer_list = []\n",
    "eta_diff_layer_list=[]\n",
    "\n",
    "metric = dFILInverseMetric()\n",
    "# 对traingloader遍历计算所有 inverse dFIL\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)):\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    # if j < 31705:\n",
    "        # continue\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(args['device']), labels.to(args['device'])\n",
    "    inputs.requires_grad_(True) # 需要求导\n",
    "    \n",
    "    # inference\n",
    "    outputs = client_net(inputs)\n",
    "\n",
    "    eta = metric.quantify(model=client_net, inputs=inputs, outputs=outputs, with_outputs=True)\n",
    "    # 打印\n",
    "    # print(str(j)+\": \"+str(eta.item()))\n",
    "    eta_same_layer_list.append(eta)\n",
    "eta_diff_layer_list.append(eta_same_layer_list)\n",
    "\n",
    "# 结果储存到csv中\n",
    "matrix = np.array(eta_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in split_layer_list]).to_csv(save_img_dir + f'dFIL-1.csv',index=False)\n",
    "pd.DataFrame(data=transpose, columns=[split_layer]).to_csv(results_dir + f'dFIL-layer{split_layer}.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. distance correlation\n",
    "注意：batchsize >=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance correlation指标计算\n",
    "\n",
    "distCorr_diff_layer_list = []\n",
    "distCorr_same_layer_list = []\n",
    "metric = distCorMetric()\n",
    "\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    tab, labels = data\n",
    "    tab, labels = tab.to(args['device']), labels.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        pred = client_net(tab).cpu().detach()\n",
    "        inputs = tab.cpu().detach()\n",
    "\n",
    "        distCorr = metric.quantify(inputs=inputs,outputs=pred) # x,z\n",
    "        distCorr_same_layer_list.append(distCorr)\n",
    "\n",
    "\n",
    "print(f\"Layer {args['split_layer']} Avg distCorr: {sum(distCorr_same_layer_list)/len(distCorr_same_layer_list)}\")\n",
    "distCorr_diff_layer_list.append(distCorr_same_layer_list)\n",
    "\n",
    "# 保存到csv中\n",
    "matrix = np.array(distCorr_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in range (len(split_layer_list))]).to_csv(save_img_dir + f'DLoss-bs{batch_size}.csv',index=False)\n",
    "pd.DataFrame(data=transpose, columns=[args['split_layer']]).to_csv(results_dir + f'DLoss.csv',index=False)\n",
    "print(results_dir + f'DLoss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. mutual information\n",
    "注意：batchsize>=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [10:49<00:00, 649.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 MI: 878.9487438395895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mutual information指标计算\n",
    "\n",
    "MI_diff_layer_list = []\n",
    "MI_same_layer_list = []\n",
    "metric = MuInfoMetric()\n",
    "avg_MI = []\n",
    "\n",
    "# for e in range(20):\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        # inference\n",
    "        if conv:\n",
    "            print('images: ', images.shape)\n",
    "            images= avg_pool2d(images,kernel_size=4)\n",
    "            print('images_pooled: ',images.shape)\n",
    "\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        inputs = images.cpu().detach()\n",
    "        mi = metric.quantify(inputs=inputs, outputs = outputs)\n",
    "        MI_same_layer_list.append(mi)\n",
    "        \n",
    "print(f\"Layer {args['split_layer']} MI: {sum(MI_same_layer_list)/len(MI_same_layer_list)}\")\n",
    "MI_diff_layer_list.append(MI_same_layer_list)\n",
    "\n",
    "\n",
    "# 保存到csv中\n",
    "matrix = np.array(MI_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in split_layer_list]).to_csv(results_dir + f'MI-bs{batch_size}.csv',index=False)\n",
    "# pd.DataFrame(data=transpose, columns=[split_layer]).to_csv(results_dir + f'MILoss-layer{split_layer}.csv',index=False)\n",
    "save_route = results_dir + f'MI.csv'\n",
    "if os.path.exists(save_route):\n",
    "    df = pd.read_csv(save_route)\n",
    "    df[args['split_layer']] = transpose\n",
    "    df.to_csv(save_route,index=False)\n",
    "else:\n",
    "    pd.DataFrame(data=transpose, columns=[args['split_layer']]).to_csv(save_route,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uncertainty Loss\n",
    "注意：batchsize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../results/InvMetric-202403//Iris/MI//Decoder-layer3.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb 单元格 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdrj-gpu-10_176_22_36/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m ULoss_same_layer_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdrj-gpu-10_176_22_36/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m metric \u001b[39m=\u001b[39m ULossMetric()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdrj-gpu-10_176_22_36/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m decoder_net \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(decoder_route)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdrj-gpu-10_176_22_36/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m decoder_net\u001b[39m.\u001b[39mto(args[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdrj-gpu-10_176_22_36/home/dengruijun/data/FinTech/PP-Split/examples/InvMetrics/quantification.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m decoder_net\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../results/InvMetric-202403//Iris/MI//Decoder-layer3.pth'"
     ]
    }
   ],
   "source": [
    "# mutual information指标计算\n",
    "\n",
    "ULoss_diff_layer_list = []\n",
    "ULoss_same_layer_list = []\n",
    "metric = ULossMetric()\n",
    "decoder_net = torch.load(decoder_route)\n",
    "decoder_net.to(args['device'])\n",
    "decoder_net.eval()\n",
    "\n",
    "\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        # inference\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        uloss = metric.quantify(output = outputs, decoder_net=decoder_net)\n",
    "        ULoss_same_layer_list.append(uloss)\n",
    "        \n",
    "print(f\"Layer {split_layer} ULoss: {sum(ULoss_same_layer_list)/len(ULoss_same_layer_list)}\")\n",
    "ULoss_diff_layer_list.append(ULoss_same_layer_list)\n",
    "\n",
    "\n",
    "# 保存到csv中\n",
    "matrix = np.array(ULoss_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in split_layer_list]).to_csv(results_dir + f'ULoss-bs{batch_size}.csv',index=False)\n",
    "pd.DataFrame(data=transpose, columns=[split_layer]).to_csv(results_dir + f'ULoss.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RepE Reader\n",
    "无所谓bs\n",
    "\n",
    "1 格式化检查\n",
    "\n",
    "2 实例化一个finder\n",
    "\n",
    "3 模型推理数据得到hidden state（中途有些处理）\n",
    "\n",
    "4 训练pca得到direction\n",
    "\n",
    "5 转换，nparray转换成浮点数\n",
    "\n",
    "6 如果有train label，就get sign一下\n",
    "\n",
    "评估维度性，对label的贡献（偏泄漏隐私，还是偏不泄漏隐私）\n",
    "\n",
    "你directionality 反应的你对于泄漏方向的偏移，和真实的标签？   \n",
    "\n",
    "7 分析测试数据的隐私泄漏程度（在每一层的隐私泄漏程度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "from target_model.data_preprocessing.dataset import pair_smashed_data,diff_pair_data\n",
    "from target_model.data_preprocessing.preprocess_cifar10 import get_cifar10_normalize_two_train\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. designing stimulus and test\n",
    "dataset_route = f\"../results/{args['result_dir']}/VGG5/quantification/{args['num_pairs']}pairs/\"\n",
    "if os.path.isfile(dataset_route+'train_feature.pkl'): # 直接加载预处理好的数据集\n",
    "    print(f\"=> loading paired dataset from {dataset_route}\")\n",
    "    with open(dataset_route+'train_feature.pkl','rb') as f:\n",
    "        train_feature = pickle.load(file=f)       \n",
    "    with open(dataset_route+'test_feature.pkl','rb') as f:\n",
    "        test_feature=pickle.load(file=f)   \n",
    "    with open(dataset_route+'train_label.pkl','rb') as f:                                                       \n",
    "        train_labels=pickle.load(file=f)      \n",
    "    with open(dataset_route+'test_label.pkl', 'rb') as f:                                                    \n",
    "        test_labels=pickle.load(file=f)     \n",
    "    train_loader= DataLoader(train_feature,shuffle=False,batch_size=1)\n",
    "    test_loader = DataLoader(test_feature,shuffle=False,batch_size=1)       \n",
    "# if False:\n",
    "#     pass\n",
    "else: # 进行预处理并存储\n",
    "    seen_loader,unseen_loader,_ = get_cifar10_normalize_two_train(batch_size=1)\n",
    "\n",
    "    train_loader,train_labels,test_loader,test_labels = pair_smashed_data(seen_loader,\n",
    "                                                                        unseen_loader,\n",
    "                                                                        num_pairs=args['num_pairs'])\n",
    "    create_dir(dataset_route)\n",
    "    with open(dataset_route+'train_feature.pkl','wb') as f:\n",
    "        pickle.dump(obj=train_loader.dataset,file=f)       \n",
    "    with open(dataset_route+'test_feature.pkl','wb') as f:\n",
    "        pickle.dump(obj=test_loader.dataset,file=f)   \n",
    "    with open(dataset_route+'train_label.pkl','wb') as f:                                                       \n",
    "        pickle.dump(obj=train_labels,file=f)      \n",
    "    with open(dataset_route+'test_label.pkl', 'wb') as f:                                                    \n",
    "        pickle.dump(obj=test_labels,file=f)                                                          \n",
    "\n",
    "print(train_labels[0])\n",
    "print(test_labels[0].index(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. collecting neural activity\n",
    "\n",
    "# #Picking the top X probabilities \n",
    "def clipDataTopX(dataToClip, top=3):\n",
    "    sorted_indices = torch.argsort(dataToClip,dim=1,descending=True)[:,:3]\n",
    "    new_data = torch.gather(dataToClip,1,sorted_indices)\n",
    "    \n",
    "\t# res = [sorted(s, reverse=True)[0:top] for s in dataToClip ]\n",
    "\t# return np.array(res)\n",
    "    # print(new_data[0])\n",
    "    return new_data\n",
    "\n",
    "# 收集所有smashed data\n",
    "train_smashed_data_list = []\n",
    "i = 1\n",
    "for j, data in enumerate(tqdm.tqdm(train_loader)): # 对trainloader遍历\n",
    "    # print(\"data: \", len(data))\n",
    "    features=data.to(args['device'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = client_net(features)\n",
    "        # pred_topk = sorted(pred, reverse=True)[0:5]\n",
    "        # train_smashed_data_list.append(pred)\n",
    "        train_smashed_data_list.append(pred)\n",
    "\n",
    "train_smashed_data_list=torch.stack(train_smashed_data_list).squeeze()\n",
    "# 拉成 [batchsize, vectorsize]的二维矩阵\n",
    "train_smashed_data_list=train_smashed_data_list.reshape(train_smashed_data_list.shape[0],-1)\n",
    "train_smashed_data_list = clipDataTopX(train_smashed_data_list,top=10)\n",
    "# 相对距离\n",
    "diff_data = diff_pair_data(train_smashed_data_list) # np.array\n",
    "print(\"diff_data.shape: \", diff_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. constructing a linear model\n",
    "# 训练direction finder\n",
    "reader = PCA_Reader(n_components=1) # 要的是numpy数据？可以要tensor数据\n",
    "# diff_data = diff_data.reshape(diff_data.shape[0],-1)\n",
    "directions = reader.get_rep_direction(diff_data)\n",
    "signs = reader.get_sign(hidden_states=train_smashed_data_list,train_labels=train_labels)\n",
    "print('direction shape of first layer: ', reader.direction.shape)\n",
    "print('signs of first layer: ', reader.direction_signs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 测试\n",
    "test_smashed_data_list = []\n",
    "for j, data in enumerate(tqdm.tqdm(test_loader)): # 对trainloader遍历\n",
    "    features=data.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        pred = client_net(features)\n",
    "        test_smashed_data_list.append(pred)\n",
    "\n",
    "test_smashed_data_list=torch.stack(test_smashed_data_list).squeeze()\n",
    "test_smashed_data_list=test_smashed_data_list.reshape(test_smashed_data_list.shape[0],-1)\n",
    "test_smashed_data_list = clipDataTopX(test_smashed_data_list,top=10)\n",
    "acc = reader.quantify_acc(hidden_states=test_smashed_data_list,test_labels=test_labels)\n",
    "print(f\"quantified accuracy(privacy lekage): {acc} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([1,2]),torch.Tensor([3,4])]\n",
    "y = [torch.Tensor([5,6]),torch.Tensor([7,8])]\n",
    "l = [x,y]\n",
    "print(l)\n",
    "l1 = [torch.stack(i) for i in l]\n",
    "print(l1)\n",
    "l2 = [item for sublist in l for item in sublist]\n",
    "print(l2)\n",
    "\n",
    "# list[tensor]转tensor\n",
    "tensor_list = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]), torch.tensor([7, 8, 9])]\n",
    "tensor_stack = torch.stack(tensor_list)\n",
    "print(tensor_stack)\n",
    "\n",
    "# 看两个tensor比较\n",
    "x = torch.Tensor([1,2])\n",
    "y = torch.Tensor([3,4])\n",
    "print(x==y)\n",
    "x.reshape(1,-1)\n",
    "print(x.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
