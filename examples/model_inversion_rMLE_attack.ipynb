{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个notebook 发起了rMLE 数据重构攻击  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "from ppsplit.attacks.model_inversion.rMLE import rMLE_Attack\n",
    "from ppsplit.utils.utils import create_dir\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 导入各个baseline模型及其数据集预处理方法\n",
    "# 模型\n",
    "from target_model.models.splitnn_utils import split_weights_client\n",
    "from target_model.models.VGG import VGG,VGG5Decoder,model_cfg\n",
    "from target_model.models.BankNet import BankNet1,bank_cfg\n",
    "from target_model.models.CreditNet import CreditNet1,credit_cfg\n",
    "from target_model.models.PurchaseNet import PurchaseClassifier1,purchase_cfg\n",
    "# 数据预处理方法\n",
    "from target_model.data_preprocessing.preprocess_cifar10 import get_cifar10_normalize,get_one_data,deprocess\n",
    "from target_model.data_preprocessing.preprocess_bank import bank_dataset,preprocess_bank\n",
    "from target_model.data_preprocessing.preprocess_credit import preprocess_credit\n",
    "from target_model.data_preprocessing.preprocess_purchase import preprocess_purchase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "CIFAR10\n"
     ]
    }
   ],
   "source": [
    "# 一些超参数\n",
    "args = {\n",
    "        'device':torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        # 'device':torch.device(\"cpu\"),\n",
    "        'dataset':'CIFAR10',\n",
    "        # 'dataset':'bank',\n",
    "        # 'dataset':'credit',\n",
    "        # 'dataset':'purchase',\n",
    "        'batch_size':1\n",
    "        }\n",
    "print(args['device'])\n",
    "args['data_type']= 1 if args['dataset']=='CIFAR10' else 0 # 区分图像数据（1）和表格数据（0）\n",
    "print(args['dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集和模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "# 数据集和模型加载\n",
    "# 加载模型和数据集，并从unit模型中切割出client_model\n",
    "if args['dataset']=='CIFAR10':\n",
    "    # 超参数\n",
    "    testset_len = 10000 # 10000个数据一次 整个测试集合的长度\n",
    "    # split_layer_list = list(range(len(model_cfg['VGG5'])))\n",
    "    split_layer = 2 # 定成3吧？\n",
    "    test_num = 1 # 试验序号\n",
    "    \n",
    "    # 关键路径\n",
    "    unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/VGG5/BN+Tanh/VGG5-params-20ep.pth' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "    results_dir  = f'../results/rMLE-results-20240413/VGG5/{test_num}/'\n",
    "    decoder_route = f\"../results/VGG5/{test_num}/Decoder-layer{split_layer}.pth\"\n",
    "\n",
    "    # 数据集加载\n",
    "    trainloader,testloader = get_cifar10_normalize(batch_size = 1)\n",
    "    one_data_loader = get_one_data(testloader,batch_size = args['batch_size']) #拿到第一个测试数据\n",
    "\n",
    "    # 切割成client model\n",
    "    client_net = VGG('Client','VGG5',split_layer,model_cfg)\n",
    "    pweights = torch.load(unit_net_route)\n",
    "    if split_layer < len(model_cfg['VGG5']):\n",
    "        pweights = split_weights_client(pweights,client_net.state_dict())\n",
    "    client_net.load_state_dict(pweights)\n",
    "\n",
    "elif args['dataset']=='bank':\n",
    "    # 超参数\n",
    "    test_num = 1 # 试验序号\n",
    "    testset_len=8238\n",
    "    # split_layer_list = ['linear1', 'linear2']\n",
    "    split_layer_list = [0,2,4,6]\n",
    "    split_layer = 2\n",
    "\n",
    "    # 关键路径\n",
    "    results_dir  = f'../results/rMLE-results-20240413/Bank/{test_num}/'\n",
    "    unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/Bank/bank-20ep_params.pth'\n",
    "    decoder_route = f\"../results/Bank/{test_num}/Decoder-layer{split_layer}.pth\"\n",
    "\n",
    "    # 数据集加载\n",
    "    trainloader,testloader = preprocess_bank(batch_size=1)\n",
    "    one_data_loader = get_one_data(testloader,batch_size = args['batch_size']) #拿到第一个测试数据 \n",
    "\n",
    "    # 模型加载\n",
    "    client_net = BankNet1(layer=split_layer)\n",
    "    pweights = torch.load(unit_net_route)\n",
    "    if split_layer < len(bank_cfg):\n",
    "        pweights = split_weights_client(pweights,client_net.state_dict())\n",
    "    client_net.load_state_dict(pweights)\n",
    "\n",
    "elif args['dataset']=='credit':\n",
    "    # 超参数\n",
    "    test_num = 1 # 试验序号\n",
    "    testset_len = 61503 # for the mutual information\n",
    "    split_layer_list = [0,3,6,9]\n",
    "    split_layer = 3\n",
    "\n",
    "    # 关键路径\n",
    "    results_dir  = f'../results/rMLE-results-20240413/Credit/{test_num}/'\n",
    "    unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/credit/credit-20ep_params.pth'\n",
    "    decoder_route = f\"../results/Credit/{test_num}/Decoder-layer{split_layer}.pth\"\n",
    "\n",
    "    # 数据集加载\n",
    "    trainloader,testloader = preprocess_credit(batch_size=1)\n",
    "    one_data_loader = get_one_data(testloader,batch_size = args['batch_size']) #拿到第一个测试数据\n",
    "\n",
    "    # client模型切割加载\n",
    "    client_net = CreditNet1(layer=split_layer)\n",
    "    pweights = torch.load(unit_net_route)\n",
    "    if split_layer < len(credit_cfg):\n",
    "        pweights = split_weights_client(pweights,client_net.state_dict())\n",
    "    client_net.load_state_dict(pweights)\n",
    "\n",
    "elif args['dataset']=='purchase':\n",
    "    # 超参数\n",
    "    test_num = 1 # 试验序号\n",
    "    testset_len = 39465 # test len\n",
    "    # split_layer_list = [0,1,2,3,4,5,6,7,8]\n",
    "    split_layer = 3\n",
    "\n",
    "    # 关键路径\n",
    "    results_dir = f'../results/rMLE-results-20240413/Purchase/{test_num}/'\n",
    "    unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/Purchase100/Purchase_bestmodel_param.pth'\n",
    "    decoder_route = f\"../results/Purchase/{test_num}/Decoder-layer{split_layer}.pth\"\n",
    "    \n",
    "    # 数据集加载\n",
    "    trainloader,testloader = preprocess_purchase(batch_size=1)\n",
    "    one_data_loader = get_one_data(testloader,batch_size = args['batch_size']) #拿到第一个测试数据\n",
    "\n",
    "    # 模型加载\n",
    "    client_net = PurchaseClassifier1(layer=split_layer)\n",
    "    # pweights = torch.load(unit_net_route,map_location=torch.device('cpu'))\n",
    "    pweights = torch.load(unit_net_route)\n",
    "    if split_layer < len(purchase_cfg):\n",
    "        pweights = split_weights_client(pweights,client_net.state_dict())\n",
    "    client_net.load_state_dict(pweights)\n",
    "\n",
    "else:\n",
    "    exit(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Tanh()\n",
       "  )\n",
       "  (denses): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建储存结果的文件夹\n",
    "inverse_dir = results_dir + 'layer'+str(split_layer)+'/' # 储存逆向结果的dir\n",
    "create_dir(results_dir)\n",
    "create_dir(inverse_dir)\n",
    "\n",
    "# client_net调整模式\n",
    "client_net = client_net.to(args['device'])\n",
    "client_net.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试进行rMLE攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_net: \n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      "  (denses): Sequential()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:11<00:00, 131.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average euc: 0.722615122795105\n",
      "average mse: 0.01757199689745903\n",
      "average ssim: 0.8617275357246399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmle_attack = rMLE_Attack(inverse_dir=inverse_dir,data_type=args['data_type'])\n",
    "\n",
    "rmle_attack.inverse(client_net=client_net,dataloader=one_data_loader,Niters=20000,save_fake=True,deprocess=None if args['data_type']==0 else deprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
