{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 基础设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Ruijun Deng\n",
    "Date: 2024-08-14 16:59:47\n",
    "LastEditTime: 2024-08-25 00:47:50\n",
    "LastEditors: Ruijun Deng\n",
    "FilePath: /PP-Split/examples/effectInfo/effectInfo.ipynb\n",
    "Description: \n",
    "'''\n",
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch.nn.functional import avg_pool2d\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "from ppsplit.quantification.distance_correlation.distCor import distCorMetric\n",
    "from ppsplit.quantification.fisher_information.dFIL_inverse import dFILInverseMetric\n",
    "from ppsplit.quantification.shannon_information.mutual_information import MuInfoMetric\n",
    "from ppsplit.quantification.shannon_information.ULoss import ULossMetric\n",
    "from ppsplit.quantification.rep_reading.rep_reader import PCA_Reader\n",
    "from ppsplit.quantification.shannon_information.ITE_tools import Shannon_quantity\n",
    "\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader_and_model, \\\n",
    "    get_dataloader,get_models,get_infotopo_para\n",
    "\n",
    "# utils\n",
    "from ppsplit.utils.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "{'device': device(type='cuda', index=0), 'dataset': 'CIFAR10', 'model': 'VGG5', 'result_dir': '20240702-effectiveInfo/', 'oneData_bs': 50, 'test_bs': 1, 'train_bs': 1, 'noise_scale': 0, 'split_layer': 2, 'test_num': 'effectiveInfo1.8', 'no_dense': True}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# nohup python -u effectInfo1.8.py > ../../results/20240702-effectiveInfo/Resnet18/effectiveInfo1.8/effectInfo1.8-pool4-layer11-gpu.log 2>&1 &\n",
    "# nohup python -u effectInfo1.8.py > ../../results/20240702-effectiveInfo/VGG5/effectiveInfo1.8/effectInfo1.8-pool4-layer6-gpu.log 2>&1 &\n",
    "args = {\n",
    "        'device':torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        # 'device':torch.device(\"cpu\"),\n",
    "        'dataset':'CIFAR10',\n",
    "        # 'dataset':'bank',\n",
    "        # 'dataset':'credit',\n",
    "        # 'dataset':'purchase',\n",
    "        # 'dataset':'Iris',\n",
    "        # 'model': 'ResNet18',\n",
    "        'model': 'VGG5',\n",
    "        # 'result_dir': '20240702-FIL/',\n",
    "        'result_dir': '20240702-effectiveInfo/',\n",
    "        'oneData_bs': 1,\n",
    "        'test_bs': 500,\n",
    "        'train_bs': 1,\n",
    "        'noise_scale': 0, # 防护措施\n",
    "        'split_layer': 2,\n",
    "        # 'test_num': 'invdFIL', # MI, invdFIL, distCor, ULoss,  # split layer [2,3,5,7,9,11] for ResNet18\n",
    "        'test_num': 'effectiveInfo1.8.1',\n",
    "        'no_dense':True,\n",
    "        }\n",
    "print(args['device'])\n",
    "print(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "train decoder model...\n",
      "infotopo: nb_of_values:  36\n",
      "results_dir: ../../results/20240702-effectiveInfo//VGG5/effectiveInfo1.8/\n",
      "inverse_dir: ../../results/20240702-effectiveInfo//VGG5/effectiveInfo1.8/layer2/\n",
      "decoder_route: ../../results/20240702-effectiveInfo//VGG5/effectiveInfo1.8//Decoder-layer2.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Tanh()\n",
       "  )\n",
       "  (denses): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)\n",
    "infotopo_msg = get_infotopo_para(args)\n",
    "msg = {**model_msg,**data_msg,**infotopo_msg}\n",
    "\n",
    "# 数据集\n",
    "one_data_loader,trainloader,testloader = data_msg['one_data_loader'],data_msg['trainloader'], data_msg['testloader']\n",
    "\n",
    "# effectEntropy Infotopo参数\n",
    "nb_of_values = msg['nb_of_values']\n",
    "conv = msg['conv']\n",
    "# conv = False\n",
    "print(\"infotopo: nb_of_values: \",nb_of_values)\n",
    "\n",
    "# 模型\n",
    "client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "decoder_route = model_msg['decoder_route']\n",
    "image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "# 路径\n",
    "results_dir = model_msg['results_dir']\n",
    "inverse_dir = results_dir + 'layer' + str(args['split_layer'])+'/'\n",
    "data_type = 1 if args['dataset'] == 'CIFAR10' else 0\n",
    "split_layer = args['split_layer']\n",
    "\n",
    "print('results_dir:', results_dir)\n",
    "print('inverse_dir:', inverse_dir)\n",
    "print('decoder_route:', decoder_route)\n",
    "\n",
    "create_dir(results_dir)\n",
    "\n",
    "# client_net使用\n",
    "client_net = client_net.to(args['device'])\n",
    "client_net.eval()\n",
    "\n",
    "# for n, p in client_net.named_parameters():\n",
    "#     print(n, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. effective information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 effect Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effective fisher 计算函数\n",
    "import torch.autograd.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# nips23\n",
    "from torch.autograd.functional import jvp\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 自己实现的、规规矩矩的 jacobian + logdet 全部用torch的函数\n",
    "def computing_det_with_outputs(model, inputs, outputs, sigmas): # sigma_square\n",
    "        # batchsize:\n",
    "        batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "        output_size = outputs[0].numel() # 一个样本的outputs长度\n",
    "        input_size = inputs[0].numel() # 一个样本的outputs长度\n",
    "        effect_fisher_sum = 0.0\n",
    "\n",
    "        # 遍历单个样本: 换数据\n",
    "        for i in range(batch_size):\n",
    "            input_i = inputs[i].unsqueeze(0)\n",
    "\n",
    "            # 计算jacobian\n",
    "            J = F.jacobian(model, input_i)\n",
    "            # J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\n",
    "            J = J.reshape(output_size, input_size) # (batch, out_size, in_size)\n",
    "            # print(f\"J2.shape: {J.shape}, J2.prod: {torch.prod(torch.tensor(list(J.shape)))}\")\n",
    "            # 计算eta\n",
    "            JtJ = torch.matmul(J.t(), J)\n",
    "            I = 1.0/(sigmas)*JtJ\n",
    "            # ddFIL  = I.trace().div(input_size*input_size)\n",
    "\n",
    "            # 储存I\n",
    "            # I_np = I.cpu().detach().numpy()\n",
    "            # df = pd.DataFrame(I_np)\n",
    "            # df.to_csv(f'{i}.csv',index=False,header=False)\n",
    "\n",
    "            # print(\"I: \", I)\n",
    "            # w = torch.det(I)\n",
    "            # print('det I: ', I.det().log())\n",
    "\n",
    "            f1 = input_size * torch.log(2*torch.pi*torch.exp(torch.tensor(1.0)))\n",
    "            f2 = torch.logdet(I)\n",
    "            # print('log det I: ',f2 )\n",
    "            print('f1: ' ,f1)\n",
    "            print('f2: ' ,f2)\n",
    "            effect_fisher = 0.5 * (f1 - f2)\n",
    "            effect_fisher_sum += effect_fisher\n",
    "\n",
    "            print(\"effect_fisher: \" , effect_fisher)\n",
    "\n",
    "        # print(\"Jt*J: \", JtJ)\n",
    "        # print(\"Jt*J: \", JtJ.shape, JtJ)\n",
    "        # print(\"I.shape: \", I.shape)\n",
    "        # eta = dFIL\n",
    "        # print(f\"eta: {eta}\")\n",
    "        # print('t2-t1=',t2-t1, 't3-t2', t3-t2)\n",
    "        effect_fisher_mean = effect_fisher_sum / batch_size\n",
    "        return effect_fisher_mean.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# 用diag 来化简\n",
    "def computing_diag_det_with_outputs(model, inputs, outputs, sigmas=1.0): # sigma_square\n",
    "    # batchsize:\n",
    "    batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "    output_size = outputs[0].numel() # 一个样本的outputs长度\n",
    "    input_size = inputs[0].numel() # 一个样本的outputs长度\n",
    "    effect_fisher_sum = 0.0\n",
    "\n",
    "    # avg\n",
    "    I_diagonal_batch_avg = torch.zeros(input_size).to(args['device']) # batch上做平均\n",
    "    print(\"I_diagonal_batch_avg: \",I_diagonal_batch_avg.shape)\n",
    "    f2_2_avg_outer = torch.tensor(0.0).to(args['device'])\n",
    "    f2_avg_outer = torch.tensor(0.0).to(args['device'])\n",
    "    \n",
    "    # effecti_fisher第一部分\n",
    "    f1 = input_size * torch.log(2*torch.pi*torch.exp(torch.tensor(1.0)))\n",
    "\n",
    "    # f2需要求平均？\n",
    "    # 遍历单个样本: 换数据\n",
    "    for i in range(batch_size): # 对每个样本\n",
    "        input_i = inputs[i].unsqueeze(0)\n",
    "\n",
    "        # 计算jacobian\n",
    "        J = F.jacobian(model, input_i)\n",
    "        # J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\n",
    "        J = J.reshape(output_size, input_size) # (batch, out_size, in_size)\n",
    "        # print(f\"J2.shape: {J.shape}, J2.prod: {torch.prod(torch.tensor(list(J.shape)))}\")\n",
    "        # 计算eta\n",
    "        JtJ = torch.matmul(J.t(), J)\n",
    "        I = 1.0/(sigmas)*JtJ\n",
    "\n",
    "        # I = JtJ\n",
    "        # print(\"I: \", I)\n",
    "        # diagonal fisher information matrix (approximation)\n",
    "        I_diagonal = torch.diagonal(I,dim1=0,dim2=1) # vector\n",
    "        # print(\"I_diagonal: \",I_diagonal.shape)\n",
    "\n",
    "        I_diag = torch.diag_embed(I_diagonal) # matrix\n",
    "        # print('drj trace: ',torch.trace(I_diag))\n",
    "        \n",
    "        # batch的平均\n",
    "        I_diagonal_batch_avg += I_diagonal / (batch_size)\n",
    "\n",
    "        # # 储存I\n",
    "        # I_np = I.cpu().detach().numpy()\n",
    "        # df = pd.DataFrame(I_np)\n",
    "        # df.to_csv(f'{i}.csv',index=False,header=False)\n",
    "\n",
    "        # print(\"I: \", I)\n",
    "        # w = torch.det(I)\n",
    "        # print('det I: ', I.det().log())\n",
    "        \n",
    "        try:\n",
    "            s,f2 = torch.slogdet(I) # 直接用torch计算\n",
    "            if s <= 0:\n",
    "                raise RuntimeError(\"sign <=0 \")\n",
    "            print('f2: ', f2)\n",
    "        except RuntimeError as e:\n",
    "            print(\"logdet计算报错\")\n",
    "        # f2_1 = torch.logdet(I_diag) # 和后面的是一样的\n",
    "        f2_2 = torch.sum(torch.log(I_diagonal+1e-10)) # /I_diagonal.numel() # diagonal后计算\n",
    "\n",
    "        f2_2_avg_outer += f2_2 / batch_size\n",
    "        # f2_avg_outer += f2 / batch_size\n",
    "\n",
    "        # print('log det I: ', f2)\n",
    "        # print('f1: ' , f1)\n",
    "        # print('f2: ', f2)\n",
    "        # print('f2_1: ', f2_1)\n",
    "        print('f2_2: ', f2_2)\n",
    "\n",
    "    f2_2_avg_inner = torch.sum(torch.log(I_diagonal_batch_avg+1e-10)) # 用平均后的diagonal 计算\n",
    "\n",
    "    print('f2_avg_outer: ',f2_avg_outer)\n",
    "    print('f2_2_avg_outer: ',f2_2_avg_outer)\n",
    "    # print('f2_2_avg_inner: ',f2_2_avg_inner)\n",
    "    print('f1: ',f1)\n",
    "\n",
    "    # effect_fisher = 0.5 * (f1 - f2_2_avg_inner)\n",
    "    effect_fisher = 0.5 * (f1 - f2_2_avg_outer)\n",
    "    # effect_fisher = 0.5 * (f1 - f2_avg_outer)\n",
    "    # effect_fisher_sum+=effect_fisher\n",
    "\n",
    "    # print(\"effect_fisher: \",effect_fisher)\n",
    "    \n",
    "    # effect_fisher_mean = effect_fisher_sum / batch_size\n",
    "    return effect_fisher.cpu().detach().numpy()\n",
    "\n",
    "# arxiv'21 迁移学习领域的log det fisher 计算\n",
    "\n",
    "# nips'23 fisher trace 计算\n",
    "def calc_tr(net, x, device, sigmas=0.01, subsample=-1, jvp_parallelism=1): # nips'23 源码\n",
    "    # 并行粒度=1 意思是，每次只处理一个维度\n",
    "\n",
    "    print(f'x.shape: {x.shape}')\n",
    "    \n",
    "    # 定义一个局部函数 jvp_func**：这个函数接受两个参数 x 和 tgt，并返回 net.forward_first 方法的雅可比向量积（JVP）。\n",
    "    # 这意味着 jvp_func 用于计算网络对于输入 x 在方向 tgt 上的一阶导数\n",
    "    # tgt 计算雅各比向量积的向量\n",
    "    def jvp_func(x, tgt): \n",
    "        # return jvp(net.forward_first, (x,), (tgt,)) #返回 outputs, jacobian product\n",
    "        return jvp(net.forward, (x,), (tgt,)) #返回 outputs, jacobian product\n",
    "\n",
    "    # 获取一个batch中第一个数据的维度？d代表的是批次中第一个数据点展平后的特征数量，即输入数据的维度。\n",
    "    d = x[0].flatten().shape[0] # 把一个batch的x展平，获取input dim\n",
    "\n",
    "    # 用于存储每个输入数据点的迹，求迹的和。\n",
    "    tr = torch.zeros(x.shape[0], dtype=x.dtype).to(device)\n",
    "    print(f'tr.shape: {tr.shape}')\n",
    "\n",
    "    samples = range(d)\n",
    "\n",
    "    for j in range(math.ceil(d)): # 对于每个数据块 # 每个数据块包含不同的维度\n",
    "        tgts = []\n",
    "\n",
    "        # 遍历每个数据块中的每个维度\n",
    "        '''\n",
    "        在这个函数中，tgt 是用于计算雅可比向量积（JVP）的向量。具体来说，tgt 的作用如下：\n",
    "        构建雅可比向量积的向量：tgt 是一个与输入 x 形状相同的张量，但它的元素大部分为零，只有一个特定位置的元素为 1。这个特定位置对应于我们在计算迹时关注的特征维度。\n",
    "        计算 JVP：在 helper 函数中，tgt 被传递给 jvp_func，用于计算网络对于输入 x 在方向 tgt 上的一阶导数。具体来说，jvp_func 计算的是网络输出相对于输入 x 的雅可比矩阵与 tgt 的乘积。\n",
    "        估计迹：通过在不同的特征维度上重复上述过程，可以估计网络对于输入数据的迹。迹的计算涉及到对所有特征维度的导数进行求和，而 tgt 的作用就是在每次计算时只关注一个特征维度。\n",
    "        简而言之，tgt 是一个用于选择特定特征维度的向量，通过它可以逐个计算每个特征维度的导数，从而最终估计整个输入数据的迹。\n",
    "        '''\n",
    "        # 对于每一列，构建tgt， 形状和x一样，但是只有一列是1，其他是0\n",
    "        for k in samples[j:(j+1)]: # 提取整个batch中每个数据的特定维度\n",
    "            tgt = torch.zeros_like(x).reshape(x.shape[0], -1) # 按照batch 排列？# 雅各比向量积的\n",
    "            # 除了当前样本索引 k 对应的元素设置为 1。这相当于在计算迹时，每次只关注一个特征维度。\n",
    "            tgt[:, k] = 1. # 提取tgt所有的样本的k的特征 计算雅各比向量积的向量，可用于计算trace，所有行的特定几列有1值\n",
    "            tgt = tgt.reshape(x.shape) # 又变回x的形状\n",
    "            # print(f'tgt.shape: {tgt.shape}')\n",
    "            tgts.append(tgt) \n",
    "        tgts = torch.stack(tgts) # 把多个维度的tgt vstack，一行一行拼接起来，一行是一个维度。\n",
    "\n",
    "\n",
    "        # 定义一个辅助函数 helper，该函数接受一个目标张量 tgt并返回一个迹的张量和一个值的张量。\n",
    "        # jvp wrapper，遍历每个batchsize\n",
    "        def helper(tgt,x=x): # x是一个batch的数据\n",
    "            batch_size = x.shape[0]\n",
    "            grads_list = []\n",
    "            for i in range(batch_size): # 对每个样本\n",
    "                _, grad = jvp_func(x[i].unsqueeze(0), tgt[i].unsqueeze(0))  # 对每个批次元素调用jvp_func\n",
    "                grads_list.append(grad)\n",
    "            # 将结果列表转换为张量, 多个batch的给stack起来\n",
    "            grad = torch.stack(grads_list)\n",
    "\n",
    "            # print('grad.shape: ',grad.shape)\n",
    "            # print('grad: ',grad)\n",
    "\n",
    "            # grad.reshape(sum(list(x.shape)),-1)\n",
    "            # I_np = grad.cpu().detach().numpy()\n",
    "            # df = pd.DataFrame(I_np)\n",
    "            # df.to_csv(f'{time.time()}.csv',index=False,header=False)\n",
    "\n",
    "            # print('grad*grad: ',grad*grad)\n",
    "            # vals, grad = vmap(jvp_func, randomness='same')(x, tgt)\n",
    "            \n",
    "            # print('grad shape: ', grad.shape)\n",
    "            # 因此，矩阵平方的迹和迹的平方通常是不相等的。\n",
    "            # 先求平方再求迹\n",
    "            # range(1, len(grad.shape)) 生成一个从 1 到 len(grad.shape) - 1 的整数序列。\n",
    "            # torch.sum 函数对张量的指定维度进行求和。\n",
    "            # 这里，它对 grad * grad 沿着 tuple(range(1, len(grad.shape))) 指定的维度进行求和。\n",
    "            # ？为什么呢？--- 前面有个unsqueeze？\n",
    "            return torch.sum(grad * grad, dim=tuple(range(1, len(grad.shape))))\n",
    "\n",
    "        # vmap被替换\n",
    "        # 遍历每个数据块\n",
    "        trs,vals = [],[]\n",
    "        for item in tgts: # 对每个维度\n",
    "            trs_ = helper(item,x)\n",
    "            trs.append(trs_) # 每个batch对应一个向量\n",
    "            # print('trs_: ',trs_.shape)\n",
    "        trs= torch.stack(trs) \n",
    "        trs = torch.log(trs+1e-10) # 为了求 f2 logdet\n",
    "        # print('trs: ',trs.shape, trs)\n",
    "\n",
    "        # 对数据，的每个维度的迹求和\n",
    "        tr += trs.sum(dim=0) \n",
    "    print('tr: ',tr)\n",
    "\n",
    "    return tr  # squeeze removes one dimension jvp puts\n",
    "\n",
    "def f2_trace(net,x,device):\n",
    "    tr = calc_tr(net, x, device, sigmas=0.01, subsample=-1, jvp_parallelism=1)\n",
    "    # f2 = torch.log(tr)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect fisher 指标\n",
    "effectFisher_same_layer_list = []\n",
    "Fishermetric = dFILInverseMetric()\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    # print('labels: ',labels)\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    if conv:\n",
    "        print('images: ', images.shape)\n",
    "        images= avg_pool2d(images,kernel_size=4)\n",
    "        print('images_pooled: ',images.shape)\n",
    "    with torch.no_grad():\n",
    "        # inference\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        # fisher\n",
    "        outputs = client_net(images)\n",
    "        # images = images.unsqueeze(0)\n",
    "\n",
    "        # drj实现的fisher 矩阵 \n",
    "        # effectFisher = Fishermetric._computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher10 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 1.0)\n",
    "        effectFisher10 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        print('effectFisher(sigma=1.0): ',effectFisher10)\n",
    "        # effectFisher001 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # print('effectFisher(sigma=0.01): ',effectFisher001)\n",
    "\n",
    "        # meang 实现的fisher trace\n",
    "        # images = images.unsqueeze(0) # ?\n",
    "        # trace = calc_tr(client_net, images, args['device'], sigmas=0.01, subsample=-1, jvp_parallelism=1)\n",
    "        \n",
    "        # f2_trace = f2_trace(client_net, images, args['device'])\n",
    "        # print('f2_trace: ',f2_trace)\n",
    "\n",
    "        # effectFisher_same_layer_list.append(effectFisher)\n",
    "        \n",
    "# print(f\"Layer {split_layer} effecInfo: {sum(effecInfo_same_la yer_list)/len(effecInfo_same_layer_list)}\")\n",
    "# print(f\"effectfisher: {sum(effectFisher_same_layer_list)/len(effectFisher_same_layer_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 effect uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the vector: 133.08425903320312\n"
     ]
    }
   ],
   "source": [
    "# Effect uniform\n",
    "import numpy as np\n",
    "import torch\n",
    "def calculate_effect_normalize(input_vector,interval=2.0):\n",
    "    # 确定每个维度的取值范围\n",
    "    a = torch.tensor(interval)\n",
    "    # 计算每个维度的熵\n",
    "    entropy_per_dimension = torch.log(a)\n",
    "    # 总熵是每个维度的熵的总和\n",
    "    size = input_vector.numel()\n",
    "    total_entropy = size * entropy_per_dimension\n",
    "    return total_entropy\n",
    "\n",
    "# def calculate_effect_normalize_batch(inputs,interval=2.0):\n",
    "#     # batchsize:\n",
    "#     batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "#     total_entropy = 0.0\n",
    "\n",
    "#     for i in range(batch_size):\n",
    "#         input_i = inputs[i].unsqueeze(0)\n",
    "#         total_entropy += calculate_effect_normalize_hetero(input_i)\n",
    "    \n",
    "#     return total_entropy/batch_size\n",
    "\n",
    "\n",
    "def calculate_effect_normalize_hetero(input_vector):\n",
    "    size = input_vector.numel()\n",
    "    input_flattened = input_vector.reshape(-1)\n",
    "    total_entropy_single = 0.0\n",
    "    for i in range(size):\n",
    "        l = 2*torch.min(torch.abs(input_flattened[i]-torch.tensor(-1.0)),torch.abs(input_flattened[i]-torch.tensor(1.0)))\n",
    "        total_entropy_single += torch.log(l+1e-10)\n",
    "    print(f\"entropy for single_input: {total_entropy_single}\")\n",
    "    return total_entropy_single \n",
    "\n",
    "\n",
    "def calculate_effect_normalize_hetero_batch(inputs):\n",
    "    # batchsize:\n",
    "    batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "    total_entropy = 0.0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        input_i = inputs[i].unsqueeze(0)\n",
    "        total_entropy += calculate_effect_normalize_hetero(input_i)\n",
    "    \n",
    "    return total_entropy/batch_size\n",
    "\n",
    "# 示例向量\n",
    "vector = torch.rand(192)\n",
    "entropy = calculate_effect_normalize(vector)\n",
    "print(f\"Entropy of the vector: {entropy}\")\n",
    "\n",
    "# print(type(entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 effect Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect entropy 计算函数\n",
    "import math\n",
    "import numpy as np\n",
    "def shannon_entropy_pyent(time_series): # 这个甚至不适合连续值吧\n",
    "    \"\"\"Calculate Shannon Entropy of the sample data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_series: np.ndarray | list[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ent: float\n",
    "        The Shannon Entropy as float value\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate frequency counts\n",
    "    _, counts = np.unique(time_series, return_counts=True)\n",
    "    total_count = len(time_series)\n",
    "    # print('counts: ', counts)\n",
    "    # print(\"total_count: \",total_count)\n",
    "\n",
    "    # Calculate frequencies and Shannon entropy\n",
    "    frequencies = counts / total_count\n",
    "    # print(\"freq: \",frequencies)\n",
    "    ent = -np.sum(frequencies * np.log(frequencies))\n",
    "\n",
    "    return ent\n",
    "\n",
    "# import infotopo\n",
    "import ppsplit.quantification.shannon_information.infotopo as infotopo\n",
    "from torch.nn.functional import avg_pool2d\n",
    "def shannon_entropy_infotopo(x, conv = False):\n",
    "    information_top = infotopo.infotopo(dimension_max = x.shape[1],\n",
    "                                        dimension_tot = x.shape[1],\n",
    "                                        sample_size = x.shape[0],\n",
    "                                        # nb_of_values = nb_of_values, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        # nb_of_values = 17, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        nb_of_values = 9, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        # forward_computation_mode = True,\n",
    "                                        )\n",
    "    if conv:\n",
    "        images_convol = information_top.convolutional_patchs(x)\n",
    "        print('images_convol: ',images_convol.shape)\n",
    "        x = images_convol\n",
    "\n",
    "    # 计算联合分布的概率？（全排列）\n",
    "    # joint_prob = information_top._compute_probability(x)\n",
    "    # print('joint_prob: ',joint_prob)\n",
    "    \n",
    "    # 计算联合熵（全排列的）\n",
    "    joint_prob_ent = information_top.simplicial_entropies_decomposition(x) # log2\n",
    "    new_joint_prob_ent = {key: value * np.log(2) for key, value in joint_prob_ent.items()} #ln 转2为底 成 e为底\n",
    "    \n",
    "    # print(\"joint_entropy: \",new_joint_prob_ent)\n",
    "    # ent = information_top._compute_forward_entropies(x)\n",
    "    # information_top.entropy_simplicial_lanscape(joint_prob_ent) # 画图\n",
    "    # ent = _entropy(np.array(list(new_joint_prob_ent.values())))\n",
    "\n",
    "    joint_entropy_final = list(new_joint_prob_ent.values())[-1]\n",
    "    return joint_entropy_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([500, 3, 32, 32])\n",
      "images_pooled:  torch.Size([500, 3, 8, 8])\n",
      "effectEntro_ite:  64.05110313624053\n",
      "effectEntro_pyent:  27.621539482380474\n",
      "original data_matrix.shape:  (500, 192)\n",
      "data_matrix_new.shape:  (87840, 169)\n",
      "images_convol:  (87840, 169)\n",
      "data_matrix [[5 6 6 ... 3 3 3]\n",
      " [6 6 6 ... 3 3 2]\n",
      " [6 6 5 ... 3 2 2]\n",
      " ...\n",
      " [5 3 3 ... 7 8 7]\n",
      " [3 3 3 ... 8 7 7]\n",
      " [3 3 3 ... 7 7 7]]\n",
      "Percent of tuples processed : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effectEntro_infotopo:  11.383272256729523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# effective entorpy\n",
    "\n",
    "from pyentrp import entropy as ent\n",
    "\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): \n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    # print(images)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # infotopo # 要给它降维\n",
    "        if conv:\n",
    "            print('images: ', images.shape)\n",
    "            images = avg_pool2d(images,kernel_size=4)\n",
    "            print('images_pooled: ',images.shape)\n",
    "\n",
    "        # ITE\n",
    "        effectEntro = Shannon_quantity(images)\n",
    "        print(\"effectEntro_ite: \",effectEntro)\n",
    "        \n",
    "        # PyEntropy\n",
    "        effectEntro_pyent = 0.0\n",
    "        for i in range(len(images[0])): # 对每个维度\n",
    "            effectEntro_pyent  += shannon_entropy_pyent(images[:,i].flatten().detach().cpu().numpy())\n",
    "            # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "        # effectEntro_pyent = shannon_entropy(images.flatten(start_dim=1).detach().cpu().numpy())\n",
    "        print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "\n",
    "            \n",
    "        images_flattened = images.flatten(start_dim=1).detach().cpu().numpy()\n",
    "        \n",
    "        effectEntro_infotopo = shannon_entropy_infotopo(images_flattened,conv=conv)\n",
    "        print('effectEntro_infotopo: ',effectEntro_infotopo)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 effectInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  103.45039928117214\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1388.1731, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1347.2361, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1399.8623, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.6014, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1478.2726, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1450.1200, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1269.6251, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1453.4626, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1445.1406, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1349.1754, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1480.9639, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1352.7544, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1393.3760, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1274.2625, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.9250, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1360.6301, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1254.9958, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1380.9413, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.6250, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.8275, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1349.8337, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1257.7433, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1519.9888, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1329.3252, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1427.7704, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1395.5933, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1419.3096, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1391.3656, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1320.8235, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1429.0104, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1439.9561, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1474.5011, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1549.4736, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.3479, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1365.6074, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1326.9797, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1494.8911, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1351.1472, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1372.9921, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1346.6129, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1333.5100, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.5696, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1324.4788, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1464.4333, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1401.7335, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1344.8914, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1398.6591, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1398.3142, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1505.9105, device='cuda:0')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1503.3480, device='cuda:0')\n",
      "f2_avg_outer:  tensor(0., device='cuda:0')\n",
      "f2_2_avg_outer:  tensor(1392.2819, device='cuda:0')\n",
      "f1:  tensor(544.8724)\n",
      "entropy for single_input: 61.94700241088867\n",
      "entropy for single_input: -62.6376838684082\n",
      "entropy for single_input: 6.6417236328125\n",
      "entropy for single_input: 21.67644500732422\n",
      "entropy for single_input: 71.8024673461914\n",
      "entropy for single_input: 44.15055847167969\n",
      "entropy for single_input: -58.469913482666016\n",
      "entropy for single_input: 22.89910125732422\n",
      "entropy for single_input: 42.46673583984375\n",
      "entropy for single_input: 18.931921005249023\n",
      "entropy for single_input: 90.44174194335938\n",
      "entropy for single_input: 23.468120574951172\n",
      "entropy for single_input: 20.739238739013672\n",
      "entropy for single_input: -74.74269104003906\n",
      "entropy for single_input: 52.94660568237305\n",
      "entropy for single_input: 59.524925231933594\n",
      "entropy for single_input: -31.053199768066406\n",
      "entropy for single_input: 57.20673370361328\n",
      "entropy for single_input: -124.91277313232422\n",
      "entropy for single_input: 37.727535247802734\n",
      "entropy for single_input: 30.815305709838867\n",
      "entropy for single_input: -271.626708984375\n",
      "entropy for single_input: 30.897855758666992\n",
      "entropy for single_input: 29.198270797729492\n",
      "entropy for single_input: 64.10552978515625\n",
      "entropy for single_input: 55.38964080810547\n",
      "entropy for single_input: 25.836759567260742\n",
      "entropy for single_input: 9.665185928344727\n",
      "entropy for single_input: 30.907602310180664\n",
      "entropy for single_input: 1.8156380653381348\n",
      "entropy for single_input: -33.172672271728516\n",
      "entropy for single_input: 82.1015625\n",
      "entropy for single_input: 94.81236267089844\n",
      "entropy for single_input: -11.352594375610352\n",
      "entropy for single_input: 7.871074199676514\n",
      "entropy for single_input: -12.690299034118652\n",
      "entropy for single_input: 78.72708129882812\n",
      "entropy for single_input: -22.3083438873291\n",
      "entropy for single_input: 43.068077087402344\n",
      "entropy for single_input: 53.928375244140625\n",
      "entropy for single_input: 47.5631103515625\n",
      "entropy for single_input: -72.8056411743164\n",
      "entropy for single_input: -7.874385356903076\n",
      "entropy for single_input: 18.93511962890625\n",
      "entropy for single_input: -20.310945510864258\n",
      "entropy for single_input: 16.46286392211914\n",
      "entropy for single_input: 26.813446044921875\n",
      "entropy for single_input: 62.38965606689453\n",
      "entropy for single_input: 74.93950653076172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy for single_input: 53.111629486083984\n",
      "effecEntro:  103.45039928117214\n",
      "effecFisher:  -423.70474\n",
      "effectUniform:  tensor(15.3594, device='cuda:0')\n",
      "effectUniform_interval:  tensor(133.0843)\n",
      "Layer 2 effecInfo: 409.4302673339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "effecInfo_diff_layer_list = []\n",
    "effecInfo_same_layer_list = []\n",
    "EntropyMetric = ULossMetric()\n",
    "Fishermetric = dFILInverseMetric()\n",
    "\n",
    "\n",
    "InversedFIL_same_layer_list = []\n",
    "NBatch = len(testloader)\n",
    "image_dimension = -1\n",
    "\n",
    "for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "# for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        print('images: ', images.shape)\n",
    "        \n",
    "        if conv:\n",
    "            images= avg_pool2d(images,kernel_size=4)\n",
    "            print('images_pooled: ',images.shape)\n",
    "        if image_dimension ==-1:\n",
    "            image_dimension = images[0].numel()\n",
    "\n",
    "\n",
    "        # effect entropy \n",
    "        # infotopo\n",
    "        # effectEntro = shannon_entropy_infotopo(images.flatten(start_dim=1).detach().cpu().numpy(), conv)\n",
    "        # 自定一的prob entropy\n",
    "        # effecEntro= EntropyMetric._entropy_prob_batch(images) # H(x)\n",
    "\n",
    "        # ITE\n",
    "        effectEntro = Shannon_quantity(images)\n",
    "        print(\"effectEntro_ite: \",effectEntro)\n",
    "\n",
    "        # PyEntropy\n",
    "        # effectEntro_pyent = 0.0\n",
    "        # for i in range(len(images[0])): # 对每个维度\n",
    "        #     effectEntro_pyent  += shannon_entropy_pyent(images[:,i].flatten().detach().cpu().numpy())\n",
    "        #     # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "        # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "\n",
    "        # effect fisher\n",
    "            # inference\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        # inverse_dFIL = Fishermetric.quantify(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01, with_outputs=True)\n",
    "        # effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "\n",
    "        # effect uniform\n",
    "        # one_image = images[0]\n",
    "        # effectUniform = calculate_effect_normalize(one_image.flatten())\n",
    "        effectUniform = calculate_effect_normalize_hetero_batch(images)\n",
    "        # uniform interval\n",
    "        effectUniform_interval = calculate_effect_normalize(images[0]) # 用第一张图片就可\n",
    "\n",
    "\n",
    "        # 存储\n",
    "        # effecInfo_same_layer_list.append(effectEntro-effectFisher)\n",
    "        effectInfo = (effectEntro-effectFisher)-(effectUniform_interval-effectUniform)\n",
    "        effecInfo_same_layer_list.append(effectInfo.detach().cpu().numpy())\n",
    "        # InversedFIL_same_layer_list.append(inverse_dFIL)\n",
    "\n",
    "        # 打印一下\n",
    "        print(\"effecEntro: \", effectEntro)\n",
    "        print(\"effecFisher: \", effectFisher)\n",
    "        print(\"effectUniform: \",effectUniform)\n",
    "        print('effectUniform_interval: ',effectUniform_interval)\n",
    "        # print(\"inverse_dFIL: \",inverse_dFIL)\n",
    "\n",
    "avg_effectInfo = sum(effecInfo_same_layer_list)/len(effecInfo_same_layer_list)\n",
    "avg_d_effectInfo = avg_effectInfo/image_dimension\n",
    "print(f\"Layer {args['split_layer']} effecInfo: {avg_effectInfo}\") # 在多个batch上再求平均，这里有点问题。\n",
    "print(f\"Layer {args['split_layer']} effecInfo_avg_d: {avg_d_effectInfo}\") # 在多个batch上再求平均，这里有点问题。\n",
    "# print(f\"Layer {args['split_layer']} InversedFIL: {sum(InversedFIL_same_layer_list)/len(InversedFIL_same_layer_list)}\")\n",
    "effecInfo_diff_layer_list.append(effecInfo_same_layer_list)\n",
    "\n",
    "# 保存到csv中\n",
    "matrix = np.array(effecInfo_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in split_layer_list]).to_csv(results_dir + f'effecInfo-bs{batch_size}.csv',index=False)\n",
    "save_route = results_dir + f'effecInfo-10000.csv'\n",
    "# if os.path.exists(save_route):\n",
    "#     df = pd.read_csv(save_route)\n",
    "#     df[args['split_layer']] = transpose\n",
    "#     df.to_csv(save_route,index=False)\n",
    "# else:\n",
    "#     pd.DataFrame(data=transpose, columns=[args['split_layer']]).to_csv(save_route,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# x = next(iter(one_data_loader))\n",
    "for i,_ in one_data_loader:\n",
    "        # print(i)\n",
    "        y = scaler.fit_transform(i)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(10,341) # 最大能接受341个特征 \n",
    "z = torch.randn(100,200)\n",
    "e1 = Shannon_quantity(y)\n",
    "e2 = Shannon_quantity(z)\n",
    "print(e1)\n",
    "print(e2)\n",
    "# print(np.log(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataPath = '/home/dengruijun/data/FinTech/DATASET/kaggle-dataset/bank/bank-additional-full.csv'\n",
    "\n",
    "[X_train, y_train], [X_test, y_test] = preprocess_bank_dataset(dataPath)\n",
    "df = pd.DataFrame(X_test)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试diagonal\n",
    "import torch\n",
    "x = torch.randn(6,5)\n",
    "y = torch.diagonal(x)\n",
    "z = torch.diag_embed(y)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.sqrt(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jvp\n",
    "x = torch.randn([2,2], requires_grad=True)\n",
    "f = lambda x: x * torch.tensor([1., 2])\n",
    "value, grad = jvp(f, (x,), (torch.tensor([[1,1],[1,0]]),))\n",
    "print(value)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改一下 resnet的 模型参数的key\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "import torch\n",
    "\n",
    "unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/CIFAR10-models/ResNet18/32bs-ep20-relu-max-adam/resnet18-drj.pth' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "from target_model.task_select import *\n",
    "client_net = resnet18(pretrained=False, split_layer=13, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "pweights = torch.load(unit_net_route)\n",
    "cweights = client_net.state_dict()\n",
    "\n",
    "print(len(pweights.keys()),pweights.keys())\n",
    "print(len(cweights.keys()),cweights.keys())\n",
    "\n",
    "\n",
    "# new_key = {}\n",
    "for keyp,keyc in zip(pweights.keys(),cweights.keys()):\n",
    "    print(keyp,'\\t\\t\\t',keyc)\n",
    "\n",
    "for i,key in enumerate(pweights.keys()):\n",
    "    if i<122:\n",
    "        continue\n",
    "    print(key)\n",
    "\n",
    "    # new_key[key.replace('model.','')] = pweights[key]\n",
    "\n",
    "new_key = {}\n",
    "for key in cweights.keys():\n",
    "    new_key[key] = pweights[key.replace('selected_layers','model.layers')]\n",
    "torch.save(new_key,'/home/dengruijun/data/FinTech/PP-Split/results/trained_models/CIFAR10-models/ResNet18/32bs-ep20-relu-max-adam/resnet18-drj-small.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "x = torch.tensor([3.0,4.0])\n",
    "x = x.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
