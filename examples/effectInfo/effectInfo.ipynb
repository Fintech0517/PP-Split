{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 基础设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": ['--noise_scale', type=float,
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Ruijun Deng\n",
    "Date: 2024-08-14 16:59:47\n",
    "LastEditTime: 2024-08-25 00:47:50\n",
    "LastEditors: Ruijun Deng\n",
    "FilePath: /PP-Split/examples/effectInfo/effectInfo.ipynb\n",
    "Description: \n",
    "'''\n",
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch.nn.functional import avg_pool2d\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "from ppsplit.quantification.distance_correlation.distCor import distCorMetric\n",
    "from ppsplit.quantification.fisher_information.dFIL_inverse import dFILInverseMetric\n",
    "from ppsplit.quantification.shannon_information.mutual_information import MuInfoMetric\n",
    "from ppsplit.quantification.shannon_information.ULoss import ULossMetric\n",
    "from ppsplit.quantification.rep_reading.rep_reader import PCA_Reader\n",
    "from ppsplit.quantification.shannon_information.ITE_tools import Shannon_quantity\n",
    "\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader_and_model, \\\n",
    "    get_dataloader,get_models,get_infotopo_para\n",
    "\n",
    "# utils\n",
    "from ppsplit.utils.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "{'device': device(type='cuda', index=1), 'dataset': 'CIFAR10', 'model': 'ViTb_16', 'result_dir': '20240702-effectiveInfo/', 'oneData_bs': 50, 'test_bs': 50, 'train_bs': 50, 'noise_scale': 0, 'split_layer': 1, 'test_num': 'effectiveInfo1.10', 'no_dense': True, 'ep': -1}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# nohup python -u effectInfo1.8.py > ../../results/20240702-effectiveInfo/Resnet18/effectiveInfo1.8/effectInfo1.8-pool4-layer11-gpu.log 2>&1 &\n",
    "# nohup python -u effectInfo1.8.py > ../../results/20240702-effectiveInfo/VGG5/effectiveInfo1.8/effectInfo1.8-pool4-layer6-gpu.log 2>&1 &\n",
    "\n",
    "# parser\n",
    "# parser = argparse.ArgumentParser(description='PP-Split')\n",
    "# parser.add_argument('--device', type=str, default=\"cuda:0\", help='device')\n",
    "# parser.add_argument('--dataset', type=str, default=\"CIFAR10\", help='dataset') # 'bank', 'credit', 'purchase', 'Iris',\n",
    "# parser.add_argument('--model', type=str, default=\"ResNet18\", help='model')  # 'ResNet18'\n",
    "# parser.add_argument('--result_dir', type=str, default=\"20240702-effectiveInfo/\", help='result_dir')\n",
    "# parser.add_argument('--oneData_bs', type=int, default=1, help='oneData_bs')\n",
    "# parser.add_argument('--test_bs', type=int, default=500, help='test_bs')\n",
    "# parser.add_argument('--train_bs', type=int, default=1, help='train_bs')\n",
    "# parser.add_argument('--noise_scale', type=int, default=0, help='noise_scale')\n",
    "# parser.add_argument('--split_layer', type=int, default=2, help='split_layer')\n",
    "# parser.add_argument('--test_num', type=str, default='effectiveInfo1.8', help='test_num')\n",
    "# parser.add_argument('--no_dense', action='store_true', help='no_dense')\n",
    "\n",
    "\n",
    "# args_python = parser.parse_args()\n",
    "# args = vars(args_python)\n",
    "\n",
    "args = {\n",
    "        'device':torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        # 'device':torch.device(\"cpu\"),\n",
    "        # 'dataset':'bank',\n",
    "        # 'dataset':'credit',\n",
    "        # 'dataset':'purchase',\n",
    "        # 'dataset':'Iris',\n",
    "        'dataset':'CIFAR10',\n",
    "        # 'dataset':'CIFAR100',\n",
    "        # 'dataset':'ImageNet1k',\n",
    "        # 'dataset':'MNIST',\n",
    "        # 'model': 'ResNet18',\n",
    "        # 'model': 'VGG5',\n",
    "        'model': 'ViTb_16',\n",
    "        # 'result_dir': '20240702-FIL/',\n",
    "        'result_dir': '20240702-effectiveInfo/',\n",
    "        'oneData_bs': 50,\n",
    "        'test_bs': 50,\n",
    "        'train_bs': 50,\n",
    "        'noise_scale': 0, # 防护措施\n",
    "        'split_layer': 1,\n",
    "        # 'test_num': 'invdFIL', # MI, invdFIL, distCor, ULoss,  # split layer [2,3,5,7,9,11] for ResNet18\n",
    "        'test_num': 'effectiveInfo1.10',\n",
    "        'no_dense': True,\n",
    "        'ep':-1, # 模型训练的epoch -1为默认\n",
    "        }\n",
    "print(args['device'])\n",
    "print(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_token\n",
      "conv_proj.weight\n",
      "conv_proj.bias\n",
      "encoder.pos_embedding\n",
      "encoder.layers.encoder_layer_0.ln_1.weight\n",
      "encoder.layers.encoder_layer_0.ln_1.bias\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_0.ln_2.weight\n",
      "encoder.layers.encoder_layer_0.ln_2.bias\n",
      "encoder.layers.encoder_layer_0.mlp.0.weight\n",
      "encoder.layers.encoder_layer_0.mlp.0.bias\n",
      "encoder.layers.encoder_layer_0.mlp.3.weight\n",
      "encoder.layers.encoder_layer_0.mlp.3.bias\n",
      "train decoder model...\n",
      "unit_net_route: /home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-c867db91-drj.pth\n",
      "infotopo: nb_of_values:  36\n",
      "results_dir: ../../results/20240702-effectiveInfo//ViTb_16/effectiveInfo1.10/\n",
      "inverse_dir: ../../results/20240702-effectiveInfo//ViTb_16/effectiveInfo1.10/layer1/\n",
      "decoder_route: ../../results/20240702-effectiveInfo//ViTb_16/effectiveInfo1.10//Decoder-layer1.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)\n",
    "infotopo_msg = get_infotopo_para(args)\n",
    "msg = {**model_msg,**data_msg,**infotopo_msg}\n",
    "\n",
    "# 数据集\n",
    "one_data_loader,trainloader,testloader = data_msg['one_data_loader'],data_msg['trainloader'], data_msg['testloader']\n",
    "data_interval = data_msg['data_interval']\n",
    "data_type = msg['data_type']\n",
    "\n",
    "# effectEntropy Infotopo参数\n",
    "nb_of_values = msg['nb_of_values']\n",
    "\n",
    "conv = msg['conv']\n",
    "pool_size = msg['pool_size']\n",
    "# conv = False\n",
    "print(\"infotopo: nb_of_values: \",nb_of_values)\n",
    "\n",
    "# 模型\n",
    "client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "decoder_route = model_msg['decoder_route']\n",
    "image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "# 路径\n",
    "results_dir = model_msg['results_dir']\n",
    "inverse_dir = results_dir + 'layer' + str(args['split_layer'])+'/'\n",
    "# data_type = 1 if args['dataset'] == 'CIFAR10' else 0\n",
    "split_layer = args['split_layer']\n",
    "\n",
    "print('results_dir:', results_dir)\n",
    "print('inverse_dir:', inverse_dir)\n",
    "print('decoder_route:', decoder_route)\n",
    "\n",
    "create_dir(results_dir)\n",
    "\n",
    "# client_net使用\n",
    "client_net = client_net.to(args['device'])\n",
    "client_net.eval()\n",
    "\n",
    "# for n, p in client_net.named_parameters():\n",
    "#     print(n, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. effective information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 effect Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effective fisher 计算函数\n",
    "import torch.autograd.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# nips23\n",
    "from torch.autograd.functional import jvp\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 自己实现的、规规矩矩的 jacobian + logdet 全部用torch的函数\n",
    "def computing_det_with_outputs(model, inputs, outputs, sigmas): # sigma_square\n",
    "        # batchsize:\n",
    "        batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "        output_size = outputs[0].numel() # 一个样本的outputs长度\n",
    "        input_size = inputs[0].numel() # 一个样本的outputs长度\n",
    "        effect_fisher_sum = 0.0\n",
    "\n",
    "        # 遍历单个样本: 换数据\n",
    "        for i in range(batch_size):\n",
    "            input_i = inputs[i].unsqueeze(0)\n",
    "\n",
    "            # 计算jacobian\n",
    "            J = F.jacobian(model, input_i)\n",
    "            # J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\n",
    "            J = J.reshape(output_size, input_size) # (batch, out_size, in_size)\n",
    "            # print(f\"J2.shape: {J.shape}, J2.prod: {torch.prod(torch.tensor(list(J.shape)))}\")\n",
    "            # 计算eta\n",
    "            JtJ = torch.matmul(J.t(), J)\n",
    "            I = 1.0/(sigmas)*JtJ\n",
    "            # ddFIL  = I.trace().div(input_size*input_size)\n",
    "\n",
    "            # 储存I\n",
    "            # I_np = I.cpu().detach().numpy()\n",
    "            # df = pd.DataFrame(I_np)\n",
    "            # df.to_csv(f'{i}.csv',index=False,header=False)\n",
    "\n",
    "            # print(\"I: \", I)\n",
    "            # w = torch.det(I)\n",
    "            # print('det I: ', I.det().log())\n",
    "\n",
    "            f1 = input_size * torch.log(2*torch.pi*torch.exp(torch.tensor(1.0)))\n",
    "            f2 = torch.logdet(I)\n",
    "            # print('log det I: ',f2 )\n",
    "            print('f1: ' ,f1)\n",
    "            print('f2: ' ,f2)\n",
    "            effect_fisher = 0.5 * (f1 - f2)\n",
    "            effect_fisher_sum += effect_fisher\n",
    "\n",
    "            print(\"effect_fisher: \" , effect_fisher)\n",
    "\n",
    "        # print(\"Jt*J: \", JtJ)\n",
    "        # print(\"Jt*J: \", JtJ.shape, JtJ)\n",
    "        # print(\"I.shape: \", I.shape)\n",
    "        # eta = dFIL\n",
    "        # print(f\"eta: {eta}\")\n",
    "        # print('t2-t1=',t2-t1, 't3-t2', t3-t2)\n",
    "        effect_fisher_mean = effect_fisher_sum / batch_size\n",
    "        return effect_fisher_mean.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# 用diag 来化简\n",
    "def computing_diag_det_with_outputs(model, inputs, outputs, sigmas=1.0): # sigma_square\n",
    "    # batchsize:\n",
    "    batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "    output_size = outputs[0].numel() # 一个样本的outputs长度\n",
    "    input_size = inputs[0].numel() # 一个样本的outputs长度\n",
    "    effect_fisher_sum = 0.0\n",
    "\n",
    "    # avg\n",
    "    I_diagonal_batch_avg = torch.zeros(input_size).to(args['device']) # batch上做平均\n",
    "    print(\"I_diagonal_batch_avg: \",I_diagonal_batch_avg.shape)\n",
    "    f2_2_avg_outer = torch.tensor(0.0).to(args['device'])\n",
    "    f2_avg_outer = torch.tensor(0.0).to(args['device'])\n",
    "    \n",
    "    # effecti_fisher第一部分\n",
    "    f1 = input_size * torch.log(2*torch.pi*torch.exp(torch.tensor(1.0)))\n",
    "\n",
    "    # f2需要求平均？\n",
    "    # 遍历单个样本: 换数据\n",
    "    for i in range(batch_size): # 对每个样本\n",
    "        input_i = inputs[i].unsqueeze(0)\n",
    "\n",
    "        # 计算jacobian\n",
    "        J = F.jacobian(model, input_i)\n",
    "        # J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\n",
    "        J = J.reshape(output_size, input_size) # (batch, out_size, in_size)\n",
    "        # print(f\"J2.shape: {J.shape}, J2.prod: {torch.prod(torch.tensor(list(J.shape)))}\")\n",
    "        # 计算eta\n",
    "        JtJ = torch.matmul(J.t(), J)\n",
    "        I = 1.0/(sigmas)*JtJ\n",
    "\n",
    "        # I = JtJ\n",
    "        # print(\"I: \", I)\n",
    "        # diagonal fisher information matrix (approximation)\n",
    "        I_diagonal = torch.diagonal(I,dim1=0,dim2=1) # vector\n",
    "        # print(\"I_diagonal: \",I_diagonal.shape)\n",
    "\n",
    "        I_diag = torch.diag_embed(I_diagonal) # matrix\n",
    "        # print('drj trace: ',torch.trace(I_diag))\n",
    "        \n",
    "        # batch的平均\n",
    "        I_diagonal_batch_avg += I_diagonal / (batch_size)\n",
    "\n",
    "        # # 储存I\n",
    "        # I_np = I.cpu().detach().numpy()\n",
    "        # df = pd.DataFrame(I_np)\n",
    "        # df.to_csv(f'{i}.csv',index=False,header=False)\n",
    "\n",
    "        # print(\"I: \", I)\n",
    "        # w = torch.det(I)\n",
    "        # print('det I: ', I.det().log())\n",
    "        \n",
    "        try:\n",
    "            s,f2 = torch.slogdet(I) # 直接用torch计算\n",
    "            # print('s: ',s)\n",
    "            if s <= 0:\n",
    "                # print('s=',s)\n",
    "                raise RuntimeError(\"sign <=0 \")\n",
    "            print('f2: ', f2)\n",
    "        except RuntimeError as e:\n",
    "            print(\"logdet计算报错\")\n",
    "        # f2_1 = torch.logdet(I_diag) # 和后面的是一样的\n",
    "        f2_2 = torch.sum(torch.log(I_diagonal+1e-10)) # /I_diagonal.numel() # diagonal后计算\n",
    "\n",
    "        f2_2_avg_outer += f2_2 / batch_size\n",
    "        # f2_avg_outer += f2 / batch_size\n",
    "\n",
    "        # print('log det I: ', f2)\n",
    "        # print('f1: ' , f1)\n",
    "        # print('f2: ', f2)\n",
    "        # print('f2_1: ', f2_1)\n",
    "        print('f2_2: ', f2_2)\n",
    "\n",
    "    f2_2_avg_inner = torch.sum(torch.log(I_diagonal_batch_avg+1e-10)) # 用平均后的diagonal 计算\n",
    "\n",
    "    print('f2_avg_outer: ',f2_avg_outer)\n",
    "    print('f2_2_avg_outer: ',f2_2_avg_outer)\n",
    "    # print('f2_2_avg_inner: ',f2_2_avg_inner)\n",
    "    print('f1: ',f1)\n",
    "\n",
    "    # effect_fisher = 0.5 * (f1 - f2_2_avg_inner)\n",
    "    effect_fisher = 0.5 * (f1 - f2_2_avg_outer)\n",
    "    # effect_fisher = 0.5 * (f1 - f2_avg_outer)\n",
    "    # effect_fisher_sum+=effect_fisher\n",
    "\n",
    "    # print(\"effect_fisher: \",effect_fisher)\n",
    "    \n",
    "    # effect_fisher_mean = effect_fisher_sum / batch_size\n",
    "    return effect_fisher.cpu().detach().numpy()\n",
    "\n",
    "# arxiv'21 迁移学习领域的log det fisher 计算\n",
    "\n",
    "# nips'23 fisher trace 计算\n",
    "def calc_tr(net, x, device, sigmas=0.01, subsample=-1, jvp_parallelism=1): # nips'23 源码\n",
    "    # 并行粒度=1 意思是，每次只处理一个维度\n",
    "\n",
    "    print(f'x.shape: {x.shape}')\n",
    "    \n",
    "    # 定义一个局部函数 jvp_func**：这个函数接受两个参数 x 和 tgt，并返回 net.forward_first 方法的雅可比向量积（JVP）。\n",
    "    # 这意味着 jvp_func 用于计算网络对于输入 x 在方向 tgt 上的一阶导数\n",
    "    # tgt 计算雅各比向量积的向量\n",
    "    def jvp_func(x, tgt): \n",
    "        # return jvp(net.forward_first, (x,), (tgt,)) #返回 outputs, jacobian product\n",
    "        return jvp(net.forward, (x,), (tgt,)) #返回 outputs, jacobian product\n",
    "\n",
    "    # 获取一个batch中第一个数据的维度？d代表的是批次中第一个数据点展平后的特征数量，即输入数据的维度。\n",
    "    d = x[0].flatten().shape[0] # 把一个batch的x展平，获取input dim\n",
    "\n",
    "    # 用于存储每个输入数据点的迹，求迹的和。\n",
    "    tr = torch.zeros(x.shape[0], dtype=x.dtype).to(device)\n",
    "    print(f'tr.shape: {tr.shape}')\n",
    "\n",
    "    samples = range(d)\n",
    "\n",
    "    for j in range(math.ceil(d)): # 对于每个数据块 # 每个数据块包含不同的维度\n",
    "        tgts = []\n",
    "\n",
    "        # 遍历每个数据块中的每个维度\n",
    "        '''\n",
    "        在这个函数中，tgt 是用于计算雅可比向量积（JVP）的向量。具体来说，tgt 的作用如下：\n",
    "        构建雅可比向量积的向量：tgt 是一个与输入 x 形状相同的张量，但它的元素大部分为零，只有一个特定位置的元素为 1。这个特定位置对应于我们在计算迹时关注的特征维度。\n",
    "        计算 JVP：在 helper 函数中，tgt 被传递给 jvp_func，用于计算网络对于输入 x 在方向 tgt 上的一阶导数。具体来说，jvp_func 计算的是网络输出相对于输入 x 的雅可比矩阵与 tgt 的乘积。\n",
    "        估计迹：通过在不同的特征维度上重复上述过程，可以估计网络对于输入数据的迹。迹的计算涉及到对所有特征维度的导数进行求和，而 tgt 的作用就是在每次计算时只关注一个特征维度。\n",
    "        简而言之，tgt 是一个用于选择特定特征维度的向量，通过它可以逐个计算每个特征维度的导数，从而最终估计整个输入数据的迹。\n",
    "        '''\n",
    "        # 对于每一列，构建tgt， 形状和x一样，但是只有一列是1，其他是0\n",
    "        for k in samples[j:(j+1)]: # 提取整个batch中每个数据的特定维度\n",
    "            tgt = torch.zeros_like(x).reshape(x.shape[0], -1) # 按照batch 排列？# 雅各比向量积的\n",
    "            # 除了当前样本索引 k 对应的元素设置为 1。这相当于在计算迹时，每次只关注一个特征维度。\n",
    "            tgt[:, k] = 1. # 提取tgt所有的样本的k的特征 计算雅各比向量积的向量，可用于计算trace，所有行的特定几列有1值\n",
    "            tgt = tgt.reshape(x.shape) # 又变回x的形状\n",
    "            # print(f'tgt.shape: {tgt.shape}')\n",
    "            tgts.append(tgt) \n",
    "        tgts = torch.stack(tgts) # 把多个维度的tgt vstack，一行一行拼接起来，一行是一个维度。\n",
    "\n",
    "\n",
    "        # 定义一个辅助函数 helper，该函数接受一个目标张量 tgt并返回一个迹的张量和一个值的张量。\n",
    "        # jvp wrapper，遍历每个batchsize\n",
    "        def helper(tgt,x=x): # x是一个batch的数据\n",
    "            batch_size = x.shape[0]\n",
    "            grads_list = []\n",
    "            for i in range(batch_size): # 对每个样本\n",
    "                _, grad = jvp_func(x[i].unsqueeze(0), tgt[i].unsqueeze(0))  # 对每个批次元素调用jvp_func\n",
    "                grads_list.append(grad)\n",
    "            # 将结果列表转换为张量, 多个batch的给stack起来\n",
    "            grad = torch.stack(grads_list)\n",
    "\n",
    "            # print('grad.shape: ',grad.shape)\n",
    "            # print('grad: ',grad)\n",
    "\n",
    "            # grad.reshape(sum(list(x.shape)),-1)\n",
    "            # I_np = grad.cpu().detach().numpy()\n",
    "            # df = pd.DataFrame(I_np)\n",
    "            # df.to_csv(f'{time.time()}.csv',index=False,header=False)\n",
    "\n",
    "            # print('grad*grad: ',grad*grad)\n",
    "            # vals, grad = vmap(jvp_func, randomness='same')(x, tgt)\n",
    "            \n",
    "            # print('grad shape: ', grad.shape)\n",
    "            # 因此，矩阵平方的迹和迹的平方通常是不相等的。\n",
    "            # 先求平方再求迹\n",
    "            # range(1, len(grad.shape)) 生成一个从 1 到 len(grad.shape) - 1 的整数序列。\n",
    "            # torch.sum 函数对张量的指定维度进行求和。\n",
    "            # 这里，它对 grad * grad 沿着 tuple(range(1, len(grad.shape))) 指定的维度进行求和。\n",
    "            # ？为什么呢？--- 前面有个unsqueeze？\n",
    "            return torch.sum(grad * grad, dim=tuple(range(1, len(grad.shape))))\n",
    "\n",
    "        # vmap被替换\n",
    "        # 遍历每个数据块\n",
    "        trs,vals = [],[]\n",
    "        for item in tgts: # 对每个维度\n",
    "            trs_ = helper(item,x)\n",
    "            trs.append(trs_) # 每个batch对应一个向量\n",
    "            # print('trs_: ',trs_.shape)\n",
    "        trs= torch.stack(trs) \n",
    "        trs = torch.log(trs+1e-10) # 为了求 f2 logdet\n",
    "        # print('trs: ',trs.shape, trs)\n",
    "\n",
    "        # 对数据，的每个维度的迹求和\n",
    "        tr += trs.sum(dim=0) \n",
    "    print('tr: ',tr)\n",
    "\n",
    "    return tr  # squeeze removes one dimension jvp puts\n",
    "\n",
    "def f2_trace(net,x,device):\n",
    "    tr = calc_tr(net, x, device, sigmas=0.01, subsample=-1, jvp_parallelism=1)\n",
    "    # f2 = torch.log(tr)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1439.8617, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1315.6509, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1351.5675, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.5345, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1481.0920, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1399.8950, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1308.3562, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1374.8175, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1403.0698, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.1267, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m client_net(images)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# images = images.unsqueeze(0)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# drj实现的fisher 矩阵 \u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# effectFisher = Fishermetric._computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m# effectFisher10 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 1.0)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         effectFisher10 \u001b[38;5;241m=\u001b[39m \u001b[43mcomputing_diag_det_with_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meffectFisher(sigma=1.0): \u001b[39m\u001b[38;5;124m'\u001b[39m,effectFisher10)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# effectFisher001 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# print('effectFisher(sigma=0.01): ',effectFisher001)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(f\"Layer {split_layer} effecInfo: {sum(effecInfo_same_la yer_list)/len(effecInfo_same_layer_list)}\")\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(f\"effectfisher: {sum(effectFisher_same_layer_list)/len(effectFisher_same_layer_list)}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 89\u001b[0m, in \u001b[0;36mcomputing_diag_det_with_outputs\u001b[0;34m(model, inputs, outputs, sigmas)\u001b[0m\n\u001b[1;32m     86\u001b[0m input_i \u001b[38;5;241m=\u001b[39m inputs[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# 计算jacobian\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m J \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m J \u001b[38;5;241m=\u001b[39m J\u001b[38;5;241m.\u001b[39mreshape(output_size, input_size) \u001b[38;5;66;03m# (batch, out_size, in_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/functional.py:670\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    668\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 670\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# effect fisher 指标\n",
    "effectFisher_same_layer_list = []\n",
    "Fishermetric = dFILInverseMetric()\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    # print('labels: ',labels)\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    if conv:\n",
    "        print('images: ', images.shape)\n",
    "        images= avg_pool2d(images,kernel_size=4)\n",
    "        print('images_pooled: ',images.shape)\n",
    "    with torch.no_grad():\n",
    "        # inference\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        # fisher\n",
    "        outputs = client_net(images)\n",
    "        # images = images.unsqueeze(0)\n",
    "\n",
    "        # drj实现的fisher 矩阵 \n",
    "        # effectFisher = Fishermetric._computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher10 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 1.0)\n",
    "        effectFisher10 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        print('effectFisher(sigma=1.0): ',effectFisher10)\n",
    "        # effectFisher001 = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # print('effectFisher(sigma=0.01): ',effectFisher001)\n",
    "\n",
    "        # meang 实现的fisher trace\n",
    "        # images = images.unsqueeze(0) # ?\n",
    "        # trace = calc_tr(client_net, images, args['device'], sigmas=0.01, subsample=-1, jvp_parallelism=1)\n",
    "        \n",
    "        # f2_trace = f2_trace(client_net, images, args['device'])\n",
    "        # print('f2_trace: ',f2_trace)\n",
    "\n",
    "        # effectFisher_same_layer_list.append(effectFisher)\n",
    "        \n",
    "# print(f\"Layer {split_layer} effecInfo: {sum(effecInfo_same_la yer_list)/len(effecInfo_same_layer_list)}\")\n",
    "# print(f\"effectfisher: {sum(effectFisher_same_layer_list)/len(effectFisher_same_layer_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 effect uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect uniform\n",
    "import numpy as np\n",
    "import torch\n",
    "def calculate_effect_normalize(input_vector,interval=(-1.0,1.0)):\n",
    "    interval_len = interval[1] - interval[0]\n",
    "    # 确定每个维度的取值范围\n",
    "    a = torch.tensor(interval_len)\n",
    "    # 计算每个维度的熵\n",
    "    entropy_per_dimension = torch.log(a)\n",
    "    # 总熵是每个维度的熵的总和\n",
    "    size = input_vector.numel()\n",
    "    total_entropy = size * entropy_per_dimension\n",
    "    return total_entropy\n",
    "\n",
    "\n",
    "def calculate_effect_normalize_hetero(input_vector, interval=(1.0,-1.0)):\n",
    "    size = input_vector.numel()\n",
    "    input_flattened = input_vector.reshape(-1)\n",
    "    total_entropy_single = 0.0\n",
    "    for i in range(size):\n",
    "        l = 2*torch.min(torch.abs(input_flattened[i]-torch.tensor(interval[0])),torch.abs(input_flattened[i]-torch.tensor(interval[1])))\n",
    "        total_entropy_single += torch.log(l+1e-10)\n",
    "    print(f\"entropy for single_input: {total_entropy_single}\")\n",
    "    return total_entropy_single \n",
    "\n",
    "\n",
    "def calculate_effect_normalize_hetero_batch(inputs, interval=(1.0,-1.0)):\n",
    "    # batchsize:\n",
    "    batch_size = inputs.shape[0] # 一个batch的样本数目\n",
    "    total_entropy = 0.0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        input_i = inputs[i].unsqueeze(0)\n",
    "        total_entropy += calculate_effect_normalize_hetero(input_i,interval)\n",
    "    \n",
    "    return total_entropy/batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the vector: 133.08425903320312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:07,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  0.5307220055446628\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  -0.36959668722377237\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  -1.6322382648857265\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:00<00:01, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_uniform:  -0.08137810630394884\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  -0.7958895935398956\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  0.9911364204255521\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  1.039590805942249\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  -0.322162950307187\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:00<00:00, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_uniform:  0.9130385771440176\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  -0.20347967615868295\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  5.836882633409921\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  4.932353812711511\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:01<00:00, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_uniform:  12.027754638428217\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  7.1660707592530395\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  4.57655477977397\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  17.345336939816814\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_uniform:  5.483021618031466\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  10.973681848155827\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  14.328853469472108\n",
      "images:  torch.Size([500, 1, 28, 28])\n",
      "images_pooled:  torch.Size([500, 1, 14, 14])\n",
      "effect_uniform:  1.3049746706535514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_effect_uniform: 4.202261385017184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 示例向量\n",
    "# vector = torch.rand(192)\n",
    "# entropy = calculate_effect_normalize(vector)\n",
    "# print(f\"Entropy of the vector: {entropy}\")\n",
    "\n",
    "# print(type(entropy))\n",
    "from ppsplit.quantification.shannon_information.mutual_information import MuInfoMetric\n",
    "\n",
    "metric = MuInfoMetric()\n",
    "def compute_muInfo_with_uniform(x,interval=(-1.0,1.0)):\n",
    "    a,b = interval\n",
    "    interval_len = b - a\n",
    "\n",
    "    uniform_matrix = interval_len*torch.rand_like(x) + a\n",
    "    x = x.detach().cpu()\n",
    "    uniform_matrix = uniform_matrix.detach().cpu()\n",
    "\n",
    "    mutual_info = metric.quantify(inputs=x, outputs = uniform_matrix)\n",
    "    return mutual_info\n",
    "\n",
    "# effective entorpy\n",
    "\n",
    "from pyentrp import entropy as ent\n",
    "\n",
    "avg_effect_uniform = 0.0\n",
    "# for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "for j, data in enumerate(tqdm.tqdm(testloader)): \n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    # print(images)\n",
    "    with torch.no_grad():\n",
    "        # # 要给它降维\n",
    "        print('images: ', images.shape)\n",
    "        if conv:\n",
    "            images = avg_pool2d(images,kernel_size=pool_size)\n",
    "            print('images_pooled: ',images.shape)\n",
    "\n",
    "\n",
    "        # muinfo with uniform\n",
    "        muinfo = compute_muInfo_with_uniform(images)\n",
    "        print('effect_uniform: ',muinfo)\n",
    "        \n",
    "        avg_effect_uniform += muinfo\n",
    "\n",
    "avg_effect_uniform = avg_effect_uniform / len(testloader)\n",
    "print(f\"avg_effect_uniform: {avg_effect_uniform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 effect Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect entropy 计算函数\n",
    "import math\n",
    "import numpy as np\n",
    "def shannon_entropy_pyent(time_series): # 这个甚至不适合连续值吧\n",
    "    \"\"\"Calculate Shannon Entropy of the sample data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_series: np.ndarray | list[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ent: float\n",
    "        The Shannon Entropy as float value\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate frequency counts\n",
    "    _, counts = np.unique(time_series, return_counts=True)\n",
    "    total_count = len(time_series)\n",
    "    # print('counts: ', counts)\n",
    "    # print(\"total_count: \",total_count)\n",
    "\n",
    "    # Calculate frequencies and Shannon entropy\n",
    "    frequencies = counts / total_count\n",
    "    # print(\"freq: \",frequencies)\n",
    "    ent = -np.sum(frequencies * np.log(frequencies))\n",
    "\n",
    "    return ent\n",
    "\n",
    "# import infotopo\n",
    "import ppsplit.quantification.shannon_information.infotopo as infotopo\n",
    "from torch.nn.functional import avg_pool2d\n",
    "def shannon_entropy_infotopo(x, conv = False):\n",
    "    information_top = infotopo.infotopo(dimension_max = x.shape[1],\n",
    "                                        dimension_tot = x.shape[1],\n",
    "                                        sample_size = x.shape[0],\n",
    "                                        nb_of_values = nb_of_values, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        # nb_of_values = 17, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        # nb_of_values = 2, # 不是很懂这个意思，为什么iris对应9？\n",
    "                                        # forward_computation_mode = True,\n",
    "                                        )\n",
    "    if conv:\n",
    "        images_convol = information_top.convolutional_patchs(x)\n",
    "        print('images_convol: ',images_convol.shape)\n",
    "        x = images_convol\n",
    "\n",
    "    # 计算联合分布的概率？（全排列）\n",
    "    # joint_prob = information_top._compute_probability(x)\n",
    "    # print('joint_prob: ',joint_prob)\n",
    "    \n",
    "    # 计算联合熵（全排列的）\n",
    "    joint_prob_ent = information_top.simplicial_entropies_decomposition(x) # log2\n",
    "    new_joint_prob_ent = {key: value * np.log(2) for key, value in joint_prob_ent.items()} #ln 转2为底 成 e为底\n",
    "    \n",
    "    # print(\"joint_entropy: \",new_joint_prob_ent)\n",
    "    # ent = information_top._compute_forward_entropies(x)\n",
    "    # information_top.entropy_simplicial_lanscape(joint_prob_ent) # 画图\n",
    "    # ent = _entropy(np.array(list(new_joint_prob_ent.values())))\n",
    "\n",
    "    joint_entropy_final = list(new_joint_prob_ent.values())[-1]\n",
    "    return joint_entropy_final\n",
    "\n",
    "\n",
    "\n",
    "# approximation entropy: 参考 sec24，用高斯分布近似\n",
    "def shannon_entropy_approximation(images):\n",
    "    images_flat = images.view(images.size(0), -1)\n",
    "    # 计算均值和方差\n",
    "    mean = torch.mean(images_flat, dim=0)\n",
    "    covariance_matrix = torch.cov(images_flat.T)\n",
    "\n",
    "    n = covariance_matrix.size(0)\n",
    "    # det_cov = torch.det(covariance_matrix)\n",
    "    # 计算熵\n",
    "    print('covariance_matrix: ',covariance_matrix)\n",
    "\n",
    "    # try:\n",
    "    #     s,f2 = torch.slogdet(covariance_matrix) # 直接用torch计算\n",
    "    #     # print('s: ',s)\n",
    "    #     if s <= 0:\n",
    "    #         # print('s=',s)\n",
    "    #         raise RuntimeError(\"sign <=0 \")\n",
    "    #     print('input entropy approximation f2 : ', f2)\n",
    "    # except RuntimeError as e:\n",
    "    #     print(\"logdet计算报错\")\n",
    "    #     raise e\n",
    "\n",
    "    determinant = torch.det(covariance_matrix)\n",
    "    print('determinant: ',determinant)\n",
    "    \n",
    "    entropy = 0.5 * (n * (np.log(2 * np.pi * np.e)) + torch.log(determinant))\n",
    "    # entropy = 0.5 * (n * (np.log(2 * np.pi * np.e)) + torch.logdet(covariance_matrix))\n",
    "    # entropy = 0.5 * (n * (np.log(2 * np.pi * np.e)) + f2)\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"均值: {mean.mean().item()}\")\n",
    "    print(f\"协方差矩阵的行列式: {torch.det(covariance_matrix).item()}\")\n",
    "    print(f\"熵: {entropy.item()}\")\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([10000, 3, 32, 32])\n",
      "images_pooled:  torch.Size([10000, 3, 8, 8])\n",
      "covariance_matrix:  tensor([[0.2860, 0.2550, 0.2292,  ..., 0.0516, 0.0620, 0.0775],\n",
      "        [0.2550, 0.2649, 0.2410,  ..., 0.0483, 0.0576, 0.0706],\n",
      "        [0.2292, 0.2410, 0.2562,  ..., 0.0475, 0.0553, 0.0670],\n",
      "        ...,\n",
      "        [0.0516, 0.0483, 0.0475,  ..., 0.2045, 0.1888, 0.1715],\n",
      "        [0.0620, 0.0576, 0.0553,  ..., 0.1888, 0.2141, 0.2013],\n",
      "        [0.0775, 0.0706, 0.0670,  ..., 0.1715, 0.2013, 0.2274]])\n",
      "determinant:  tensor(0.)\n",
      "均值: -0.04683014377951622\n",
      "协方差矩阵的行列式: 0.0\n",
      "熵: -inf\n",
      "effectEntro_approx:  tensor(-inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# effective entorpy\n",
    "\n",
    "from pyentrp import entropy as ent\n",
    "\n",
    "for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "# for j, data in enumerate(tqdm.tqdm(testloader)): \n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    # print(images)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # # 要给它降维\n",
    "        print('images: ', images.shape)\n",
    "        if conv:\n",
    "            images = avg_pool2d(images,kernel_size=pool_size)\n",
    "            print('images_pooled: ',images.shape)\n",
    "\n",
    "        # 1. ITE\n",
    "        # effectEntro = Shannon_quantity(images)\n",
    "        # print(\"effectEntro_ite: \",effectEntro)\n",
    "        \n",
    "        # 2. PyEntropy\n",
    "        # effectEntro_pyent = 0.0\n",
    "        # for i in range(len(images[0])): # 对每个维度\n",
    "        #     effectEntro_pyent  += shannon_entropy_pyent(images[:,i].flatten().detach().cpu().numpy())\n",
    "        #     # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "        # # effectEntro_pyent = shannon_entropy(images.flatten(start_dim=1).detach().cpu().numpy())\n",
    "        # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "\n",
    "        # 3. prob_entropy\n",
    "        # uloss = ULossMetric()\n",
    "        # prob_entropy = uloss._entropy_prob_batch(x=images)\n",
    "        # print('prob_entropy: ',prob_entropy)\n",
    "\n",
    "        # 4. infotopo\n",
    "        # images_flattened = images.flatten(start_dim=1).detach().cpu().numpy()\n",
    "        # effectEntro_infotopo = shannon_entropy_infotopo(images_flattened,conv=conv)\n",
    "        # print('effectEntro_infotopo: ',effectEntro_infotopo)\n",
    "\n",
    "        # 5. approximation\n",
    "        effectEntro_approx = shannon_entropy_approximation(images)\n",
    "        print('effectEntro_approx: ',effectEntro_approx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 effectInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  103.45039928117214\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1439.8617, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1315.6509, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1351.5675, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.5345, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1481.0920, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1399.8950, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1308.3562, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1374.8175, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1403.0698, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.1267, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1553.9719, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1387.9484, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.0072, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1296.6763, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.8759, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1456.4760, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1324.9995, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1454.1119, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1283.5997, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1398.3032, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1398.1182, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1252.7238, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1379.5374, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.5500, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1479.0574, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1439.2740, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1391.5353, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1384.2408, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1406.6274, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1335.3247, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1311.3887, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1550.9539, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1605.9362, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1358.8472, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1346.2292, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.8785, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1506.9994, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1336.2391, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.4463, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1429.1309, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1420.6449, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1284.1108, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1341.1232, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1378.1605, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1369.2576, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1409.6663, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1365.7891, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1432.5166, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1494.8789, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [01:18<4:21:04, 78.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1422.7227, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1393.4771, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  103.45039928117214\n",
      "effecFisher:  -424.30234\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  91.71463145506786\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1328.6263, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1424.4104, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1348.3845, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1349.2281, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1328.7341, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1493.9897, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1391.6030, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1271.2491, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1534.3845, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1571.1659, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1463.8622, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1350.0684, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1283.6251, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1333.6316, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1478.4679, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.6884, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1439.6399, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1353.6205, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1318.1250, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1320.2153, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1463.7466, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.4152, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1436.2795, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1491.2002, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1317.4763, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1482.4001, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1494.9937, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1381.7021, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1314.9614, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1270.4357, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.5747, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1263.3524, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1426.2689, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1336.9750, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1319.7664, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1376.1130, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1342.9209, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1288.0389, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1338.1570, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1485.9711, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1495.4830, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.2581, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1316.9092, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.1376, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1409.3372, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1516.4972, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1476.9659, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1698.3595, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1261.0378, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [02:34<4:13:14, 76.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1342.7485, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1392.6040, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  91.71463145506786\n",
      "effecFisher:  -423.8658\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  111.22835374928954\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1491.9755, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1442.0768, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1263.5121, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1335.4951, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1451.2014, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1274.8217, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1417.4087, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1337.8462, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1349.3315, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1278.1523, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1352.6647, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1362.6182, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1383.7056, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1535.5012, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1399.9546, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1379.0609, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1520.8674, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1362.4985, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1244.2476, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.2450, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1409.8118, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1303.1276, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1438.1003, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1380.4890, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.1929, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1487.3079, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1508.9714, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1365.7506, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1317.1639, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1486.3997, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1418.4113, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1344.4062, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1430.8367, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1349.4341, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1332.0334, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1428.5862, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1339.9490, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1459.4299, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1414.2789, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1452.6797, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1614.7466, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.9286, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1311.6361, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1422.4446, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1312.0890, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1344.9741, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1302.1627, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1341.6099, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1319.6997, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [03:55<4:18:51, 78.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1330.3346, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1386.1633, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  111.22835374928954\n",
      "effecFisher:  -420.64548\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  101.40073871439373\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1378.1670, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1304.8922, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1381.2568, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1392.3301, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1342.0966, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.3400, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1358.0481, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.0883, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1432.8555, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1543.4723, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1369.2076, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1315.5602, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1376.1881, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1425.9585, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1353.1091, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1411.1309, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.0551, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1442.6941, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.3661, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1323.5654, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1396.0325, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1369.4910, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1619.2634, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1401.9824, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1435.0234, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1324.4541, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1401.1774, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1469.9241, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1490.3848, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1387.8622, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1308.7551, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1321.5354, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1458.8044, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1697.8336, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1366.4673, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1596.9667, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1280.1145, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1470.7742, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1281.9846, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1331.7905, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1344.1511, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1441.6639, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1406.4175, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1386.3967, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1474.3671, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1378.3793, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.0387, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1291.7749, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1289.0551, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [05:17<4:22:13, 80.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1492.9727, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1399.0045, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  101.40073871439373\n",
      "effecFisher:  -427.06607\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  109.89770742105625\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1353.9387, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.2185, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1456.1785, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1353.4010, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1368.6074, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1426.9374, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1358.3566, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1419.6453, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1485.2257, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1351.4065, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1478.5580, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1340.7133, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1283.1111, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1361.9875, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1438.3967, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1263.6501, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1276.5111, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.5121, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1245.2157, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1463.2439, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1404.8848, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1370.8914, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.6992, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1432.8057, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1352.4534, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1359.6638, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1361.5027, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1414.4612, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1316.5730, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1418.7761, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1289.4539, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1319.2432, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1322.3286, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1408.8837, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1366.0854, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1423.3430, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1347.1373, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1288.0068, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1269.0558, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1287.7279, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1308.0330, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1457.8456, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1438.2026, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1347.1248, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1368.9561, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1279.6694, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1461.6584, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1379.3325, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1516.4247, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [06:37<4:20:05, 80.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1262.1844, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1367.8046, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  109.89770742105625\n",
      "effecFisher:  -411.4661\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  99.48054872868542\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1478.3733, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1298.6869, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.2125, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.9492, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1460.7747, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1441.8549, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1420.1853, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1277.6527, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1348.4946, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1347.1957, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1367.5902, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1401.4502, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1362.3076, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1342.7894, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1452.3594, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1326.2590, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1424.4264, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1320.4707, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1504.0347, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1315.8195, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1554.4851, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.1992, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1316.1487, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1255.1189, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.1265, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1381.4885, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1330.6272, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.0341, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1450.9849, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1324.8641, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1404.3700, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1434.4347, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1447.4355, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1289.5098, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1334.0642, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1484.2489, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1266.9449, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1431.4601, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1412.7422, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1352.4736, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1406.1760, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1545.0118, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1446.2498, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1361.7114, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.9846, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1556.8112, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1331.9021, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1284.2778, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.6218, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [07:59<4:21:19, 80.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1433.9604, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1386.2872, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  99.48054872868542\n",
      "effecFisher:  -420.70743\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  86.28246628139303\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1356.1526, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1472.5164, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1470.2244, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1397.2219, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1583.2571, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1325.9939, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1426.8926, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1489.7770, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1380.3015, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1476.6699, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1450.3932, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1486.5364, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1531.3213, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1282.0043, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1475.0925, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1340.5914, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1415.7209, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1540.9370, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1361.2091, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1536.6155, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1526.9801, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1359.9291, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1273.2552, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.1316, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.7046, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1373.4514, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1583.5416, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1452.2854, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1419.4141, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1466.3147, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1361.3206, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1304.2483, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1523.6034, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1329.6680, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1390.1829, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1374.8269, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1436.7620, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1384.7535, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1328.8782, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.2289, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1533.3474, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1420.4755, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1452.3984, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1471.0408, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1419.8627, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1348.7323, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1381.3682, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1438.7720, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1346.6107, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [09:21<4:20:30, 80.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1426.9128, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1420.8285, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  86.28246628139303\n",
      "effecFisher:  -437.97806\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  101.40652692429686\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1331.3286, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1416.1245, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1306.6432, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1262.5137, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1599.0370, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1360.7841, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1548.2218, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1463.3955, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1374.5914, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1303.3333, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1376.3833, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1471.3733, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1387.7682, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1394.4348, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.7275, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1320.9946, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1372.1605, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.3002, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1377.2339, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1416.6522, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1512.4247, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1344.5953, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1335.4438, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1465.9409, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1307.2238, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1423.0557, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1275.4421, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1410.9363, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1437.6177, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1390.5894, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1481.4930, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1352.7351, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1259.8105, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1407.7235, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1392.3545, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1244.4900, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1408.4214, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1359.0193, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.2429, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1431.0898, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1389.7347, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1343.4885, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1454.5533, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1315.0012, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1385.2394, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1464.6572, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1407.6892, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1400.7632, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1351.9106, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [10:41<4:18:25, 80.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdet计算报错\n",
      "f2_2:  tensor(1320.8549, device='cuda:1')\n",
      "f2_avg_outer:  tensor(0., device='cuda:1')\n",
      "f2_2_avg_outer:  tensor(1386.7311, device='cuda:1')\n",
      "f1:  tensor(544.8724)\n",
      "effecEntro:  101.40652692429686\n",
      "effecFisher:  -420.92935\n",
      "images:  torch.Size([50, 3, 32, 32])\n",
      "images_pooled:  torch.Size([50, 3, 8, 8])\n",
      "effectEntro_ite:  102.01009546485906\n",
      "I_diagonal_batch_avg:  torch.Size([192])\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1312.0552, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1323.8954, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1409.9261, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1383.2563, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1333.0039, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1305.6768, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1369.6403, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1411.9590, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1388.5144, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1362.0432, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1491.9026, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1371.8826, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1444.4143, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1497.1824, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1316.5461, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1316.2246, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1327.4919, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1343.9709, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1461.9481, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1366.2000, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1268.0229, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1416.7802, device='cuda:1')\n",
      "logdet计算报错\n",
      "f2_2:  tensor(1492.9761, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [11:19<4:31:42, 84.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m client_net(images)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# inverse_dFIL = Fishermetric.quantify(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01, with_outputs=True)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m effectFisher \u001b[38;5;241m=\u001b[39m \u001b[43mcomputing_diag_det_with_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# effect uniform\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# one_image = images[0]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# effectUniform = calculate_effect_normalize(one_image.flatten())\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# effecInfo_same_layer_list.append(effectEntro-effectFisher)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# effectInfo = (effectEntro-effectFisher)-(effectUniform_interval-effectUniform)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m effectInfo \u001b[38;5;241m=\u001b[39m (effectEntro\u001b[38;5;241m-\u001b[39meffectFisher)\n",
      "Cell \u001b[0;32mIn[4], line 89\u001b[0m, in \u001b[0;36mcomputing_diag_det_with_outputs\u001b[0;34m(model, inputs, outputs, sigmas)\u001b[0m\n\u001b[1;32m     86\u001b[0m input_i \u001b[38;5;241m=\u001b[39m inputs[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# 计算jacobian\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m J \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# J = J.reshape(J.shape[0],outputs.numel(),inputs.numel()) # (batch, out_size, in_size)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m J \u001b[38;5;241m=\u001b[39m J\u001b[38;5;241m.\u001b[39mreshape(output_size, input_size) \u001b[38;5;66;03m# (batch, out_size, in_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/functional.py:670\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    668\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 670\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "effecInfo_diff_layer_list = []\n",
    "effecInfo_same_layer_list = []\n",
    "EntropyMetric = ULossMetric()\n",
    "Fishermetric = dFILInverseMetric()\n",
    "\n",
    "\n",
    "InversedFIL_same_layer_list = []\n",
    "NBatch = len(testloader)\n",
    "image_dimension = -1\n",
    "\n",
    "for j, data in enumerate(tqdm.tqdm(testloader)): # 对testloader遍历\n",
    "# for j, data in enumerate(tqdm.tqdm(one_data_loader)): # 测试第一个testloader\n",
    "    images, labels = data\n",
    "    images, labels = images.to(args['device']), labels.to(args['device'])\n",
    "    with torch.no_grad():\n",
    "        print('images: ', images.shape)\n",
    "        \n",
    "        if conv:\n",
    "            images= avg_pool2d(images,kernel_size=pool_size)\n",
    "            print('images_pooled: ',images.shape)\n",
    "        if image_dimension ==-1:\n",
    "            image_dimension = images[0].numel()\n",
    "\n",
    "\n",
    "        # effect entropy \n",
    "        # infotopo\n",
    "        # effectEntro = shannon_entropy_infotopo(images.flatten(start_dim=1).detach().cpu().numpy(), conv)\n",
    "        # 自定一的prob entropy\n",
    "        # effecEntro= EntropyMetric._entropy_prob_batch(images) # H(x)\n",
    "\n",
    "        # ITE\n",
    "        effectEntro = Shannon_quantity(images)\n",
    "        print(\"effectEntro_ite: \",effectEntro)\n",
    "\n",
    "        # PyEntropy\n",
    "        # effectEntro_pyent = 0.0\n",
    "        # for i in range(len(images[0])): # 对每个维度\n",
    "        #     effectEntro_pyent  += shannon_entropy_pyent(images[:,i].flatten().detach().cpu().numpy())\n",
    "        #     # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "        # print('effectEntro_pyent: ',effectEntro_pyent)\n",
    "\n",
    "        # effect fisher\n",
    "            # inference\n",
    "        outputs = client_net(images).clone().detach()\n",
    "        # inverse_dFIL = Fishermetric.quantify(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01, with_outputs=True)\n",
    "        # effectFisher = computing_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        # effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "        effectFisher = computing_diag_det_with_outputs(model=client_net, inputs=images, outputs=outputs,sigmas = 0.01)\n",
    "\n",
    "        # effect uniform\n",
    "        # one_image = images[0]\n",
    "        # effectUniform = calculate_effect_normalize(one_image.flatten())\n",
    "\n",
    "        # effectUniform = calculate_effect_normalize_hetero_batch(images,data_interval)\n",
    "        # # uniform interval\n",
    "        # effectUniform_interval = calculate_effect_normalize(images[0],data_interval) # 用第一张图片就可\n",
    "\n",
    "\n",
    "        # 存储\n",
    "        # effecInfo_same_layer_list.append(effectEntro-effectFisher)\n",
    "        # effectInfo = (effectEntro-effectFisher)-(effectUniform_interval-effectUniform)\n",
    "        effectInfo = (effectEntro-effectFisher)\n",
    "        # effecInfo_same_layer_list.append(effectInfo.detach().cpu().numpy())\n",
    "        effecInfo_same_layer_list.append(effectInfo)\n",
    "        # InversedFIL_same_layer_list.append(inverse_dFIL)\n",
    "\n",
    "        # 打印一下\n",
    "        print(\"effecEntro: \", effectEntro)\n",
    "        print(\"effecFisher: \", effectFisher)\n",
    "        # print(\"effectUniform: \",effectUniform)\n",
    "        # print('effectUniform_interval: ',effectUniform_interval)\n",
    "        # print(\"inverse_dFIL: \",inverse_dFIL)\n",
    "\n",
    "avg_effectInfo = sum(effecInfo_same_layer_list)/len(effecInfo_same_layer_list)\n",
    "avg_d_effectInfo = avg_effectInfo/image_dimension\n",
    "print(f\"Layer {args['split_layer']} effecInfo: {avg_effectInfo}\") # 在多个batch上再求平均，这里有点问题。\n",
    "print(f\"Layer {args['split_layer']} effecInfo_avg_d: {avg_d_effectInfo}\") # 在多个batch上再求平均，这里有点问题。\n",
    "# print(f\"Layer {args['split_layer']} InversedFIL: {sum(InversedFIL_same_layer_list)/len(InversedFIL_same_layer_list)}\")\n",
    "effecInfo_diff_layer_list.append(effecInfo_same_layer_list)\n",
    "\n",
    "# 保存到csv中\n",
    "matrix = np.array(effecInfo_diff_layer_list) # 有点大，x\n",
    "transpose = matrix.T # 一行一条数据，一列代表一个layer \n",
    "# pd.DataFrame(data=transpose, columns=[i for i in split_layer_list]).to_csv(results_dir + f'effecInfo-bs{batch_size}.csv',index=False)\n",
    "save_route = results_dir + f'effecInfo-10000.csv'\n",
    "# if os.path.exists(save_route):\n",
    "#     df = pd.read_csv(save_route)\n",
    "#     df[args['split_layer']] = transpose\n",
    "#     df.to_csv(save_route,index=False)\n",
    "# else:\n",
    "#     pd.DataFrame(data=transpose, columns=[args['split_layer']]).to_csv(save_route,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# x = next(iter(one_data_loader))\n",
    "for i,_ in one_data_loader:\n",
    "        # print(i)\n",
    "        y = scaler.fit_transform(i)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(10,341) # 最大能接受341个特征 \n",
    "z = torch.randn(100,200)\n",
    "e1 = Shannon_quantity(y)\n",
    "e2 = Shannon_quantity(z)\n",
    "print(e1)\n",
    "print(e2)\n",
    "# print(np.log(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataPath = '/home/dengruijun/data/FinTech/DATASET/kaggle-dataset/bank/bank-additional-full.csv'\n",
    "\n",
    "[X_train, y_train], [X_test, y_test] = preprocess_bank_dataset(dataPath)\n",
    "df = pd.DataFrame(X_test)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试diagonal\n",
    "import torch\n",
    "x = torch.randn(6,5)\n",
    "y = torch.diagonal(x)\n",
    "z = torch.diag_embed(y)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.sqrt(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jvp\n",
    "x = torch.randn([2,2], requires_grad=True)\n",
    "f = lambda x: x * torch.tensor([1., 2])\n",
    "value, grad = jvp(f, (x,), (torch.tensor([[1,1],[1,0]]),))\n",
    "print(value)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "x = torch.tensor([3.0,4.0])\n",
    "x = x.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
