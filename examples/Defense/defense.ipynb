{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch.nn.functional import avg_pool2d\n",
    "\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "\n",
    "# task select\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader,get_models,get_infotopo_para\n",
    "\n",
    "# utils\n",
    "from ppsplit.utils import concat_weights, create_dir, load_json, save_json\n",
    "\n",
    "# defense:\n",
    "from ppsplit.defense.obfuscation.scheduler import Scheduler\n",
    "from ppsplit.defense.dp.posthoc.posthoc import PosthocDefense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Obfuscation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'defense': {'method': 'uniform_noise', 'client': {'model_name': 'resnet18', 'split_layer': 6, 'pretrained': False, 'optimizer': 'adam', 'lr': 0.0003, 'distribution': 'gaussian', 'mean': 0, 'sigma': 1}, 'server': {'model_name': 'resnet18', 'split_layer': 6, 'logits': 2, 'pretrained': False, 'lr': 0.0003, 'optimizer': 'adam'}, 'learning_rate': 0.01, 'total_epochs': 150, 'training_batch_size': 128, 'dataset': 'fairface', 'protected_attribute': 'data', 'prediction_attribute': 'gender', 'img_size': 128, 'split': False, 'test_batch_size': 64, 'exp_id': '1', 'exp_keys': ['client.distribution', 'client.mean', 'client.sigma'], 'device': 'cuda:0'}, 'general': {'result_dir': '20241228-defense/', 'test_num': 'uniform_noise', 'device': 'cuda:0', 'dataset': 'CIFAR10', 'oneData_bs': 1, 'train_bs': 128, 'test_bs': 64, 'model': 'VGG5', 'split_layer': 2, 'ep': -1, 'no_dense': 0, 'noise_scale': 0}}\n"
     ]
    }
   ],
   "source": [
    "config = load_json('./config/nopeek.json')\n",
    "# config = load_json('./config/shredder.json')\n",
    "# config = load_json('./config/cloak.json')\n",
    "# config = load_json('./config/uniform_noise.json')\n",
    "\n",
    "print(config)\n",
    "args = config['general']\n",
    "config['defense']['device']=args['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "client_net cweights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked'])\n",
      "len unit_net weights:  25\n",
      "len client_net cweights:  14\n",
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "client_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      "  (denses): Sequential()\n",
      ")\n",
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "server_net cweights:  odict_keys(['features.1.weight', 'features.1.bias', 'features.2.weight', 'features.2.bias', 'features.2.running_mean', 'features.2.running_var', 'features.2.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "len unit_net weights:  25\n",
      "len server_net cweights:  11\n",
      "server_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "=> loading decoder model '/home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth'\n",
      "unit_net_route: /home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/VGG5/BN+Tanh/VGG5-params-20ep.pth\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'no_pool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data_msg \u001b[38;5;241m=\u001b[39m get_dataloader(args)\n\u001b[1;32m      2\u001b[0m model_msg \u001b[38;5;241m=\u001b[39m get_models(args)\n\u001b[0;32m----> 3\u001b[0m infotopo_msg \u001b[38;5;241m=\u001b[39m \u001b[43mget_infotopo_para\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m msg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_msg,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_msg,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minfotopo_msg}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 数据集\u001b[39;00m\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/target_model/task_select.py:47\u001b[0m, in \u001b[0;36mget_infotopo_para\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_infotopo_para\u001b[39m(args):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# 提取参数\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m     no_pool \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mno_pool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_pool: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_pool\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# dataset,train_bs,test_bs,oneData_bs=args['dataset'],args['train_bs'],args['test_bs'],args['oneData_bs']\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# 加载模型和数据集，并从unit模型中切割出client_model\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'no_pool'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)\n",
    "msg = {**model_msg,**data_msg}\n",
    "\n",
    "# 数据集\n",
    "one_data_loader,trainloader,testloader = data_msg['one_data_loader'],data_msg['trainloader'], data_msg['testloader']\n",
    "data_interval = data_msg['data_interval']\n",
    "data_type = msg['data_type']\n",
    "\n",
    "# 模型\n",
    "client_net = model_msg['client_net']\n",
    "server_net,unit_net = model_msg['server_net'], model_msg['unit_net']\n",
    "image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "# 路径\n",
    "results_dir = model_msg['results_dir']\n",
    "inverse_dir = results_dir + 'layer' + str(args['split_layer'])+'/'\n",
    "# data_type = 1 if args['dataset'] == 'CIFAR10' else 0\n",
    "split_layer = args['split_layer']\n",
    "\n",
    "print('results_dir:', results_dir)\n",
    "\n",
    "create_dir(inverse_dir)\n",
    "\n",
    "# net使用\n",
    "client_net = client_net.to(args['device'])\n",
    "server_net = server_net.to(args['device'])\n",
    "unit_net = unit_net.to(args['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防御\n",
    "config['defense'][\"results_dir\"] = results_dir\n",
    "# config[\"1\"] = results_dir\n",
    "defense_scheduler = Scheduler(config)\n",
    "if config['defense']['method']=='cloak':\n",
    "    client_net = None\n",
    "    server_net = unit_net\n",
    "\n",
    "# 初始化和run存储模型\n",
    "defense_scheduler.initialize(train_loader = trainloader, test_loader = testloader, client_model = client_net, server_model = server_net)\n",
    "client_net,server_net = defense_scheduler.run_job()\n",
    "\n",
    "# 拼接模型并保存\n",
    "if client_net: # 如果有client_net，则拼接\n",
    "    new_weights_unit = concat_weights(unit_net.state_dict(),client_net.state_dict(),server_net.state_dict())\n",
    "else: # 如果没有client_net，则直接保存server_net\n",
    "    new_weights_unit = server_net.state_dict()\n",
    "\n",
    "unit_net.load_state_dict(new_weights_unit)\n",
    "torch.save(unit_net.state_dict(), inverse_dir + 'unit_net_defensed.pth')\n",
    "\n",
    "print(\"model saved in \",inverse_dir + 'unit_net_defensed.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arl_config': {'alpha': 0.99, 'dset': 'utkface', 'noise_reg': 1, 'sigma': 0.01, 'siamese_reg': 1, 'margin': 25, 'lambda': 1.0, 'tag': 'gender', 'device': 'cuda:0', 'epoch': 50}, 'eval_config': {'epsilon': 5, 'delta': 0.1, 'radius': 0.2, 'eval_size': 100, 'proposed_bound': 0.84, 'max_upper_bound': 2}}\n",
      "{'result_dir': '20241228-defense/', 'test_num': 'Posthoc', 'device': 'cuda:0', 'dataset': 'CIFAR10', 'oneData_bs': 1, 'train_bs': 32, 'test_bs': 64, 'model': 'VGG5', 'split_layer': 2, 'ep': -1, 'no_dense': 0, 'noise_scale': 0}\n"
     ]
    }
   ],
   "source": [
    "config = load_json('./config/posthoc.json')\n",
    "\n",
    "args =  {\n",
    "        \"result_dir\":\"20241228-defense/\",\n",
    "        \"test_num\":\"Posthoc\",\n",
    "        \"device\":\"cuda:0\",\n",
    "\n",
    "        \"dataset\":\"CIFAR10\",\n",
    "        \"oneData_bs\": 1,\n",
    "        \"train_bs\": 32,\n",
    "        \"test_bs\": 64,\n",
    "        \n",
    "        \"model\":\"VGG5\",\n",
    "        \"split_layer\": 2,\n",
    "        \"ep\":-1,\n",
    "        \"no_dense\": 0,\n",
    "        \n",
    "        \"noise_scale\": 0\n",
    "    }\n",
    "print(config)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "client_net cweights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked'])\n",
      "len unit_net weights:  25\n",
      "len client_net cweights:  14\n",
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "client_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      "  (denses): Sequential()\n",
      ")\n",
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "server_net cweights:  odict_keys(['features.1.weight', 'features.1.bias', 'features.2.weight', 'features.2.bias', 'features.2.running_mean', 'features.2.running_var', 'features.2.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "len unit_net weights:  25\n",
      "len server_net cweights:  11\n",
      "server_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "=> loading decoder model '/home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth'\n",
      "unit_net_route: /home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/VGG5/BN+Tanh/VGG5-params-20ep.pth\n",
      "results_dir: ../../results/20241228-defense//VGG5/Posthoc/\n",
      "decoder_route: /home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth\n"
     ]
    }
   ],
   "source": [
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)\n",
    "# infotopo_msg = get_infotopo_para(args)\n",
    "msg = {**model_msg,**data_msg}\n",
    "\n",
    "# 数据集\n",
    "one_data_loader,trainloader,testloader = data_msg['one_data_loader'],data_msg['trainloader'], data_msg['testloader']\n",
    "\n",
    "# 模型\n",
    "client_net = model_msg['client_net']\n",
    "client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "decoder_route = model_msg['decoder_route']\n",
    "server_net = model_msg['server_net']\n",
    "\n",
    "image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "# 路径\n",
    "results_dir = model_msg['results_dir']\n",
    "split_layer = args['split_layer']\n",
    "\n",
    "print('results_dir:', results_dir)\n",
    "print('decoder_route:', decoder_route)\n",
    "\n",
    "create_dir(results_dir)\n",
    "\n",
    "# decoder_route = \"/home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth\"\n",
    "# # decoder_route = \"/home/dengruijun/data/FinTech/PP-Split/results/20241228-defense/VGG5/Posthoc/_noisereg_0.01_siamesereg_25_1.0/adv.pth\"\n",
    "# if os.path.isfile(decoder_route): # 如果已经训练好了\n",
    "#     print(\"=> loading decoder model '{}'\".format(decoder_route))\n",
    "#     decoder_net = torch.load(decoder_route)\n",
    "# else:\n",
    "#     print(\"=> no decoder model found at '{}'\".format(decoder_route))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 01:15:29,531 - ppsplit.defense.dp.posthoc.posthoc - INFO - {'alpha': 0.99, 'dset': 'utkface', 'noise_reg': 1, 'sigma': 0.01, 'siamese_reg': 1, 'margin': 25, 'lambda': 1.0, 'tag': 'gender', 'device': 'cuda:0', 'epoch': 50}\n",
      "2025-02-23 01:15:29,533 - ppsplit.defense.dp.posthoc.posthoc - INFO - {'epsilon': 5, 'delta': 0.1, 'radius': 0.2, 'eval_size': 100, 'proposed_bound': 0.84, 'max_upper_bound': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "ARL base_dir: ../../results/20241228-defense//VGG5/Posthoc/_noisereg_0.01_siamesereg_25_1.0\n"
     ]
    }
   ],
   "source": [
    "# 加载 posthoc 防御方法\n",
    "# 用于testloader的batch size\n",
    "posthoc_defense = PosthocDefense(config, \n",
    "                                 train_loader=trainloader, \n",
    "                                 test_loader=testloader,\n",
    "                                 client_net=client_net, \n",
    "                                 server_net=server_net, \n",
    "                                 decoder_net=decoder_net,\n",
    "                                 results_dir=results_dir,\n",
    "                                 device=args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load decoder model from: /home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth\n",
      "VGG5Decoder(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (denses): Sequential()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载decoder模型\n",
    "if not os.path.isfile(decoder_route): # 如果没有训练decoder\n",
    "    # 训练decoder\n",
    "    args['train_bs']=32\n",
    "    args['test_bs']=32\n",
    "    msg_data = get_dataloader(args)\n",
    "\n",
    "    posthoc_defense.arl_obj.setup_path()\n",
    "    print(\"starting training ARL\")\n",
    "    \n",
    "    posthoc_defense.arl_obj.train()\n",
    "    \n",
    "else:\n",
    "    print(\"Load decoder model from:\",decoder_route)\n",
    "\n",
    "print(decoder_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARL训练\n",
    "# 用于train_loader的batch size\n",
    "args['train_bs']=32\n",
    "args['test_bs']=32\n",
    "msg_data = get_dataloader(args)\n",
    "posthoc_defense.train_ARL(train_loader=trainloader, test_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'layer_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# posthoc 框架训练\u001b[39;00m\n\u001b[1;32m      2\u001b[0m posthoc_defense\u001b[38;5;241m.\u001b[39marl_obj\u001b[38;5;241m.\u001b[39mon_cpu() \u001b[38;5;66;03m# move the models to cpu\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mposthoc_defense\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefense_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/ppsplit/defense/dp/posthoc/posthoc.py:60\u001b[0m, in \u001b[0;36mPosthocDefense.defense_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefense_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 60\u001b[0m     mean_lc, std_lc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_local_sens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval\u001b[38;5;241m.\u001b[39mproposed_bound \u001b[38;5;241m=\u001b[39m mean_lc \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mstd_lc\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval\u001b[38;5;241m.\u001b[39mproposed_bound\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/ppsplit/defense/dp/posthoc/posthoc.py:217\u001b[0m, in \u001b[0;36mEvaluation.test_local_sens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m simple_domain \u001b[38;5;241m=\u001b[39m Hyperbox\u001b[38;5;241m.\u001b[39mbuild_linf_ball(center[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius) \u001b[38;5;66;03m# 邻域\u001b[39;00m\n\u001b[1;32m    215\u001b[0m cross_problem \u001b[38;5;241m=\u001b[39m LipMIP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marl_obj\u001b[38;5;241m.\u001b[39mobfuscator\u001b[38;5;241m.\u001b[39mcpu(), simple_domain,\n\u001b[1;32m    216\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1Ball1\u001b[39m\u001b[38;5;124m'\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 217\u001b[0m \u001b[43mcross_problem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_max_lipschitz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m lip_val \u001b[38;5;241m=\u001b[39m cross_problem\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_idx, lip_val)\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/ppsplit/defense/dp/posthoc/lipmip/lipMIP.py:115\u001b[0m, in \u001b[0;36mLipMIP.compute_max_lipschitz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_max_lipschitz\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Computes the maximum lipschitz constant with a fixed\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m        domain already set.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        Returns the maximum lipschitz constant and the point that\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m        attains it\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     squire, timer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_gurobi_squire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     model \u001b[38;5;241m=\u001b[39m squire\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/ppsplit/defense/dp/posthoc/lipmip/lipMIP.py:98\u001b[0m, in \u001b[0;36mLipMIP.build_gurobi_squire\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Step 1: Build the pre-ReLU and pre-switch hyperboxes\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreact, HBoxIA):\n\u001b[0;32m---> 98\u001b[0m     pre_bounds \u001b[38;5;241m=\u001b[39m \u001b[43mHBoxIA\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     pre_bounds\u001b[38;5;241m.\u001b[39mcompute_forward(technique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreact)\n\u001b[1;32m    100\u001b[0m     pre_bounds\u001b[38;5;241m.\u001b[39mcompute_backward(technique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreact)\n",
      "File \u001b[0;32m~/data/FinTech/PP-Split/ppsplit/defense/dp/posthoc/lipmip/interval_analysis.py:55\u001b[0m, in \u001b[0;36mHBoxIA.__init__\u001b[0;34m(self, network, input_domain, backprop_domain)\u001b[0m\n\u001b[1;32m     52\u001b[0m \tbackprop_domain \u001b[38;5;241m=\u001b[39m Hyperbox\u001b[38;5;241m.\u001b[39mfrom_vector(backprop_domain)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backprop_domain \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1Ball1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrossLipschitz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargetCrossLipschitz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m \t\t\t\t\t     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrueCrossLipschitz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrueTargetCrossLipschitz\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 55\u001b[0m \toutput_dim \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_sizes\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     56\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m backprop_domain \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1Ball1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     57\u001b[0m \t\tradius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'layer_sizes'"
     ]
    }
   ],
   "source": [
    "# posthoc 框架训练\n",
    "posthoc_defense.arl_obj.on_cpu() # move the models to cpu\n",
    "posthoc_defense.defense_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posthoc 隐私测试\n",
    "posthoc_defense.defense_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
