{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "# utils\n",
    "from ppsplit.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Ruijun Deng\n",
    "Date: 2024-08-24 00:41:28\n",
    "LastEditTime: 2024-10-27 02:06:57\n",
    "LastEditors: Ruijun Deng\n",
    "FilePath: /PP-Split/target_model/models.ipynb\n",
    "Description: \n",
    "'''\n",
    "# 导入各个baseline模型及其数据集预处理方法\n",
    "# 模型\n",
    "from target_model.utils import split_weights_client\n",
    "from target_model.models.ImageClassification.VGG5_9 import VGG,VGG5Decoder,model_cfg\n",
    "from target_model.models.TableClassification.BankNet import BankNet1,BankNetDecoder1,bank_cfg\n",
    "from target_model.models.TableClassification.CreditNet import CreditNet1,CreditNetDecoder1,credit_cfg\n",
    "from target_model.models.TableClassification.PurchaseNet import PurchaseClassifier1,PurchaseDecoder1,purchase_cfg\n",
    "from target_model.models.TableClassification.IrisNet import IrisNet,IrisNetDecoder,Iris_cfg\n",
    "from target_model.models.ImageClassification.ResNet import resnet18,resnet34,resnet50,InversionNet,resnet_model_cfg\n",
    "from target_model.models.ImageClassification.AlexNet import AlexNet_MNIST\n",
    "from target_model.models.ImageClassification.ViT import vit_b_16 as ViTb_16\n",
    "\n",
    "\n",
    "# 数据预处理方法\n",
    "from target_model.data_preprocessing.preprocess_cifar10 import get_cifar10_normalize,deprocess\n",
    "from target_model.data_preprocessing.preprocess_bank import bank_dataset,preprocess_bank,preprocess_bank_dataset,tabinfo_bank\n",
    "from target_model.data_preprocessing.preprocess_credit import preprocess_credit,tabinfo_credit\n",
    "from target_model.data_preprocessing.preprocess_purchase import preprocess_purchase,tabinfo_purchase\n",
    "from target_model.data_preprocessing.preprocess_Iris import preprocess_Iris, tabinfo_Iris\n",
    "from target_model.data_preprocessing.dataset import get_one_data\n",
    "\n",
    "\n",
    "# utils\n",
    "from  ppsplit.utils import create_dir\n",
    "\n",
    "\n",
    "# model_select\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader_and_model, \\\n",
    "    get_dataloader,get_models,get_infotopo_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "{'result_dir': '20241228-defense/', 'test_num': 'Posthoc', 'device': 'cuda:0', 'dataset': 'CIFAR10', 'oneData_bs': 1, 'train_bs': 32, 'test_bs': 64, 'model': 'VGG5', 'split_layer': 2, 'ep': -1, 'no_dense': 0, 'noise_scale': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args =  {\n",
    "        \"result_dir\":\"20241228-defense/\",\n",
    "        \"test_num\":\"Posthoc\",\n",
    "        \"device\":\"cuda:0\",\n",
    "\n",
    "        \"dataset\":\"CIFAR10\",\n",
    "        \"oneData_bs\": 1,\n",
    "        \"train_bs\": 32,\n",
    "        \"test_bs\": 64,\n",
    "        \n",
    "        \"model\":\"VGG5\",\n",
    "        \"split_layer\": 2,\n",
    "        \"ep\":-1,\n",
    "        \"no_dense\": 0,\n",
    "        \n",
    "        \"noise_scale\": 0\n",
    "    }\n",
    "print(args['device'])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unit layers: 14\n",
      "Split layer: -1\n",
      "ResNet(\n",
      "  (selected_layers): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate=none)\n",
      "    (3): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# resnet18\n",
    "net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "# inet = InversionNet(in_c=64, upconv_channels=[(128, 'same'), (3, 'same')], last_activation=None)\n",
    "inet = InversionNet(last_activation=None)\n",
    "print(inet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unit layers: 22\n",
      "Split layer: -1\n"
     ]
    }
   ],
   "source": [
    "# 加载一下模型参数\n",
    "# resnet18 cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/CIFAR10-models/ResNet18/32bs-ep20-relu-max-adam/resnet18-drj.pth' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet18 cifar100\n",
    "\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet34 cifar100\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj-align.pth'\n",
    "# client_net = resnet34(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet50 cifar100\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj-align.pth'\n",
    "# # client_net = resnet50(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet18 20ep cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/epoch=14resnet18-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "\n",
    "# resnet18 20ep narrow cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/epoch=16resnet18_narrow-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnett18 20ep wide cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/epoch=14resnet18_wide-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet34 20ep cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR10/epoch=10-args.classifier=0-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet34(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet18 20ep 2narrow cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_2narrow/CIFAR10/epoch=14resnet18_2narrow-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_2narrow/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_2narrow/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# maeng 已训练好的参数 resnet18,34,50\n",
    "# 18\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet18.pt'\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet34.pt'\n",
    "new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet50.pt'\n",
    "\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "# client_net = resnet34(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "client_net = resnet50(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='relu', pooling='max')\n",
    "\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet18-align.pt'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet34-align.pt'\n",
    "new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/CIFAR10-models/state_dicts/resnet50-align.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n",
      "320 odict_keys(['selected_layers.0.weight', 'selected_layers.1.weight', 'selected_layers.1.bias', 'selected_layers.1.running_mean', 'selected_layers.1.running_var', 'selected_layers.1.num_batches_tracked', 'selected_layers.4.conv1.weight', 'selected_layers.4.bn1.weight', 'selected_layers.4.bn1.bias', 'selected_layers.4.bn1.running_mean', 'selected_layers.4.bn1.running_var', 'selected_layers.4.bn1.num_batches_tracked', 'selected_layers.4.conv2.weight', 'selected_layers.4.bn2.weight', 'selected_layers.4.bn2.bias', 'selected_layers.4.bn2.running_mean', 'selected_layers.4.bn2.running_var', 'selected_layers.4.bn2.num_batches_tracked', 'selected_layers.4.conv3.weight', 'selected_layers.4.bn3.weight', 'selected_layers.4.bn3.bias', 'selected_layers.4.bn3.running_mean', 'selected_layers.4.bn3.running_var', 'selected_layers.4.bn3.num_batches_tracked', 'selected_layers.4.downsample.0.weight', 'selected_layers.4.downsample.1.weight', 'selected_layers.4.downsample.1.bias', 'selected_layers.4.downsample.1.running_mean', 'selected_layers.4.downsample.1.running_var', 'selected_layers.4.downsample.1.num_batches_tracked', 'selected_layers.5.conv1.weight', 'selected_layers.5.bn1.weight', 'selected_layers.5.bn1.bias', 'selected_layers.5.bn1.running_mean', 'selected_layers.5.bn1.running_var', 'selected_layers.5.bn1.num_batches_tracked', 'selected_layers.5.conv2.weight', 'selected_layers.5.bn2.weight', 'selected_layers.5.bn2.bias', 'selected_layers.5.bn2.running_mean', 'selected_layers.5.bn2.running_var', 'selected_layers.5.bn2.num_batches_tracked', 'selected_layers.5.conv3.weight', 'selected_layers.5.bn3.weight', 'selected_layers.5.bn3.bias', 'selected_layers.5.bn3.running_mean', 'selected_layers.5.bn3.running_var', 'selected_layers.5.bn3.num_batches_tracked', 'selected_layers.6.conv1.weight', 'selected_layers.6.bn1.weight', 'selected_layers.6.bn1.bias', 'selected_layers.6.bn1.running_mean', 'selected_layers.6.bn1.running_var', 'selected_layers.6.bn1.num_batches_tracked', 'selected_layers.6.conv2.weight', 'selected_layers.6.bn2.weight', 'selected_layers.6.bn2.bias', 'selected_layers.6.bn2.running_mean', 'selected_layers.6.bn2.running_var', 'selected_layers.6.bn2.num_batches_tracked', 'selected_layers.6.conv3.weight', 'selected_layers.6.bn3.weight', 'selected_layers.6.bn3.bias', 'selected_layers.6.bn3.running_mean', 'selected_layers.6.bn3.running_var', 'selected_layers.6.bn3.num_batches_tracked', 'selected_layers.7.conv1.weight', 'selected_layers.7.bn1.weight', 'selected_layers.7.bn1.bias', 'selected_layers.7.bn1.running_mean', 'selected_layers.7.bn1.running_var', 'selected_layers.7.bn1.num_batches_tracked', 'selected_layers.7.conv2.weight', 'selected_layers.7.bn2.weight', 'selected_layers.7.bn2.bias', 'selected_layers.7.bn2.running_mean', 'selected_layers.7.bn2.running_var', 'selected_layers.7.bn2.num_batches_tracked', 'selected_layers.7.conv3.weight', 'selected_layers.7.bn3.weight', 'selected_layers.7.bn3.bias', 'selected_layers.7.bn3.running_mean', 'selected_layers.7.bn3.running_var', 'selected_layers.7.bn3.num_batches_tracked', 'selected_layers.7.downsample.0.weight', 'selected_layers.7.downsample.1.weight', 'selected_layers.7.downsample.1.bias', 'selected_layers.7.downsample.1.running_mean', 'selected_layers.7.downsample.1.running_var', 'selected_layers.7.downsample.1.num_batches_tracked', 'selected_layers.8.conv1.weight', 'selected_layers.8.bn1.weight', 'selected_layers.8.bn1.bias', 'selected_layers.8.bn1.running_mean', 'selected_layers.8.bn1.running_var', 'selected_layers.8.bn1.num_batches_tracked', 'selected_layers.8.conv2.weight', 'selected_layers.8.bn2.weight', 'selected_layers.8.bn2.bias', 'selected_layers.8.bn2.running_mean', 'selected_layers.8.bn2.running_var', 'selected_layers.8.bn2.num_batches_tracked', 'selected_layers.8.conv3.weight', 'selected_layers.8.bn3.weight', 'selected_layers.8.bn3.bias', 'selected_layers.8.bn3.running_mean', 'selected_layers.8.bn3.running_var', 'selected_layers.8.bn3.num_batches_tracked', 'selected_layers.9.conv1.weight', 'selected_layers.9.bn1.weight', 'selected_layers.9.bn1.bias', 'selected_layers.9.bn1.running_mean', 'selected_layers.9.bn1.running_var', 'selected_layers.9.bn1.num_batches_tracked', 'selected_layers.9.conv2.weight', 'selected_layers.9.bn2.weight', 'selected_layers.9.bn2.bias', 'selected_layers.9.bn2.running_mean', 'selected_layers.9.bn2.running_var', 'selected_layers.9.bn2.num_batches_tracked', 'selected_layers.9.conv3.weight', 'selected_layers.9.bn3.weight', 'selected_layers.9.bn3.bias', 'selected_layers.9.bn3.running_mean', 'selected_layers.9.bn3.running_var', 'selected_layers.9.bn3.num_batches_tracked', 'selected_layers.10.conv1.weight', 'selected_layers.10.bn1.weight', 'selected_layers.10.bn1.bias', 'selected_layers.10.bn1.running_mean', 'selected_layers.10.bn1.running_var', 'selected_layers.10.bn1.num_batches_tracked', 'selected_layers.10.conv2.weight', 'selected_layers.10.bn2.weight', 'selected_layers.10.bn2.bias', 'selected_layers.10.bn2.running_mean', 'selected_layers.10.bn2.running_var', 'selected_layers.10.bn2.num_batches_tracked', 'selected_layers.10.conv3.weight', 'selected_layers.10.bn3.weight', 'selected_layers.10.bn3.bias', 'selected_layers.10.bn3.running_mean', 'selected_layers.10.bn3.running_var', 'selected_layers.10.bn3.num_batches_tracked', 'selected_layers.11.conv1.weight', 'selected_layers.11.bn1.weight', 'selected_layers.11.bn1.bias', 'selected_layers.11.bn1.running_mean', 'selected_layers.11.bn1.running_var', 'selected_layers.11.bn1.num_batches_tracked', 'selected_layers.11.conv2.weight', 'selected_layers.11.bn2.weight', 'selected_layers.11.bn2.bias', 'selected_layers.11.bn2.running_mean', 'selected_layers.11.bn2.running_var', 'selected_layers.11.bn2.num_batches_tracked', 'selected_layers.11.conv3.weight', 'selected_layers.11.bn3.weight', 'selected_layers.11.bn3.bias', 'selected_layers.11.bn3.running_mean', 'selected_layers.11.bn3.running_var', 'selected_layers.11.bn3.num_batches_tracked', 'selected_layers.11.downsample.0.weight', 'selected_layers.11.downsample.1.weight', 'selected_layers.11.downsample.1.bias', 'selected_layers.11.downsample.1.running_mean', 'selected_layers.11.downsample.1.running_var', 'selected_layers.11.downsample.1.num_batches_tracked', 'selected_layers.12.conv1.weight', 'selected_layers.12.bn1.weight', 'selected_layers.12.bn1.bias', 'selected_layers.12.bn1.running_mean', 'selected_layers.12.bn1.running_var', 'selected_layers.12.bn1.num_batches_tracked', 'selected_layers.12.conv2.weight', 'selected_layers.12.bn2.weight', 'selected_layers.12.bn2.bias', 'selected_layers.12.bn2.running_mean', 'selected_layers.12.bn2.running_var', 'selected_layers.12.bn2.num_batches_tracked', 'selected_layers.12.conv3.weight', 'selected_layers.12.bn3.weight', 'selected_layers.12.bn3.bias', 'selected_layers.12.bn3.running_mean', 'selected_layers.12.bn3.running_var', 'selected_layers.12.bn3.num_batches_tracked', 'selected_layers.13.conv1.weight', 'selected_layers.13.bn1.weight', 'selected_layers.13.bn1.bias', 'selected_layers.13.bn1.running_mean', 'selected_layers.13.bn1.running_var', 'selected_layers.13.bn1.num_batches_tracked', 'selected_layers.13.conv2.weight', 'selected_layers.13.bn2.weight', 'selected_layers.13.bn2.bias', 'selected_layers.13.bn2.running_mean', 'selected_layers.13.bn2.running_var', 'selected_layers.13.bn2.num_batches_tracked', 'selected_layers.13.conv3.weight', 'selected_layers.13.bn3.weight', 'selected_layers.13.bn3.bias', 'selected_layers.13.bn3.running_mean', 'selected_layers.13.bn3.running_var', 'selected_layers.13.bn3.num_batches_tracked', 'selected_layers.14.conv1.weight', 'selected_layers.14.bn1.weight', 'selected_layers.14.bn1.bias', 'selected_layers.14.bn1.running_mean', 'selected_layers.14.bn1.running_var', 'selected_layers.14.bn1.num_batches_tracked', 'selected_layers.14.conv2.weight', 'selected_layers.14.bn2.weight', 'selected_layers.14.bn2.bias', 'selected_layers.14.bn2.running_mean', 'selected_layers.14.bn2.running_var', 'selected_layers.14.bn2.num_batches_tracked', 'selected_layers.14.conv3.weight', 'selected_layers.14.bn3.weight', 'selected_layers.14.bn3.bias', 'selected_layers.14.bn3.running_mean', 'selected_layers.14.bn3.running_var', 'selected_layers.14.bn3.num_batches_tracked', 'selected_layers.15.conv1.weight', 'selected_layers.15.bn1.weight', 'selected_layers.15.bn1.bias', 'selected_layers.15.bn1.running_mean', 'selected_layers.15.bn1.running_var', 'selected_layers.15.bn1.num_batches_tracked', 'selected_layers.15.conv2.weight', 'selected_layers.15.bn2.weight', 'selected_layers.15.bn2.bias', 'selected_layers.15.bn2.running_mean', 'selected_layers.15.bn2.running_var', 'selected_layers.15.bn2.num_batches_tracked', 'selected_layers.15.conv3.weight', 'selected_layers.15.bn3.weight', 'selected_layers.15.bn3.bias', 'selected_layers.15.bn3.running_mean', 'selected_layers.15.bn3.running_var', 'selected_layers.15.bn3.num_batches_tracked', 'selected_layers.16.conv1.weight', 'selected_layers.16.bn1.weight', 'selected_layers.16.bn1.bias', 'selected_layers.16.bn1.running_mean', 'selected_layers.16.bn1.running_var', 'selected_layers.16.bn1.num_batches_tracked', 'selected_layers.16.conv2.weight', 'selected_layers.16.bn2.weight', 'selected_layers.16.bn2.bias', 'selected_layers.16.bn2.running_mean', 'selected_layers.16.bn2.running_var', 'selected_layers.16.bn2.num_batches_tracked', 'selected_layers.16.conv3.weight', 'selected_layers.16.bn3.weight', 'selected_layers.16.bn3.bias', 'selected_layers.16.bn3.running_mean', 'selected_layers.16.bn3.running_var', 'selected_layers.16.bn3.num_batches_tracked', 'selected_layers.17.conv1.weight', 'selected_layers.17.bn1.weight', 'selected_layers.17.bn1.bias', 'selected_layers.17.bn1.running_mean', 'selected_layers.17.bn1.running_var', 'selected_layers.17.bn1.num_batches_tracked', 'selected_layers.17.conv2.weight', 'selected_layers.17.bn2.weight', 'selected_layers.17.bn2.bias', 'selected_layers.17.bn2.running_mean', 'selected_layers.17.bn2.running_var', 'selected_layers.17.bn2.num_batches_tracked', 'selected_layers.17.conv3.weight', 'selected_layers.17.bn3.weight', 'selected_layers.17.bn3.bias', 'selected_layers.17.bn3.running_mean', 'selected_layers.17.bn3.running_var', 'selected_layers.17.bn3.num_batches_tracked', 'selected_layers.17.downsample.0.weight', 'selected_layers.17.downsample.1.weight', 'selected_layers.17.downsample.1.bias', 'selected_layers.17.downsample.1.running_mean', 'selected_layers.17.downsample.1.running_var', 'selected_layers.17.downsample.1.num_batches_tracked', 'selected_layers.18.conv1.weight', 'selected_layers.18.bn1.weight', 'selected_layers.18.bn1.bias', 'selected_layers.18.bn1.running_mean', 'selected_layers.18.bn1.running_var', 'selected_layers.18.bn1.num_batches_tracked', 'selected_layers.18.conv2.weight', 'selected_layers.18.bn2.weight', 'selected_layers.18.bn2.bias', 'selected_layers.18.bn2.running_mean', 'selected_layers.18.bn2.running_var', 'selected_layers.18.bn2.num_batches_tracked', 'selected_layers.18.conv3.weight', 'selected_layers.18.bn3.weight', 'selected_layers.18.bn3.bias', 'selected_layers.18.bn3.running_mean', 'selected_layers.18.bn3.running_var', 'selected_layers.18.bn3.num_batches_tracked', 'selected_layers.19.conv1.weight', 'selected_layers.19.bn1.weight', 'selected_layers.19.bn1.bias', 'selected_layers.19.bn1.running_mean', 'selected_layers.19.bn1.running_var', 'selected_layers.19.bn1.num_batches_tracked', 'selected_layers.19.conv2.weight', 'selected_layers.19.bn2.weight', 'selected_layers.19.bn2.bias', 'selected_layers.19.bn2.running_mean', 'selected_layers.19.bn2.running_var', 'selected_layers.19.bn2.num_batches_tracked', 'selected_layers.19.conv3.weight', 'selected_layers.19.bn3.weight', 'selected_layers.19.bn3.bias', 'selected_layers.19.bn3.running_mean', 'selected_layers.19.bn3.running_var', 'selected_layers.19.bn3.num_batches_tracked', 'selected_layers.21.weight', 'selected_layers.21.bias'])\n"
     ]
    }
   ],
   "source": [
    "# 提取state_dict\n",
    "# pweights = torch.load(unit_net_route)\n",
    "# print(pweights.keys())\n",
    "# state_dict = pweights['state_dict']\n",
    "# torch.save(state_dict, new_unit_net_route)\n",
    "\n",
    "\n",
    "\n",
    "# 改一下 resnet的 模型参数的key\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "import torch\n",
    "\n",
    "# from target_model.task_select import *\n",
    "\n",
    "pweights = torch.load(new_unit_net_route) # 存的参数\n",
    "cweights = client_net.state_dict() # 当前模型的参数名称\n",
    "\n",
    "print(len(pweights.keys()),pweights.keys())\n",
    "print(len(cweights.keys()),cweights.keys())\n",
    "\n",
    "\n",
    "# new_key = {}\n",
    "# for keyp,keyc in zip(pweights.keys(),cweights.keys()):\n",
    "#     print(keyp,'\\t\\t\\t',keyc)\n",
    "\n",
    "# for i,key in enumerate(pweights.keys()):\n",
    "#     if i<122:\n",
    "#         continue\n",
    "#     print(key)\n",
    "\n",
    "    # new_key[key.replace('model.','')] = pweights[key]\n",
    "\n",
    "# new_key = {}\n",
    "# for key in cweights.keys():\n",
    "#     # new_key[key] = pweights[key.replace('selected_layers','model.layers')] # resnet18 cifar10\n",
    "#     # new_key[key] = pweights[key.replace('selected_layers','model.selected_layers')] # resnet18 cifar100\n",
    "#     new_key[key] = pweights[key.replace('selected_layers','model.selected_layers')] # resnet18 cifar100\n",
    "# torch.save(new_key, new_unit_net_route_align)\n",
    "\n",
    "# 每个元素使用第一个字典的value和第二个字典的key\n",
    "# new_key = {key2: value1 for value1, key2 in zip(pweights.values(), cweights.keys())}\n",
    "# torch.save(new_key, new_unit_net_route_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (selected_layers): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate=none)\n",
      "    (3): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载模型参数\n",
    "# client_net = resnet18(pretrained=False, split_layer=13, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "state_dict = torch.load(new_unit_net_route_align)\n",
    "client_net.load_state_dict(state_dict) \n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet_MNIST(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# alexnet mnist\n",
    "net = AlexNet_MNIST()\n",
    "print(net)\n",
    "# print(len(net)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Tanh()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Tanh()\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): Tanh()\n",
      "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): Tanh()\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR-10\n",
    "# model_msg = get_models(args)\n",
    "# # 模型\n",
    "# client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "# decoder_route = model_msg['decoder_route']\n",
    "# image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "\n",
    "client_net = VGG('Unit','VGG9',len(model_cfg['VGG9'])-1,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)\n",
    "# 0ep\n",
    "# client_net.load_state_dict(torch.load('/home/dengruijun/data/FinTech/PP-Split/results/trained_models/VGG9/CIFAR10/VGG9-CIFAR10-20epoch.pth-0.pth'))\n",
    "# 20ep\n",
    "client_net.load_state_dict(torch.load('/home/dengruijun/data/FinTech/PP-Split/results/trained_models/VGG9/CIFAR10/VGG9-CIFAR10-20epoch.pth-20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Tanh()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Tanh()\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): Tanh()\n",
      "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): Tanh()\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "client_net = VGG('Unit','VGG9_MNIST',len(model_cfg['VGG9'])-1,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VGG5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "features.8.weight\n",
      "features.8.bias\n",
      "features.9.weight\n",
      "features.9.bias\n",
      "features.9.running_mean\n",
      "features.9.running_var\n",
      "features.9.num_batches_tracked\n",
      "denses.0.weight\n",
      "denses.0.bias\n",
      "denses.1.weight\n",
      "denses.1.bias\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10\n",
    "client_net = VGG('Unit','VGG5',2,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)\n",
    "\n",
    "# 0ep\n",
    "pweights=torch.load('/home/dengruijun/data/FinTech/PP-Split/results/trained_models/VGG5/CIFAR10/VGG5-CIFAR10-0epoch.pth')\n",
    "# 20ep\n",
    "pweights=torch.load('/home/dengruijun/data/FinTech/PP-Split/results/trained_models/VGG5/CIFAR10/VGG5-CIFAR10-20epoch.pth')\n",
    "\n",
    "\n",
    "pweights = split_weights_client(pweights,client_net.state_dict())\n",
    "client_net.load_state_dict(pweights)\n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "client_net = VGG('Unit','VGG5_MNIST',2,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 导入torch官网参数\n",
    "from torchvision.models import vit_b_16,ViT_B_16_Weights\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = '/home/dengruijun/data/project/data/torch_models/'\n",
    "vit_model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "print(vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])\n"
     ]
    }
   ],
   "source": [
    "# 查看官网参数内容\n",
    "unit_net_route = '/home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-c867db91.pth'\n",
    "weights = torch.load(unit_net_route)\n",
    "print(weights.keys())\n",
    "# print(weights.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.0.weight', 'encoder.layers.encoder_layer_0.mlp.0.bias', 'encoder.layers.encoder_layer_0.mlp.3.weight', 'encoder.layers.encoder_layer_0.mlp.3.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.0.weight', 'encoder.layers.encoder_layer_1.mlp.0.bias', 'encoder.layers.encoder_layer_1.mlp.3.weight', 'encoder.layers.encoder_layer_1.mlp.3.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.0.weight', 'encoder.layers.encoder_layer_2.mlp.0.bias', 'encoder.layers.encoder_layer_2.mlp.3.weight', 'encoder.layers.encoder_layer_2.mlp.3.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.0.weight', 'encoder.layers.encoder_layer_3.mlp.0.bias', 'encoder.layers.encoder_layer_3.mlp.3.weight', 'encoder.layers.encoder_layer_3.mlp.3.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.0.weight', 'encoder.layers.encoder_layer_4.mlp.0.bias', 'encoder.layers.encoder_layer_4.mlp.3.weight', 'encoder.layers.encoder_layer_4.mlp.3.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.0.weight', 'encoder.layers.encoder_layer_5.mlp.0.bias', 'encoder.layers.encoder_layer_5.mlp.3.weight', 'encoder.layers.encoder_layer_5.mlp.3.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.0.weight', 'encoder.layers.encoder_layer_6.mlp.0.bias', 'encoder.layers.encoder_layer_6.mlp.3.weight', 'encoder.layers.encoder_layer_6.mlp.3.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.0.weight', 'encoder.layers.encoder_layer_7.mlp.0.bias', 'encoder.layers.encoder_layer_7.mlp.3.weight', 'encoder.layers.encoder_layer_7.mlp.3.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.0.weight', 'encoder.layers.encoder_layer_8.mlp.0.bias', 'encoder.layers.encoder_layer_8.mlp.3.weight', 'encoder.layers.encoder_layer_8.mlp.3.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.0.weight', 'encoder.layers.encoder_layer_9.mlp.0.bias', 'encoder.layers.encoder_layer_9.mlp.3.weight', 'encoder.layers.encoder_layer_9.mlp.3.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.0.weight', 'encoder.layers.encoder_layer_10.mlp.0.bias', 'encoder.layers.encoder_layer_10.mlp.3.weight', 'encoder.layers.encoder_layer_10.mlp.3.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.0.weight', 'encoder.layers.encoder_layer_11.mlp.0.bias', 'encoder.layers.encoder_layer_11.mlp.3.weight', 'encoder.layers.encoder_layer_11.mlp.3.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])\n"
     ]
    }
   ],
   "source": [
    "# 用我自己改的ViT模型代码\n",
    "vit_model = ViTb_16()\n",
    "print(vit_model)\n",
    "vit_model.load_state_dict(weights) # 可以直接load 官网参数，没有问题。\n",
    "print(vit_model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切割后模型 参数加载\n",
    "unit_net_route = '/home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-c867db91-drj.pth'\n",
    "split_layer = 13\n",
    "pweights = torch.load(unit_net_route)\n",
    "vit_model = ViTb_16(split_layer=split_layer)\n",
    "print(vit_model)\n",
    "\n",
    "if split_layer < 13:\n",
    "    pweights = split_weights_client(pweights, vit_model.state_dict())\n",
    "vit_model.load_state_dict(pweights,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_token\n",
      "class_token\n",
      "conv_proj.weight\n",
      "conv_proj.weight\n",
      "conv_proj.bias\n",
      "conv_proj.bias\n",
      "encoder.pos_embedding\n",
      "encoder.pos_embedding\n",
      "encoder.layers.encoder_layer_0.ln_1.weight\n",
      "encoder.layers.encoder_layer_0.ln_1.weight\n",
      "encoder.layers.encoder_layer_0.ln_1.bias\n",
      "encoder.layers.encoder_layer_0.ln_1.bias\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_0.ln_2.weight\n",
      "encoder.layers.encoder_layer_0.ln_2.weight\n",
      "encoder.layers.encoder_layer_0.ln_2.bias\n",
      "encoder.layers.encoder_layer_0.ln_2.bias\n",
      "encoder.layers.encoder_layer_0.mlp.0.weight\n",
      "encoder.layers.encoder_layer_0.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_0.mlp.0.bias\n",
      "encoder.layers.encoder_layer_0.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_0.mlp.3.weight\n",
      "encoder.layers.encoder_layer_0.mlp.3.weight\n",
      "encoder.layers.encoder_layer_0.mlp.3.bias\n",
      "encoder.layers.encoder_layer_0.mlp.3.bias\n",
      "encoder.layers.encoder_layer_1.ln_1.weight\n",
      "encoder.layers.encoder_layer_1.ln_1.weight\n",
      "encoder.layers.encoder_layer_1.ln_1.bias\n",
      "encoder.layers.encoder_layer_1.ln_1.bias\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_1.ln_2.weight\n",
      "encoder.layers.encoder_layer_1.ln_2.weight\n",
      "encoder.layers.encoder_layer_1.ln_2.bias\n",
      "encoder.layers.encoder_layer_1.ln_2.bias\n",
      "encoder.layers.encoder_layer_1.mlp.0.weight\n",
      "encoder.layers.encoder_layer_1.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_1.mlp.0.bias\n",
      "encoder.layers.encoder_layer_1.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_1.mlp.3.weight\n",
      "encoder.layers.encoder_layer_1.mlp.3.weight\n",
      "encoder.layers.encoder_layer_1.mlp.3.bias\n",
      "encoder.layers.encoder_layer_1.mlp.3.bias\n",
      "encoder.layers.encoder_layer_2.ln_1.weight\n",
      "encoder.layers.encoder_layer_2.ln_1.weight\n",
      "encoder.layers.encoder_layer_2.ln_1.bias\n",
      "encoder.layers.encoder_layer_2.ln_1.bias\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_2.ln_2.weight\n",
      "encoder.layers.encoder_layer_2.ln_2.weight\n",
      "encoder.layers.encoder_layer_2.ln_2.bias\n",
      "encoder.layers.encoder_layer_2.ln_2.bias\n",
      "encoder.layers.encoder_layer_2.mlp.0.weight\n",
      "encoder.layers.encoder_layer_2.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_2.mlp.0.bias\n",
      "encoder.layers.encoder_layer_2.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_2.mlp.3.weight\n",
      "encoder.layers.encoder_layer_2.mlp.3.weight\n",
      "encoder.layers.encoder_layer_2.mlp.3.bias\n",
      "encoder.layers.encoder_layer_2.mlp.3.bias\n",
      "encoder.layers.encoder_layer_3.ln_1.weight\n",
      "encoder.layers.encoder_layer_3.ln_1.weight\n",
      "encoder.layers.encoder_layer_3.ln_1.bias\n",
      "encoder.layers.encoder_layer_3.ln_1.bias\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_3.ln_2.weight\n",
      "encoder.layers.encoder_layer_3.ln_2.weight\n",
      "encoder.layers.encoder_layer_3.ln_2.bias\n",
      "encoder.layers.encoder_layer_3.ln_2.bias\n",
      "encoder.layers.encoder_layer_3.mlp.0.weight\n",
      "encoder.layers.encoder_layer_3.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_3.mlp.0.bias\n",
      "encoder.layers.encoder_layer_3.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_3.mlp.3.weight\n",
      "encoder.layers.encoder_layer_3.mlp.3.weight\n",
      "encoder.layers.encoder_layer_3.mlp.3.bias\n",
      "encoder.layers.encoder_layer_3.mlp.3.bias\n",
      "encoder.layers.encoder_layer_4.ln_1.weight\n",
      "encoder.layers.encoder_layer_4.ln_1.weight\n",
      "encoder.layers.encoder_layer_4.ln_1.bias\n",
      "encoder.layers.encoder_layer_4.ln_1.bias\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_4.ln_2.weight\n",
      "encoder.layers.encoder_layer_4.ln_2.weight\n",
      "encoder.layers.encoder_layer_4.ln_2.bias\n",
      "encoder.layers.encoder_layer_4.ln_2.bias\n",
      "encoder.layers.encoder_layer_4.mlp.0.weight\n",
      "encoder.layers.encoder_layer_4.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_4.mlp.0.bias\n",
      "encoder.layers.encoder_layer_4.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_4.mlp.3.weight\n",
      "encoder.layers.encoder_layer_4.mlp.3.weight\n",
      "encoder.layers.encoder_layer_4.mlp.3.bias\n",
      "encoder.layers.encoder_layer_4.mlp.3.bias\n",
      "encoder.layers.encoder_layer_5.ln_1.weight\n",
      "encoder.layers.encoder_layer_5.ln_1.weight\n",
      "encoder.layers.encoder_layer_5.ln_1.bias\n",
      "encoder.layers.encoder_layer_5.ln_1.bias\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_5.ln_2.weight\n",
      "encoder.layers.encoder_layer_5.ln_2.weight\n",
      "encoder.layers.encoder_layer_5.ln_2.bias\n",
      "encoder.layers.encoder_layer_5.ln_2.bias\n",
      "encoder.layers.encoder_layer_5.mlp.0.weight\n",
      "encoder.layers.encoder_layer_5.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_5.mlp.0.bias\n",
      "encoder.layers.encoder_layer_5.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_5.mlp.3.weight\n",
      "encoder.layers.encoder_layer_5.mlp.3.weight\n",
      "encoder.layers.encoder_layer_5.mlp.3.bias\n",
      "encoder.layers.encoder_layer_5.mlp.3.bias\n",
      "encoder.layers.encoder_layer_6.ln_1.weight\n",
      "encoder.layers.encoder_layer_6.ln_1.weight\n",
      "encoder.layers.encoder_layer_6.ln_1.bias\n",
      "encoder.layers.encoder_layer_6.ln_1.bias\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_6.ln_2.weight\n",
      "encoder.layers.encoder_layer_6.ln_2.weight\n",
      "encoder.layers.encoder_layer_6.ln_2.bias\n",
      "encoder.layers.encoder_layer_6.ln_2.bias\n",
      "encoder.layers.encoder_layer_6.mlp.0.weight\n",
      "encoder.layers.encoder_layer_6.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_6.mlp.0.bias\n",
      "encoder.layers.encoder_layer_6.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_6.mlp.3.weight\n",
      "encoder.layers.encoder_layer_6.mlp.3.weight\n",
      "encoder.layers.encoder_layer_6.mlp.3.bias\n",
      "encoder.layers.encoder_layer_6.mlp.3.bias\n",
      "encoder.layers.encoder_layer_7.ln_1.weight\n",
      "encoder.layers.encoder_layer_7.ln_1.weight\n",
      "encoder.layers.encoder_layer_7.ln_1.bias\n",
      "encoder.layers.encoder_layer_7.ln_1.bias\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_7.ln_2.weight\n",
      "encoder.layers.encoder_layer_7.ln_2.weight\n",
      "encoder.layers.encoder_layer_7.ln_2.bias\n",
      "encoder.layers.encoder_layer_7.ln_2.bias\n",
      "encoder.layers.encoder_layer_7.mlp.0.weight\n",
      "encoder.layers.encoder_layer_7.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_7.mlp.0.bias\n",
      "encoder.layers.encoder_layer_7.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_7.mlp.3.weight\n",
      "encoder.layers.encoder_layer_7.mlp.3.weight\n",
      "encoder.layers.encoder_layer_7.mlp.3.bias\n",
      "encoder.layers.encoder_layer_7.mlp.3.bias\n",
      "encoder.layers.encoder_layer_8.ln_1.weight\n",
      "encoder.layers.encoder_layer_8.ln_1.weight\n",
      "encoder.layers.encoder_layer_8.ln_1.bias\n",
      "encoder.layers.encoder_layer_8.ln_1.bias\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_8.ln_2.weight\n",
      "encoder.layers.encoder_layer_8.ln_2.weight\n",
      "encoder.layers.encoder_layer_8.ln_2.bias\n",
      "encoder.layers.encoder_layer_8.ln_2.bias\n",
      "encoder.layers.encoder_layer_8.mlp.0.weight\n",
      "encoder.layers.encoder_layer_8.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_8.mlp.0.bias\n",
      "encoder.layers.encoder_layer_8.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_8.mlp.3.weight\n",
      "encoder.layers.encoder_layer_8.mlp.3.weight\n",
      "encoder.layers.encoder_layer_8.mlp.3.bias\n",
      "encoder.layers.encoder_layer_8.mlp.3.bias\n",
      "encoder.layers.encoder_layer_9.ln_1.weight\n",
      "encoder.layers.encoder_layer_9.ln_1.weight\n",
      "encoder.layers.encoder_layer_9.ln_1.bias\n",
      "encoder.layers.encoder_layer_9.ln_1.bias\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_9.ln_2.weight\n",
      "encoder.layers.encoder_layer_9.ln_2.weight\n",
      "encoder.layers.encoder_layer_9.ln_2.bias\n",
      "encoder.layers.encoder_layer_9.ln_2.bias\n",
      "encoder.layers.encoder_layer_9.mlp.0.weight\n",
      "encoder.layers.encoder_layer_9.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_9.mlp.0.bias\n",
      "encoder.layers.encoder_layer_9.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_9.mlp.3.weight\n",
      "encoder.layers.encoder_layer_9.mlp.3.weight\n",
      "encoder.layers.encoder_layer_9.mlp.3.bias\n",
      "encoder.layers.encoder_layer_9.mlp.3.bias\n",
      "encoder.layers.encoder_layer_10.ln_1.weight\n",
      "encoder.layers.encoder_layer_10.ln_1.weight\n",
      "encoder.layers.encoder_layer_10.ln_1.bias\n",
      "encoder.layers.encoder_layer_10.ln_1.bias\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_10.ln_2.weight\n",
      "encoder.layers.encoder_layer_10.ln_2.weight\n",
      "encoder.layers.encoder_layer_10.ln_2.bias\n",
      "encoder.layers.encoder_layer_10.ln_2.bias\n",
      "encoder.layers.encoder_layer_10.mlp.0.weight\n",
      "encoder.layers.encoder_layer_10.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_10.mlp.0.bias\n",
      "encoder.layers.encoder_layer_10.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_10.mlp.3.weight\n",
      "encoder.layers.encoder_layer_10.mlp.3.weight\n",
      "encoder.layers.encoder_layer_10.mlp.3.bias\n",
      "encoder.layers.encoder_layer_10.mlp.3.bias\n",
      "encoder.layers.encoder_layer_11.ln_1.weight\n",
      "encoder.layers.encoder_layer_11.ln_1.weight\n",
      "encoder.layers.encoder_layer_11.ln_1.bias\n",
      "encoder.layers.encoder_layer_11.ln_1.bias\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_11.ln_2.weight\n",
      "encoder.layers.encoder_layer_11.ln_2.weight\n",
      "encoder.layers.encoder_layer_11.ln_2.bias\n",
      "encoder.layers.encoder_layer_11.ln_2.bias\n",
      "encoder.layers.encoder_layer_11.mlp.0.weight\n",
      "encoder.layers.encoder_layer_11.mlp.linear_1.weight\n",
      "encoder.layers.encoder_layer_11.mlp.0.bias\n",
      "encoder.layers.encoder_layer_11.mlp.linear_1.bias\n",
      "encoder.layers.encoder_layer_11.mlp.3.weight\n",
      "encoder.layers.encoder_layer_11.mlp.3.weight\n",
      "encoder.layers.encoder_layer_11.mlp.3.bias\n",
      "encoder.layers.encoder_layer_11.mlp.3.bias\n",
      "encoder.ln.weight\n",
      "encoder.ln.weight\n",
      "encoder.ln.bias\n",
      "encoder.ln.bias\n",
      "heads.head.weight\n",
      "heads.head.weight\n",
      "heads.head.bias\n",
      "heads.head.bias\n",
      "class_token \t\t\t class_token\n",
      "conv_proj.weight \t\t\t conv_proj.weight\n",
      "conv_proj.bias \t\t\t conv_proj.bias\n",
      "encoder.pos_embedding \t\t\t encoder.pos_embedding\n",
      "encoder.layers.encoder_layer_0.ln_1.weight \t\t\t encoder.layers.encoder_layer_0.ln_1.weight\n",
      "encoder.layers.encoder_layer_0.ln_1.bias \t\t\t encoder.layers.encoder_layer_0.ln_1.bias\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_0.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_0.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_0.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_0.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_0.ln_2.weight \t\t\t encoder.layers.encoder_layer_0.ln_2.weight\n",
      "encoder.layers.encoder_layer_0.ln_2.bias \t\t\t encoder.layers.encoder_layer_0.ln_2.bias\n",
      "encoder.layers.encoder_layer_0.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_0.mlp.0.weight\n",
      "encoder.layers.encoder_layer_0.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_0.mlp.0.bias\n",
      "encoder.layers.encoder_layer_0.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_0.mlp.3.weight\n",
      "encoder.layers.encoder_layer_0.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_0.mlp.3.bias\n",
      "encoder.layers.encoder_layer_1.ln_1.weight \t\t\t encoder.layers.encoder_layer_1.ln_1.weight\n",
      "encoder.layers.encoder_layer_1.ln_1.bias \t\t\t encoder.layers.encoder_layer_1.ln_1.bias\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_1.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_1.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_1.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_1.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_1.ln_2.weight \t\t\t encoder.layers.encoder_layer_1.ln_2.weight\n",
      "encoder.layers.encoder_layer_1.ln_2.bias \t\t\t encoder.layers.encoder_layer_1.ln_2.bias\n",
      "encoder.layers.encoder_layer_1.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_1.mlp.0.weight\n",
      "encoder.layers.encoder_layer_1.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_1.mlp.0.bias\n",
      "encoder.layers.encoder_layer_1.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_1.mlp.3.weight\n",
      "encoder.layers.encoder_layer_1.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_1.mlp.3.bias\n",
      "encoder.layers.encoder_layer_2.ln_1.weight \t\t\t encoder.layers.encoder_layer_2.ln_1.weight\n",
      "encoder.layers.encoder_layer_2.ln_1.bias \t\t\t encoder.layers.encoder_layer_2.ln_1.bias\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_2.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_2.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_2.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_2.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_2.ln_2.weight \t\t\t encoder.layers.encoder_layer_2.ln_2.weight\n",
      "encoder.layers.encoder_layer_2.ln_2.bias \t\t\t encoder.layers.encoder_layer_2.ln_2.bias\n",
      "encoder.layers.encoder_layer_2.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_2.mlp.0.weight\n",
      "encoder.layers.encoder_layer_2.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_2.mlp.0.bias\n",
      "encoder.layers.encoder_layer_2.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_2.mlp.3.weight\n",
      "encoder.layers.encoder_layer_2.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_2.mlp.3.bias\n",
      "encoder.layers.encoder_layer_3.ln_1.weight \t\t\t encoder.layers.encoder_layer_3.ln_1.weight\n",
      "encoder.layers.encoder_layer_3.ln_1.bias \t\t\t encoder.layers.encoder_layer_3.ln_1.bias\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_3.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_3.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_3.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_3.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_3.ln_2.weight \t\t\t encoder.layers.encoder_layer_3.ln_2.weight\n",
      "encoder.layers.encoder_layer_3.ln_2.bias \t\t\t encoder.layers.encoder_layer_3.ln_2.bias\n",
      "encoder.layers.encoder_layer_3.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_3.mlp.0.weight\n",
      "encoder.layers.encoder_layer_3.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_3.mlp.0.bias\n",
      "encoder.layers.encoder_layer_3.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_3.mlp.3.weight\n",
      "encoder.layers.encoder_layer_3.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_3.mlp.3.bias\n",
      "encoder.layers.encoder_layer_4.ln_1.weight \t\t\t encoder.layers.encoder_layer_4.ln_1.weight\n",
      "encoder.layers.encoder_layer_4.ln_1.bias \t\t\t encoder.layers.encoder_layer_4.ln_1.bias\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_4.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_4.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_4.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_4.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_4.ln_2.weight \t\t\t encoder.layers.encoder_layer_4.ln_2.weight\n",
      "encoder.layers.encoder_layer_4.ln_2.bias \t\t\t encoder.layers.encoder_layer_4.ln_2.bias\n",
      "encoder.layers.encoder_layer_4.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_4.mlp.0.weight\n",
      "encoder.layers.encoder_layer_4.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_4.mlp.0.bias\n",
      "encoder.layers.encoder_layer_4.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_4.mlp.3.weight\n",
      "encoder.layers.encoder_layer_4.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_4.mlp.3.bias\n",
      "encoder.layers.encoder_layer_5.ln_1.weight \t\t\t encoder.layers.encoder_layer_5.ln_1.weight\n",
      "encoder.layers.encoder_layer_5.ln_1.bias \t\t\t encoder.layers.encoder_layer_5.ln_1.bias\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_5.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_5.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_5.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_5.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_5.ln_2.weight \t\t\t encoder.layers.encoder_layer_5.ln_2.weight\n",
      "encoder.layers.encoder_layer_5.ln_2.bias \t\t\t encoder.layers.encoder_layer_5.ln_2.bias\n",
      "encoder.layers.encoder_layer_5.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_5.mlp.0.weight\n",
      "encoder.layers.encoder_layer_5.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_5.mlp.0.bias\n",
      "encoder.layers.encoder_layer_5.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_5.mlp.3.weight\n",
      "encoder.layers.encoder_layer_5.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_5.mlp.3.bias\n",
      "encoder.layers.encoder_layer_6.ln_1.weight \t\t\t encoder.layers.encoder_layer_6.ln_1.weight\n",
      "encoder.layers.encoder_layer_6.ln_1.bias \t\t\t encoder.layers.encoder_layer_6.ln_1.bias\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_6.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_6.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_6.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_6.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_6.ln_2.weight \t\t\t encoder.layers.encoder_layer_6.ln_2.weight\n",
      "encoder.layers.encoder_layer_6.ln_2.bias \t\t\t encoder.layers.encoder_layer_6.ln_2.bias\n",
      "encoder.layers.encoder_layer_6.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_6.mlp.0.weight\n",
      "encoder.layers.encoder_layer_6.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_6.mlp.0.bias\n",
      "encoder.layers.encoder_layer_6.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_6.mlp.3.weight\n",
      "encoder.layers.encoder_layer_6.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_6.mlp.3.bias\n",
      "encoder.layers.encoder_layer_7.ln_1.weight \t\t\t encoder.layers.encoder_layer_7.ln_1.weight\n",
      "encoder.layers.encoder_layer_7.ln_1.bias \t\t\t encoder.layers.encoder_layer_7.ln_1.bias\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_7.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_7.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_7.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_7.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_7.ln_2.weight \t\t\t encoder.layers.encoder_layer_7.ln_2.weight\n",
      "encoder.layers.encoder_layer_7.ln_2.bias \t\t\t encoder.layers.encoder_layer_7.ln_2.bias\n",
      "encoder.layers.encoder_layer_7.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_7.mlp.0.weight\n",
      "encoder.layers.encoder_layer_7.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_7.mlp.0.bias\n",
      "encoder.layers.encoder_layer_7.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_7.mlp.3.weight\n",
      "encoder.layers.encoder_layer_7.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_7.mlp.3.bias\n",
      "encoder.layers.encoder_layer_8.ln_1.weight \t\t\t encoder.layers.encoder_layer_8.ln_1.weight\n",
      "encoder.layers.encoder_layer_8.ln_1.bias \t\t\t encoder.layers.encoder_layer_8.ln_1.bias\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_8.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_8.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_8.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_8.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_8.ln_2.weight \t\t\t encoder.layers.encoder_layer_8.ln_2.weight\n",
      "encoder.layers.encoder_layer_8.ln_2.bias \t\t\t encoder.layers.encoder_layer_8.ln_2.bias\n",
      "encoder.layers.encoder_layer_8.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_8.mlp.0.weight\n",
      "encoder.layers.encoder_layer_8.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_8.mlp.0.bias\n",
      "encoder.layers.encoder_layer_8.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_8.mlp.3.weight\n",
      "encoder.layers.encoder_layer_8.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_8.mlp.3.bias\n",
      "encoder.layers.encoder_layer_9.ln_1.weight \t\t\t encoder.layers.encoder_layer_9.ln_1.weight\n",
      "encoder.layers.encoder_layer_9.ln_1.bias \t\t\t encoder.layers.encoder_layer_9.ln_1.bias\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_9.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_9.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_9.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_9.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_9.ln_2.weight \t\t\t encoder.layers.encoder_layer_9.ln_2.weight\n",
      "encoder.layers.encoder_layer_9.ln_2.bias \t\t\t encoder.layers.encoder_layer_9.ln_2.bias\n",
      "encoder.layers.encoder_layer_9.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_9.mlp.0.weight\n",
      "encoder.layers.encoder_layer_9.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_9.mlp.0.bias\n",
      "encoder.layers.encoder_layer_9.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_9.mlp.3.weight\n",
      "encoder.layers.encoder_layer_9.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_9.mlp.3.bias\n",
      "encoder.layers.encoder_layer_10.ln_1.weight \t\t\t encoder.layers.encoder_layer_10.ln_1.weight\n",
      "encoder.layers.encoder_layer_10.ln_1.bias \t\t\t encoder.layers.encoder_layer_10.ln_1.bias\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_10.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_10.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_10.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_10.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_10.ln_2.weight \t\t\t encoder.layers.encoder_layer_10.ln_2.weight\n",
      "encoder.layers.encoder_layer_10.ln_2.bias \t\t\t encoder.layers.encoder_layer_10.ln_2.bias\n",
      "encoder.layers.encoder_layer_10.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_10.mlp.0.weight\n",
      "encoder.layers.encoder_layer_10.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_10.mlp.0.bias\n",
      "encoder.layers.encoder_layer_10.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_10.mlp.3.weight\n",
      "encoder.layers.encoder_layer_10.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_10.mlp.3.bias\n",
      "encoder.layers.encoder_layer_11.ln_1.weight \t\t\t encoder.layers.encoder_layer_11.ln_1.weight\n",
      "encoder.layers.encoder_layer_11.ln_1.bias \t\t\t encoder.layers.encoder_layer_11.ln_1.bias\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_weight \t\t\t encoder.layers.encoder_layer_11.self_attention.in_proj_weight\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_bias \t\t\t encoder.layers.encoder_layer_11.self_attention.in_proj_bias\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.weight \t\t\t encoder.layers.encoder_layer_11.self_attention.out_proj.weight\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.bias \t\t\t encoder.layers.encoder_layer_11.self_attention.out_proj.bias\n",
      "encoder.layers.encoder_layer_11.ln_2.weight \t\t\t encoder.layers.encoder_layer_11.ln_2.weight\n",
      "encoder.layers.encoder_layer_11.ln_2.bias \t\t\t encoder.layers.encoder_layer_11.ln_2.bias\n",
      "encoder.layers.encoder_layer_11.mlp.linear_1.weight \t\t\t encoder.layers.encoder_layer_11.mlp.0.weight\n",
      "encoder.layers.encoder_layer_11.mlp.linear_1.bias \t\t\t encoder.layers.encoder_layer_11.mlp.0.bias\n",
      "encoder.layers.encoder_layer_11.mlp.linear_2.weight \t\t\t encoder.layers.encoder_layer_11.mlp.3.weight\n",
      "encoder.layers.encoder_layer_11.mlp.linear_2.bias \t\t\t encoder.layers.encoder_layer_11.mlp.3.bias\n",
      "encoder.ln.weight \t\t\t encoder.ln.weight\n",
      "encoder.ln.bias \t\t\t encoder.ln.bias\n",
      "heads.head.weight \t\t\t heads.head.weight\n",
      "heads.head.bias \t\t\t heads.head.bias\n"
     ]
    }
   ],
   "source": [
    "# 模型参数key修改： linear_1.weight -> 3.weight\n",
    "unit_net_route = '/home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-c867db91.pth'\n",
    "new_unit_net_route_align = '/home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-c867db91-drj.pth'\n",
    "# split_layer = 1\n",
    "pweights = torch.load(unit_net_route)\n",
    "vit_model = ViTb_16()\n",
    "cweights = vit_model.state_dict() \n",
    "\n",
    "new_key = {}\n",
    "for key in cweights.keys():\n",
    "    print(key)\n",
    "    print(key.replace('mlp.0','mlp.linear_1'))\n",
    "    if('mlp.0' in key):\n",
    "        new_key[key] = pweights[key.replace('mlp.0','mlp.linear_1')]\n",
    "    elif('mlp.3' in key):\n",
    "        new_key[key] = pweights[key.replace('mlp.3','mlp.linear_2')]\n",
    "    else:\n",
    "        new_key[key] = pweights[key]\n",
    "torch.save(new_key, new_unit_net_route_align)\n",
    "\n",
    "new_key = {}\n",
    "for keyp,keyc in zip(pweights.keys(),vit_model.state_dict().keys()):\n",
    "    print(keyp,'\\t\\t\\t',keyc)\n",
    "\n",
    "\n",
    "# for i in range(2):\n",
    "#     for type in [\"weight\", \"bias\"]:\n",
    "#         old_key = f\"{prefix}linear_{i+1}.{type}\"\n",
    "#         new_key = f\"{prefix}{3*i}.{type}\"\n",
    "#         if old_key in state_dict:\n",
    "#             state_dict[new_key] = state_dict.pop(old_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 看看面相其他数据集的模型大小\n",
    "# cifar10\n",
    "vit_model = ViTb_16()\n",
    "print(vit_model)\n",
    "torch.save(vit_model.state_dict(),'/home/dengruijun/data/project/data/torch_models/hub/checkpoints/vit_b_16-cifar10-8*8*3.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 模型信息计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数的平均第二范数: 7.32628158852458\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 计算模型参数的平均第二范数\n",
    "def average_l2_norm(model):\n",
    "    total_l2_norm = 0.0\n",
    "    num_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            l2_norm = torch.norm(param, p=2)\n",
    "            total_l2_norm += l2_norm.item()\n",
    "            num_params += 1\n",
    "\n",
    "    avg_l2_norm = total_l2_norm / num_params if num_params > 0 else 0.0\n",
    "    return avg_l2_norm\n",
    "\n",
    "def average_l2_norm_state(state_dict):\n",
    "    total_l2_norm = 0.0\n",
    "    num_params = 0\n",
    "\n",
    "    for param_tensor in state_dict.values():\n",
    "        if param_tensor.requires_grad:\n",
    "            l2_norm = torch.norm(param_tensor, p=2)\n",
    "            total_l2_norm += l2_norm.item()\n",
    "            num_params += 1\n",
    "    avg_l2_norm = total_l2_norm / num_params if num_params > 0 else -1\n",
    "    return avg_l2_norm\n",
    "\n",
    "# 打印平均第二范数\n",
    "# model\n",
    "avg_l2_norm = average_l2_norm(client_net)\n",
    "# avg_l2_norm = average_l2_norm_state(pweights)\n",
    "print(f\"模型参数的平均第二范数: {avg_l2_norm}\")\n",
    "# print(pweights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型参数数目\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# 计算模型每层输出的大小\n",
    "def model_output_size(model, input):\n",
    "    input = torch.randn_like(input)\n",
    "    output_feat = model(input)\n",
    "    return output_feat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数数目: 85975528\n",
      "第0层输出的大小: torch.Size([1, 1, 768])\n",
      "第1层输出的大小: torch.Size([1, 2, 768])\n",
      "第2层输出的大小: torch.Size([1, 2, 768])\n",
      "第3层输出的大小: torch.Size([1, 2, 768])\n",
      "第4层输出的大小: torch.Size([1, 2, 768])\n",
      "第5层输出的大小: torch.Size([1, 2, 768])\n",
      "第6层输出的大小: torch.Size([1, 2, 768])\n",
      "第7层输出的大小: torch.Size([1, 2, 768])\n",
      "第8层输出的大小: torch.Size([1, 2, 768])\n",
      "第9层输出的大小: torch.Size([1, 2, 768])\n",
      "第10层输出的大小: torch.Size([1, 2, 768])\n",
      "第11层输出的大小: torch.Size([1, 2, 768])\n",
      "第12层输出的大小: torch.Size([1, 2, 768])\n"
     ]
    }
   ],
   "source": [
    "# 测试vit\n",
    "vit_model = ViTb_16(split_layer=13)\n",
    "\n",
    "model_param_num = count_parameters(vit_model)\n",
    "print(f\"模型参数数目: {model_param_num}\")\n",
    "\n",
    "for i in range(13):\n",
    "    vit_model = ViTb_16(split_layer=i)\n",
    "    print(f\"第{i}层输出的大小: {model_output_size(vit_model, torch.randn(1, 3, 8, 8))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task select获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "client_net cweights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked'])\n",
      "len unit_net weights:  25\n",
      "len client_net cweights:  14\n",
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "client_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      "  (denses): Sequential()\n",
      ")\n",
      "unit_net weights:  odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.5.weight', 'features.5.bias', 'features.5.running_mean', 'features.5.running_var', 'features.5.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.9.weight', 'features.9.bias', 'features.9.running_mean', 'features.9.running_var', 'features.9.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "server_net cweights:  odict_keys(['features.1.weight', 'features.1.bias', 'features.2.weight', 'features.2.bias', 'features.2.running_mean', 'features.2.running_var', 'features.2.num_batches_tracked', 'denses.0.weight', 'denses.0.bias', 'denses.1.weight', 'denses.1.bias'])\n",
      "len unit_net weights:  25\n",
      "len server_net cweights:  11\n",
      "server_net:  VGG(\n",
      "  (features): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (denses): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "=> loading decoder model '/home/dengruijun/data/FinTech/PP-Split/results/inverse-model-results-20240414/VGG5/2/Decoder-layer2.pth'\n",
      "unit_net_route: /home/dengruijun/data/FinTech/PP-Split/results/trained_models/ImageClassification/VGG5/BN+Tanh/VGG5-params-20ep.pth\n"
     ]
    }
   ],
   "source": [
    "data_msg = get_dataloader(args)\n",
    "model_msg = get_models(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
