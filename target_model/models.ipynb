{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '48'\n",
    "# 导入各个指标\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "# utils\n",
    "from ppsplit.utils.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入各个baseline模型及其数据集预处理方法\n",
    "# 模型\n",
    "from target_model.models.splitnn_utils import split_weights_client\n",
    "from target_model.models.VGG import VGG,VGG5Decoder,model_cfg\n",
    "from target_model.models.BankNet import BankNet1,BankNetDecoder1,bank_cfg\n",
    "from target_model.models.CreditNet import CreditNet1,CreditNetDecoder1,credit_cfg\n",
    "from target_model.models.PurchaseNet import PurchaseClassifier1,PurchaseDecoder1,purchase_cfg\n",
    "from target_model.models.IrisNet import IrisNet,IrisNetDecoder,Iris_cfg\n",
    "from target_model.models.ResNet import resnet18,resnet34,resnet50,InversionNet,resnet_model_cfg\n",
    "from target_model.models.AlexNet import AlexNet_MNIST\n",
    "\n",
    "\n",
    "# 数据预处理方法\n",
    "from target_model.data_preprocessing.preprocess_cifar10 import get_cifar10_normalize,deprocess\n",
    "from target_model.data_preprocessing.preprocess_bank import bank_dataset,preprocess_bank,preprocess_bank_dataset,tabinfo_bank\n",
    "from target_model.data_preprocessing.preprocess_credit import preprocess_credit,tabinfo_credit\n",
    "from target_model.data_preprocessing.preprocess_purchase import preprocess_purchase,tabinfo_purchase\n",
    "from target_model.data_preprocessing.preprocess_Iris import preprocess_Iris, tabinfo_Iris\n",
    "from target_model.data_preprocessing.dataset import get_one_data\n",
    "\n",
    "# utils\n",
    "from  ppsplit.utils.utils import create_dir\n",
    "\n",
    "\n",
    "# model_select\n",
    "from target_model.task_select import get_dataloader_and_model,get_dataloader_and_model, \\\n",
    "    get_dataloader,get_models,get_infotopo_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "{'device': device(type='cuda', index=0), 'dataset': 'purchase', 'model': 'VGG9', 'result_dir': '20240702-effectiveInfo/', 'oneData_bs': 500, 'test_bs': 500, 'train_bs': 1, 'noise_scale': 0, 'split_layer': 5, 'test_num': 'effectiveInfo1.8.1', 'no_dense': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "        'device':torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        # 'device':torch.device(\"cpu\"),\n",
    "        # 'dataset':'CIFAR10',\n",
    "        # 'dataset':'bank',\n",
    "        # 'dataset':'credit',\n",
    "        'dataset':'purchase',\n",
    "        # 'dataset':'Iris',\n",
    "        # 'model': 'ResNet18',\n",
    "        # 'model': 'VGG5',\n",
    "        'model': 'VGG9',\n",
    "        # 'result_dir': '20240702-FIL/',\n",
    "        'result_dir': '20240702-effectiveInfo/',\n",
    "        'oneData_bs': 500,\n",
    "        'test_bs': 500,\n",
    "        'train_bs': 1,\n",
    "        'noise_scale': 0, # 防护措施\n",
    "        'split_layer': 5,\n",
    "        # 'test_num': 'invdFIL', # MI, invdFIL, distCor, ULoss,  # split layer [2,3,5,7,9,11] for ResNet18\n",
    "        'test_num': 'effectiveInfo1.8.1',\n",
    "        'no_dense':True,\n",
    "        }\n",
    "print(args['device'])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unit layers: 14\n",
      "Split layer: -1\n",
      "ResNet(\n",
      "  (selected_layers): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate=none)\n",
      "    (3): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# resnet18\n",
    "net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "# inet = InversionNet(in_c=64, upconv_channels=[(128, 'same'), (3, 'same')], last_activation=None)\n",
    "inet = InversionNet(last_activation=None)\n",
    "print(inet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unit layers: 14\n",
      "Split layer: -1\n",
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters', 'datamodule_hparams_name', 'datamodule_hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "# 加载一下模型参数\n",
    "# resnet18 cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/CIFAR10-models/ResNet18/32bs-ep20-relu-max-adam/resnet18-drj.pth' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet18 cifar100\n",
    "\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR100/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet34 cifar100\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet34/CIFAR100/resnet34-drj-align.pth'\n",
    "# client_net = resnet34(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet50 cifar100\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet50/CIFAR100/resnet50-drj-align.pth'\n",
    "# # client_net = resnet50(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnet18 20ep cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/epoch=14resnet18-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "\n",
    "# resnet18 20ep narrow cifar10\n",
    "# unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/epoch=16resnet18_narrow-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "# new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/resnet18-drj.pth'\n",
    "# new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_narrow/CIFAR10/resnet18-drj-align.pth'\n",
    "# client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "# resnett18 20ep wide cifar10\n",
    "unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/epoch=14resnet18_wide-drj.pth.ckpt' # VGG5-BN+Tanh # 存储的是模型参数，不包括模型结构\n",
    "new_unit_net_route = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/resnet18-drj.pth'\n",
    "new_unit_net_route_align = '/home/dengruijun/data/FinTech/PP-Split/results/trained_models/ResNet/resnet18_wide/CIFAR10/resnet18-drj-align.pth'\n",
    "client_net = resnet18(pretrained=False, split_layer=-1, bottleneck_dim=-1, num_classes=10, activation='gelu', pooling='avg')\n",
    "\n",
    "\n",
    "# 提取state_dict\n",
    "pweights = torch.load(unit_net_route)\n",
    "print(pweights.keys())\n",
    "state_dict = pweights['state_dict']\n",
    "torch.save(state_dict, new_unit_net_route)\n",
    "\n",
    "# 修改key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 odict_keys(['model.selected_layers.0.weight', 'model.selected_layers.1.weight', 'model.selected_layers.1.bias', 'model.selected_layers.1.running_mean', 'model.selected_layers.1.running_var', 'model.selected_layers.1.num_batches_tracked', 'model.selected_layers.4.conv1.weight', 'model.selected_layers.4.bn1.weight', 'model.selected_layers.4.bn1.bias', 'model.selected_layers.4.bn1.running_mean', 'model.selected_layers.4.bn1.running_var', 'model.selected_layers.4.bn1.num_batches_tracked', 'model.selected_layers.4.conv2.weight', 'model.selected_layers.4.bn2.weight', 'model.selected_layers.4.bn2.bias', 'model.selected_layers.4.bn2.running_mean', 'model.selected_layers.4.bn2.running_var', 'model.selected_layers.4.bn2.num_batches_tracked', 'model.selected_layers.5.conv1.weight', 'model.selected_layers.5.bn1.weight', 'model.selected_layers.5.bn1.bias', 'model.selected_layers.5.bn1.running_mean', 'model.selected_layers.5.bn1.running_var', 'model.selected_layers.5.bn1.num_batches_tracked', 'model.selected_layers.5.conv2.weight', 'model.selected_layers.5.bn2.weight', 'model.selected_layers.5.bn2.bias', 'model.selected_layers.5.bn2.running_mean', 'model.selected_layers.5.bn2.running_var', 'model.selected_layers.5.bn2.num_batches_tracked', 'model.selected_layers.6.conv1.weight', 'model.selected_layers.6.bn1.weight', 'model.selected_layers.6.bn1.bias', 'model.selected_layers.6.bn1.running_mean', 'model.selected_layers.6.bn1.running_var', 'model.selected_layers.6.bn1.num_batches_tracked', 'model.selected_layers.6.conv2.weight', 'model.selected_layers.6.bn2.weight', 'model.selected_layers.6.bn2.bias', 'model.selected_layers.6.bn2.running_mean', 'model.selected_layers.6.bn2.running_var', 'model.selected_layers.6.bn2.num_batches_tracked', 'model.selected_layers.6.downsample.0.weight', 'model.selected_layers.6.downsample.1.weight', 'model.selected_layers.6.downsample.1.bias', 'model.selected_layers.6.downsample.1.running_mean', 'model.selected_layers.6.downsample.1.running_var', 'model.selected_layers.6.downsample.1.num_batches_tracked', 'model.selected_layers.7.conv1.weight', 'model.selected_layers.7.bn1.weight', 'model.selected_layers.7.bn1.bias', 'model.selected_layers.7.bn1.running_mean', 'model.selected_layers.7.bn1.running_var', 'model.selected_layers.7.bn1.num_batches_tracked', 'model.selected_layers.7.conv2.weight', 'model.selected_layers.7.bn2.weight', 'model.selected_layers.7.bn2.bias', 'model.selected_layers.7.bn2.running_mean', 'model.selected_layers.7.bn2.running_var', 'model.selected_layers.7.bn2.num_batches_tracked', 'model.selected_layers.8.conv1.weight', 'model.selected_layers.8.bn1.weight', 'model.selected_layers.8.bn1.bias', 'model.selected_layers.8.bn1.running_mean', 'model.selected_layers.8.bn1.running_var', 'model.selected_layers.8.bn1.num_batches_tracked', 'model.selected_layers.8.conv2.weight', 'model.selected_layers.8.bn2.weight', 'model.selected_layers.8.bn2.bias', 'model.selected_layers.8.bn2.running_mean', 'model.selected_layers.8.bn2.running_var', 'model.selected_layers.8.bn2.num_batches_tracked', 'model.selected_layers.8.downsample.0.weight', 'model.selected_layers.8.downsample.1.weight', 'model.selected_layers.8.downsample.1.bias', 'model.selected_layers.8.downsample.1.running_mean', 'model.selected_layers.8.downsample.1.running_var', 'model.selected_layers.8.downsample.1.num_batches_tracked', 'model.selected_layers.9.conv1.weight', 'model.selected_layers.9.bn1.weight', 'model.selected_layers.9.bn1.bias', 'model.selected_layers.9.bn1.running_mean', 'model.selected_layers.9.bn1.running_var', 'model.selected_layers.9.bn1.num_batches_tracked', 'model.selected_layers.9.conv2.weight', 'model.selected_layers.9.bn2.weight', 'model.selected_layers.9.bn2.bias', 'model.selected_layers.9.bn2.running_mean', 'model.selected_layers.9.bn2.running_var', 'model.selected_layers.9.bn2.num_batches_tracked', 'model.selected_layers.10.conv1.weight', 'model.selected_layers.10.bn1.weight', 'model.selected_layers.10.bn1.bias', 'model.selected_layers.10.bn1.running_mean', 'model.selected_layers.10.bn1.running_var', 'model.selected_layers.10.bn1.num_batches_tracked', 'model.selected_layers.10.conv2.weight', 'model.selected_layers.10.bn2.weight', 'model.selected_layers.10.bn2.bias', 'model.selected_layers.10.bn2.running_mean', 'model.selected_layers.10.bn2.running_var', 'model.selected_layers.10.bn2.num_batches_tracked', 'model.selected_layers.10.downsample.0.weight', 'model.selected_layers.10.downsample.1.weight', 'model.selected_layers.10.downsample.1.bias', 'model.selected_layers.10.downsample.1.running_mean', 'model.selected_layers.10.downsample.1.running_var', 'model.selected_layers.10.downsample.1.num_batches_tracked', 'model.selected_layers.11.conv1.weight', 'model.selected_layers.11.bn1.weight', 'model.selected_layers.11.bn1.bias', 'model.selected_layers.11.bn1.running_mean', 'model.selected_layers.11.bn1.running_var', 'model.selected_layers.11.bn1.num_batches_tracked', 'model.selected_layers.11.conv2.weight', 'model.selected_layers.11.bn2.weight', 'model.selected_layers.11.bn2.bias', 'model.selected_layers.11.bn2.running_mean', 'model.selected_layers.11.bn2.running_var', 'model.selected_layers.11.bn2.num_batches_tracked', 'model.selected_layers.13.weight', 'model.selected_layers.13.bias'])\n",
      "122 odict_keys(['selected_layers.0.weight', 'selected_layers.1.weight', 'selected_layers.1.bias', 'selected_layers.1.running_mean', 'selected_layers.1.running_var', 'selected_layers.1.num_batches_tracked', 'selected_layers.4.conv1.weight', 'selected_layers.4.bn1.weight', 'selected_layers.4.bn1.bias', 'selected_layers.4.bn1.running_mean', 'selected_layers.4.bn1.running_var', 'selected_layers.4.bn1.num_batches_tracked', 'selected_layers.4.conv2.weight', 'selected_layers.4.bn2.weight', 'selected_layers.4.bn2.bias', 'selected_layers.4.bn2.running_mean', 'selected_layers.4.bn2.running_var', 'selected_layers.4.bn2.num_batches_tracked', 'selected_layers.5.conv1.weight', 'selected_layers.5.bn1.weight', 'selected_layers.5.bn1.bias', 'selected_layers.5.bn1.running_mean', 'selected_layers.5.bn1.running_var', 'selected_layers.5.bn1.num_batches_tracked', 'selected_layers.5.conv2.weight', 'selected_layers.5.bn2.weight', 'selected_layers.5.bn2.bias', 'selected_layers.5.bn2.running_mean', 'selected_layers.5.bn2.running_var', 'selected_layers.5.bn2.num_batches_tracked', 'selected_layers.6.conv1.weight', 'selected_layers.6.bn1.weight', 'selected_layers.6.bn1.bias', 'selected_layers.6.bn1.running_mean', 'selected_layers.6.bn1.running_var', 'selected_layers.6.bn1.num_batches_tracked', 'selected_layers.6.conv2.weight', 'selected_layers.6.bn2.weight', 'selected_layers.6.bn2.bias', 'selected_layers.6.bn2.running_mean', 'selected_layers.6.bn2.running_var', 'selected_layers.6.bn2.num_batches_tracked', 'selected_layers.6.downsample.0.weight', 'selected_layers.6.downsample.1.weight', 'selected_layers.6.downsample.1.bias', 'selected_layers.6.downsample.1.running_mean', 'selected_layers.6.downsample.1.running_var', 'selected_layers.6.downsample.1.num_batches_tracked', 'selected_layers.7.conv1.weight', 'selected_layers.7.bn1.weight', 'selected_layers.7.bn1.bias', 'selected_layers.7.bn1.running_mean', 'selected_layers.7.bn1.running_var', 'selected_layers.7.bn1.num_batches_tracked', 'selected_layers.7.conv2.weight', 'selected_layers.7.bn2.weight', 'selected_layers.7.bn2.bias', 'selected_layers.7.bn2.running_mean', 'selected_layers.7.bn2.running_var', 'selected_layers.7.bn2.num_batches_tracked', 'selected_layers.8.conv1.weight', 'selected_layers.8.bn1.weight', 'selected_layers.8.bn1.bias', 'selected_layers.8.bn1.running_mean', 'selected_layers.8.bn1.running_var', 'selected_layers.8.bn1.num_batches_tracked', 'selected_layers.8.conv2.weight', 'selected_layers.8.bn2.weight', 'selected_layers.8.bn2.bias', 'selected_layers.8.bn2.running_mean', 'selected_layers.8.bn2.running_var', 'selected_layers.8.bn2.num_batches_tracked', 'selected_layers.8.downsample.0.weight', 'selected_layers.8.downsample.1.weight', 'selected_layers.8.downsample.1.bias', 'selected_layers.8.downsample.1.running_mean', 'selected_layers.8.downsample.1.running_var', 'selected_layers.8.downsample.1.num_batches_tracked', 'selected_layers.9.conv1.weight', 'selected_layers.9.bn1.weight', 'selected_layers.9.bn1.bias', 'selected_layers.9.bn1.running_mean', 'selected_layers.9.bn1.running_var', 'selected_layers.9.bn1.num_batches_tracked', 'selected_layers.9.conv2.weight', 'selected_layers.9.bn2.weight', 'selected_layers.9.bn2.bias', 'selected_layers.9.bn2.running_mean', 'selected_layers.9.bn2.running_var', 'selected_layers.9.bn2.num_batches_tracked', 'selected_layers.10.conv1.weight', 'selected_layers.10.bn1.weight', 'selected_layers.10.bn1.bias', 'selected_layers.10.bn1.running_mean', 'selected_layers.10.bn1.running_var', 'selected_layers.10.bn1.num_batches_tracked', 'selected_layers.10.conv2.weight', 'selected_layers.10.bn2.weight', 'selected_layers.10.bn2.bias', 'selected_layers.10.bn2.running_mean', 'selected_layers.10.bn2.running_var', 'selected_layers.10.bn2.num_batches_tracked', 'selected_layers.10.downsample.0.weight', 'selected_layers.10.downsample.1.weight', 'selected_layers.10.downsample.1.bias', 'selected_layers.10.downsample.1.running_mean', 'selected_layers.10.downsample.1.running_var', 'selected_layers.10.downsample.1.num_batches_tracked', 'selected_layers.11.conv1.weight', 'selected_layers.11.bn1.weight', 'selected_layers.11.bn1.bias', 'selected_layers.11.bn1.running_mean', 'selected_layers.11.bn1.running_var', 'selected_layers.11.bn1.num_batches_tracked', 'selected_layers.11.conv2.weight', 'selected_layers.11.bn2.weight', 'selected_layers.11.bn2.bias', 'selected_layers.11.bn2.running_mean', 'selected_layers.11.bn2.running_var', 'selected_layers.11.bn2.num_batches_tracked', 'selected_layers.13.weight', 'selected_layers.13.bias'])\n"
     ]
    }
   ],
   "source": [
    "# 改一下 resnet的 模型参数的key\n",
    "import sys\n",
    "sys.path.append('/home/dengruijun/data/FinTech/PP-Split/')\n",
    "import torch\n",
    "\n",
    "# from target_model.task_select import *\n",
    "\n",
    "pweights = torch.load(new_unit_net_route)\n",
    "cweights = client_net.state_dict()\n",
    "\n",
    "print(len(pweights.keys()),pweights.keys())\n",
    "print(len(cweights.keys()),cweights.keys())\n",
    "\n",
    "\n",
    "# new_key = {}\n",
    "# for keyp,keyc in zip(pweights.keys(),cweights.keys()):\n",
    "#     print(keyp,'\\t\\t\\t',keyc)\n",
    "\n",
    "# for i,key in enumerate(pweights.keys()):\n",
    "#     if i<122:\n",
    "#         continue\n",
    "#     print(key)\n",
    "\n",
    "    # new_key[key.replace('model.','')] = pweights[key]\n",
    "\n",
    "new_key = {}\n",
    "for key in cweights.keys():\n",
    "    # new_key[key] = pweights[key.replace('selected_layers','model.layers')] # resnet18 cifar10\n",
    "    # new_key[key] = pweights[key.replace('selected_layers','model.selected_layers')] # resnet18 cifar100\n",
    "    new_key[key] = pweights[key.replace('selected_layers','model.selected_layers')] # resnet18 cifar100\n",
    "torch.save(new_key, new_unit_net_route_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (selected_layers): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate=none)\n",
      "    (3): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): GELU(approximate=none)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载模型参数\n",
    "# client_net = resnet18(pretrained=False, split_layer=13, bottleneck_dim=-1, num_classes=100, activation='gelu', pooling='avg')\n",
    "state_dict = torch.load(new_unit_net_route_align)\n",
    "client_net.load_state_dict(state_dict) \n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet mnist\n",
    "net = AlexNet_MNIST()\n",
    "print(net)\n",
    "# print(len(net)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_msg = get_models(args)\n",
    "# # 模型\n",
    "# client_net,decoder_net = model_msg['client_net'],model_msg['decoder_net']\n",
    "# decoder_route = model_msg['decoder_route']\n",
    "# image_deprocess = model_msg['image_deprocess']\n",
    "\n",
    "\n",
    "client_net = VGG('Unit','VGG9',len(model_cfg['VGG9'])-1,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_net = VGG('Unit','VGG5',len(model_cfg['VGG5'])-1,model_cfg,noise_scale=args['noise_scale'])\n",
    "print(client_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drj-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
