/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /data/dengruijun/FinTech/PP-Split/results/trained_models/CIFAR10-models/state_dicts exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name      | Type               | Params | Mode
---------------------------------------------------------
0 | criterion | CrossEntropyLoss   | 0      | train
1 | accuracy  | MulticlassAccuracy | 0      | train
2 | model     | ResNet             | 11.2 M | train
---------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
71        Modules in train mode
0         Modules in eval mode
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('loss/val', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('acc/val', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.

















Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.74it/s, v_num=rhi6]




















Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.75it/s, v_num=rhi6]




















Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.60it/s, v_num=rhi6]



















Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.82it/s, v_num=rhi6]



















Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:36<00:00, 21.17it/s, v_num=rhi6]




















Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.82it/s, v_num=rhi6]



















Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.85it/s, v_num=rhi6]




















Epoch 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.54it/s, v_num=rhi6]




















Epoch 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.36it/s, v_num=rhi6]




















Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.84it/s, v_num=rhi6]



















Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.71it/s, v_num=rhi6]




















Epoch 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 21.02it/s, v_num=rhi6]



















Epoch 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.67it/s, v_num=rhi6]




















Epoch 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.85it/s, v_num=rhi6]



















Epoch 14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.66it/s, v_num=rhi6]




















Epoch 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.43it/s, v_num=rhi6]



















Epoch 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:36<00:00, 21.22it/s, v_num=rhi6]




















Epoch 17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.78it/s, v_num=rhi6]



















Epoch 18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.69it/s, v_num=rhi6]




















Epoch 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:37<00:00, 20.83it/s, v_num=rhi6]

Validation DataLoader 0:  47%|██████████████████████████████████████████████████████▌                                                            | 74/156 [00:01<00:01, 44.93it/s]
Testing DataLoader 0:  42%|█████████████████████████████████████████████████▉                                                                    | 66/156 [00:01<00:01, 51.58it/s]
`Trainer.fit` stopped: `max_epochs=20` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [00:03<00:00, 50.43it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         acc/test          [39m│[35m     72.21554565429688     [39m│
└───────────────────────────┴───────────────────────────┘
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('acc/test', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.