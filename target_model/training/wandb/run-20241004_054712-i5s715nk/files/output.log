LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name      | Type               | Params
-------------------------------------------------
0 | criterion | CrossEntropyLoss   | 0
1 | accuracy  | MulticlassAccuracy | 0
2 | model     | ResNet             | 10.6 M
-------------------------------------------------
10.6 M    Trainable params
0         Non-trainable params
10.6 M    Total params
42.547    Total estimated model params size (MB)
/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
Sanity Checking DataLoader 0:   0%|                                                            | 0/2 [00:00<?, ?it/s]
/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: It is recommended to use `self.log('loss/val', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.

Epoch 0:   0%|                                                                               | 0/195 [00:00<?, ?it/s]









Epoch 0: 100%|█████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.41it/s, v_num=15nk]









Epoch 1: 100%|█████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.58it/s, v_num=15nk]






























Epoch 4: 100%|█████████████████████████████████████████████████████████| 195/195 [00:19<00:00, 10.10it/s, v_num=15nk]









Epoch 5: 100%|█████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.83it/s, v_num=15nk]










Epoch 6: 100%|█████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.34it/s, v_num=15nk]








Epoch 7: 100%|█████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.79it/s, v_num=15nk]






























Epoch 10: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.62it/s, v_num=15nk]








Epoch 11: 100%|████████████████████████████████████████████████████████| 195/195 [00:17<00:00, 10.89it/s, v_num=15nk]









Epoch 12: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.79it/s, v_num=15nk]









Epoch 13: 100%|████████████████████████████████████████████████████████| 195/195 [00:17<00:00, 10.89it/s, v_num=15nk]









Epoch 14: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.72it/s, v_num=15nk]









Epoch 15: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.52it/s, v_num=15nk]









Epoch 16: 100%|████████████████████████████████████████████████████████| 195/195 [00:17<00:00, 10.84it/s, v_num=15nk]









Epoch 17: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.65it/s, v_num=15nk]










Epoch 18: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.45it/s, v_num=15nk]








Epoch 19: 100%|████████████████████████████████████████████████████████| 195/195 [00:18<00:00, 10.83it/s, v_num=15nk]
Validation DataLoader 0:  15%|████████▌                                               | 6/39 [00:00<00:01, 25.68it/s]

`Trainer.fit` stopped: `max_epochs=20` reached.
[rank: 0] Seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
/home/dengruijun/miniconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
Testing DataLoader 0:  90%|████████████████████████████████████████████████████      | 35/39 [00:01<00:00, 25.18it/s]
Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 25.13it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         acc/test          [39m│[35m     76.06169891357422     [39m│
└───────────────────────────┴───────────────────────────┘