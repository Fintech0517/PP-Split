/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /data/dengruijun/FinTech/PP-Split/results/trained_models/CIFAR10-models/state_dicts exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name      | Type               | Params | Mode
---------------------------------------------------------
0 | criterion | CrossEntropyLoss   | 0      | train
1 | accuracy  | MulticlassAccuracy | 0      | train
2 | model     | ResNet             | 11.2 M | train
---------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
71        Modules in train mode
0         Modules in eval mode
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('loss/val', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('acc/val', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
Epoch 0:   4%|████▌                                                                                                                  | 30/781 [00:01<00:44, 16.79it/s, v_num=uphx]


















Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.34it/s, v_num=uphx]




















Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.10it/s, v_num=uphx]




















Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.33it/s, v_num=uphx]




















Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.24it/s, v_num=uphx]





















Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.11it/s, v_num=uphx]




















Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.21it/s, v_num=uphx]



















Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.40it/s, v_num=uphx]





















Epoch 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.24it/s, v_num=uphx]




















Epoch 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:39<00:00, 19.96it/s, v_num=uphx]




















Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.28it/s, v_num=uphx]




















Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.28it/s, v_num=uphx]




















Epoch 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:39<00:00, 20.01it/s, v_num=uphx]




















Epoch 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:39<00:00, 19.93it/s, v_num=uphx]




















Epoch 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.43it/s, v_num=uphx]




















Epoch 14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:39<00:00, 20.01it/s, v_num=uphx]




















Epoch 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.10it/s, v_num=uphx]




















Epoch 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.17it/s, v_num=uphx]




















Epoch 17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.29it/s, v_num=uphx]




















Epoch 18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.33it/s, v_num=uphx]




















Epoch 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 781/781 [00:38<00:00, 20.18it/s, v_num=uphx]


Testing DataLoader 0:  10%|████████████                                                                                                          | 16/156 [00:00<00:02, 51.52it/s]
`Trainer.fit` stopped: `max_epochs=20` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.

Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [00:03<00:00, 49.29it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         acc/test          [39m│[35m     80.32852935791016     [39m│
└───────────────────────────┴───────────────────────────┘
/data/other/anaconda3/envs/drj-pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('acc/test', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.